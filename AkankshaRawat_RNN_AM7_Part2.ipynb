{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AkankshaRawat_RNN_AM7_Part2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyORIWzcI7Le3sfzwjsHP4px",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akanksha0911/DeepLearning_7/blob/main/AkankshaRawat_RNN_AM7_Part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RNN- One-to-many\n",
        "\n",
        ">pytorch-image-captioning\n",
        "\n",
        "https://colab.research.google.com/drive/1aRK2Mi1ECZdhcM6Hj9REN4ksQMvsDfiT#scrollTo=vHkuk9uZY7gj"
      ],
      "metadata": {
        "id": "FAeof87u4H2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_ILB5QY4_8i",
        "outputId": "4ce6d038-b62a-46db-fd9e-73d12905fe60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.16-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 11.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.11-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 38.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.2.0)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=20fd9f0821c0793c5ae7a9f18488bcbbb8bd415b7a2cac4ccb0e331560dfb5dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.11 setproctitle-1.2.3 shortuuid-1.0.8 smmap-5.0.0 wandb-0.12.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "import wandb\n",
        "import pickle\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Scikit-learn includes many helpful utilities\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "tqdm.pandas()"
      ],
      "metadata": {
        "id": "7yciZtvS4VGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk--MHSqaDFY"
      },
      "source": [
        "# RNN - Many-to-one\n",
        "> In this post, We will briefly cover the many-to-one type, which is one the common types of Recurrent Neural Network and its implementation in tensorflow. \n",
        "\n",
        "\n",
        "https://colab.research.google.com/github/goodboychan/goodboychan.github.io/blob/main/_notebooks/2020-12-06-01-RNN-Many-to-one.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1uMP0zxaDFc",
        "outputId": "fe0dcb0b-ef1f-4231-93b5-f1b5ff529e2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow: 2.8.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "print('Tensorflow: {}'.format(tf.__version__))\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (16, 10)\n",
        "plt.rc('font', size=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_6zPMYDaDFe"
      },
      "source": [
        "## Various usage of RNN\n",
        "As we already discussed, RNN is used for sequence data handling. And there are several types of RNN architecture.\n",
        "\n",
        "![various_rnn](image/various_rnn.png) {% fn 1 %}\n",
        "\n",
        "In previous [post](https://goodboychan.github.io/chans_jupyter/python/deep_learning/tensorflow-keras/2020/10/26/02-RNN-Basic.html), we take a look **one-to-one** type, which is the basic RNN structure. And next one is **one-to-many** type. For example, if the model gets the fixed format like image as an input, it generates the sequence data. You can see the implementation on image caption application. Another type is **many-to-many** type. It gets sequence data as an inputs, and also generates the sequence data as an output. Common application of many-to-many type is machine translation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s48ruQipaDFe"
      },
      "source": [
        "## Many-to-one\n",
        "\n",
        "**Many-to-one** type, which is our topic in this post, gets an sequence data as an input and generates some informatic data like labels. So we can use it for classification. Suppose that someone defines the sentiment of each sentence, and train the model with many-to-one type. And when the model gets the unseen sentence, then it will predict the intention of sentence, good or bad.\n",
        "\n",
        "![many-to-one example](image/many-to-one.png)\n",
        "\n",
        "The detailed explanation is like this.\n",
        "\n",
        "Suppose we have a sentence, \"This movis is good\". And we want to classify the sentiment of this sentence. In order to do this, we need to apply tokenization in word level. If this sentensce intends the good sentiment, then word token may contains good words, like \"good\". So we can classify this sentense to good sentiment.\n",
        "\n",
        "So if we want to apply it in RNN model, we need to consider the sentence as a word sequence(many), then clssify its label(one). That is process of many-to-one type model.\n",
        "\n",
        "![many-to-one detail](image/many-to-one_detail.png)\n",
        "\n",
        "But as you notice, computational model cannot accept the word itself as an input. Instead, it needs to convert with numerical vector. **Embedding** Layer can do this.\n",
        "\n",
        "So how can we implement this with tensorflow?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg72Qzc5aDFf"
      },
      "source": [
        "## Example - Word sentiment classification\n",
        "\n",
        "At first, we prepare the dummy data for simple classification. For the simplicity, we defined 1 as a good token, and 0 otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTQuAC9jaDFg"
      },
      "outputs": [],
      "source": [
        "words = ['good', 'bad', 'worse', 'so good']\n",
        "y = [1, 0, 0, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noj5bn_YaDFg"
      },
      "source": [
        "Based on this, we can generate the token dictionary, which is the mapping table for each characters. But before we prepare this, we need to consider one exceptional case, the variation of each sentence length. To train the network, the format (or shape) of input data must be fixed. So we need to add the concept of **padding**. Tensorflow has useful API for padding, `pad_sequences`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XftZdN9kaDFh"
      },
      "outputs": [],
      "source": [
        "char_set = ['<pad>'] + sorted(list(set(''.join(words))))\n",
        "idx2char = {idx:char for idx, char in enumerate(char_set)}\n",
        "char2idx = {char:idx for idx, char in enumerate(char_set)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeVzKvMyaDFh",
        "outputId": "f252fa3b-3127-4992-82a7-61f9b29320c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<pad>', ' ', 'a', 'b', 'd', 'e', 'g', 'o', 'r', 's', 'w']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "char_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJd0YAXMaDFi",
        "outputId": "26b03bd7-bb9d-4a79-bd3a-1e9727844d20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '<pad>',\n",
              " 1: ' ',\n",
              " 2: 'a',\n",
              " 3: 'b',\n",
              " 4: 'd',\n",
              " 5: 'e',\n",
              " 6: 'g',\n",
              " 7: 'o',\n",
              " 8: 'r',\n",
              " 9: 's',\n",
              " 10: 'w'}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "idx2char"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGZenhaLaDFj",
        "outputId": "93de91e1-29b2-4d65-ef96-300d13e1b52f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 1,\n",
              " '<pad>': 0,\n",
              " 'a': 2,\n",
              " 'b': 3,\n",
              " 'd': 4,\n",
              " 'e': 5,\n",
              " 'g': 6,\n",
              " 'o': 7,\n",
              " 'r': 8,\n",
              " 's': 9,\n",
              " 'w': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "char2idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TAefJ0GaDFj"
      },
      "source": [
        "So as we mentioned before, we need to vectorize each tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbdAcKEDaDFj"
      },
      "outputs": [],
      "source": [
        "X = list(map(lambda word: [char2idx.get(char) for char in word], words))\n",
        "X_len = list(map(lambda word: len(word), X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-6CFxcEaDFk",
        "outputId": "617a0f53-219d-4d1a-e489-eb5fa0fdebb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[6, 7, 7, 4], [3, 2, 4], [10, 7, 8, 9, 5], [9, 7, 1, 6, 7, 7, 4]]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JB7JBhuaDFk",
        "outputId": "d9e8ae5f-7718-4a06-fb51-122537b33461",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 3, 5, 7]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "X_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAkwYhaSaDFk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Padding the sequence of indices\n",
        "max_sequence=10\n",
        "\n",
        "X = pad_sequences(X, maxlen=max_sequence, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCjNKhAfaDFl",
        "outputId": "ad02f699-9f37-452b-b438-419b97f70db2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6,  7,  7,  4,  0,  0,  0,  0,  0,  0],\n",
              "       [ 3,  2,  4,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [10,  7,  8,  9,  5,  0,  0,  0,  0,  0],\n",
              "       [ 9,  7,  1,  6,  7,  7,  4,  0,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuAAb_XOaDFl",
        "outputId": "60e3e79d-d6cd-475b-ac62-4bd40a35a87c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omKggSSiaDFm"
      },
      "source": [
        "Here, we used `pad_sequences` API with several arguments. First, we defined maximum sequence length to 10. So numerical vector has an maximum length of 10. That is, we just consider 10 characters for sequence. And there are some words that has less than 10 characters. In that case, we filled some 0s for padding. Through argument, we can define the direction of padding, `pre` or `post`.\n",
        "\n",
        "And of course, it is efficient to use the dataset with generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRX3zdscaDFm",
        "outputId": "d2a70703-a8c5-4197-de8b-3b807451b488",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BatchDataset element_spec=(TensorSpec(shape=(None, 10), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
          ]
        }
      ],
      "source": [
        "# Generate data pipeline\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X, y)).shuffle(buffer_size=4).batch(batch_size=2)\n",
        "print(train_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqOKoeCBaDFm"
      },
      "source": [
        "After that, we can build many-to-one model with simpleRNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0k9OT3XoaDFn"
      },
      "outputs": [],
      "source": [
        "input_dim = len(char2idx)\n",
        "output_dim = len(char2idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbUu9cx8aDFn",
        "outputId": "088e3131-edfe-47df-8653-662df171daef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 10, 11)            121       \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 10)                220       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 22        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 363\n",
            "Trainable params: 242\n",
            "Non-trainable params: 121\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=input_dim, output_dim=output_dim,\n",
        "              mask_zero=True, input_length=max_sequence,\n",
        "              trainable=False, embeddings_initializer=tf.keras.initializers.random_normal()),\n",
        "    SimpleRNN(units=10),\n",
        "    Dense(2)\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dv2lcuq9aDFn"
      },
      "outputs": [],
      "source": [
        "def loss_fn(model, X, y):\n",
        "    return tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(y_true=y, \n",
        "                                                                          y_pred=model(X), \n",
        "                                                                          from_logits=True))\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fNx_hinaDFo",
        "outputId": "17f2d18c-4009-45d1-bab0-c641aef6d546",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:   5, tr_loss: 0.071402\n",
            "epoch:  10, tr_loss: 0.004197\n",
            "epoch:  15, tr_loss: 0.001211\n",
            "epoch:  20, tr_loss: 0.000727\n",
            "epoch:  25, tr_loss: 0.000566\n",
            "epoch:  30, tr_loss: 0.000487\n"
          ]
        }
      ],
      "source": [
        "tr_loss_hist = []\n",
        "\n",
        "for e in range(30):\n",
        "    avg_tr_loss = 0\n",
        "    tr_step = 0\n",
        "    \n",
        "    for x_mb, y_mb in train_ds:\n",
        "        with tf.GradientTape() as tape:\n",
        "            tr_loss = loss_fn(model, x_mb, y_mb)\n",
        "            \n",
        "        grads = tape.gradient(tr_loss, sources=model.variables)\n",
        "        optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
        "        avg_tr_loss += tr_loss\n",
        "        tr_step += 1\n",
        "    \n",
        "    avg_tr_loss /= tr_step\n",
        "    tr_loss_hist.append(avg_tr_loss)\n",
        "    \n",
        "    if (e + 1) % 5 == 0:\n",
        "        print('epoch: {:3}, tr_loss: {:3f}'.format(e + 1, avg_tr_loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e4LN1VSaDFo"
      },
      "source": [
        "After that, we can check the performance of this simple rnn network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLX6yOrvaDFo"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5NzMs64aDFo",
        "outputId": "15aa2363-6466-4f2d-bb87-b207a6ea043c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc: 100.00%\n"
          ]
        }
      ],
      "source": [
        "print('acc: {:.2%}'.format(np.mean(y_pred == y)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnA6mei_aDFp",
        "outputId": "35eb960e-a7b3-474f-a9af-3813bdfe4325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure()\n",
        "plt.plot(tr_loss_hist)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT77e7-oaDFp"
      },
      "source": [
        "As you can see, the performance of this simple network shows almost 100% accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTyA9FOtaDFp"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this post, we just cover the basic concept of **many-to-one** type RNN model for sentiment classification, and implement it with Tensorflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6ChDAxkaDFp"
      },
      "source": [
        "{{ 'Reference from stanford CS231n lecture note' | fndetail: 1 }}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fMAOBMNaMO8"
      },
      "source": [
        "# RNN - Many-to-many\n",
        "> In this coalb, We will cover the many-to-many RNN model, which can be used for Part of Speech (POS) tagging and Named Entity Recognition (NER).\n",
        "    Ref: https://goodboychan.github.io/python/deep_learning/tensorflow-keras/2020/12/09/01-RNN-Many-to-many.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpnt95xuaMO_",
        "outputId": "134b4600-4d76-45d7-ea37-bd84fd26df69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow: 2.8.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "print('Tensorflow: {}'.format(tf.__version__))\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (16, 10)\n",
        "plt.rc('font', size=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVc0gjgpaMPA"
      },
      "source": [
        "## What is \"Many-to-many\"?\n",
        "\n",
        "Previously, we covered 3 kinds of RNN model, one-to-one, many-to-one, and many-to-one with stacked model. Especially on many-to-one model, it gets an sequence data as an input, and generates the single output. So it can be used for classification, and previous example shows simple implementation of many-to-one model for word/sequence classification.\n",
        "\n",
        "Then, what is **many-to-many** model?\n",
        "\n",
        "The concept is same as before. In many-to-one model, to generate the output, the final input must be entered into model. Unlike this, many-to-many model generates the output whenever each input is read. That is, many-to-many model can understand the feature of each token in input sequence.\n",
        "\n",
        "One possible example is [**Part-of-Speech**](https://en.wikipedia.org/wiki/Part_of_speech) tagging, POS for short. POS is a category of words (or lexical items) that have similar grammatical properties. Common POS type are noun, verb, adjective, adverb, pronoun, etc. {% fn 2 %}. So POS tagging is automatically tagged POS of each token. Of course, it can manually handle with rule-based model, but many-to-many model is appropriate for doing this.\n",
        "\n",
        "For example, we have a sentence.\n",
        "$$ \\text{tensorflow is very easy} $$\n",
        "\n",
        "In order to do POS tagging, word tokenization is processed on that sentence. After that, we can get\n",
        "\n",
        "$$ [\\text{'tensorflow', 'is', 'very', 'easy'}] $$\n",
        "\n",
        "Then POS will be tagged on each token like this,\n",
        "\n",
        "$$[\\text{'noun', 'verb', 'adverb', 'adjective'}]$$\n",
        "\n",
        "If the many-to-many model is well-trained, whole process will be happened well.\n",
        "\n",
        "Unlike many-to-one model, loss measure is also different in many-to-many model. In many-to-one model, it can measure the loss by comparing the prediction value($\\hat{y}$) and actual value($y$). But in many-to-many model, each output node can measure the loss. There are many losses, so common ways to use it for training is by averaging whole losses. This kind of loss is called **sequence loss**. After that, specific optimizer (SGD or Adam) tries to minimize the loss with backpropagation.\n",
        "\n",
        "One thing we need to consider is handling padding tokens('<pad>'). As you saw from previous post, padding tokens are for formalize the various length of each sentence, it has no meaning. So it is required to remove (or \"masking\") padding tokens before training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9y9tYV_aMPB"
      },
      "source": [
        "## Example - Part of Speech Tagging\n",
        "\n",
        "### Prepraring Dataset\n",
        "\n",
        "In this section, we will implement the simple many-to-many model for POS tagging. Of course, there are two types of training data, sentence, and POS of that sentence. (Assume that we already tokenize each sentence.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--IocrJCaMPC"
      },
      "outputs": [],
      "source": [
        "sentences = [['I', 'feel', 'hungry'],\n",
        "             ['tensorflow', 'is', 'very', 'difficult'],\n",
        "             ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
        "             ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
        "\n",
        "pos = [['pronoun', 'verb', 'adjective'], \n",
        "       ['noun', 'verb', 'adverb', 'adjective'],\n",
        "       ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
        "       ['noun', 'verb', 'adverb', 'adjective', 'verb']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTymquu_aMPC"
      },
      "source": [
        "Same as previous example, we can build token dictionary. And additionally, we need to build POS dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTagCLqTaMPD",
        "outputId": "38610abf-496d-4aab-f6fc-aa3f5d3bdb81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<pad>', 'I', 'a', 'changing', 'deep', 'difficult', 'fast', 'feel', 'for', 'framework', 'hungry', 'is', 'learning', 'tensorflow', 'very']\n",
            "{'<pad>': 0, 'I': 1, 'a': 2, 'changing': 3, 'deep': 4, 'difficult': 5, 'fast': 6, 'feel': 7, 'for': 8, 'framework': 9, 'hungry': 10, 'is': 11, 'learning': 12, 'tensorflow': 13, 'very': 14}\n",
            "{0: '<pad>', 1: 'I', 2: 'a', 3: 'changing', 4: 'deep', 5: 'difficult', 6: 'fast', 7: 'feel', 8: 'for', 9: 'framework', 10: 'hungry', 11: 'is', 12: 'learning', 13: 'tensorflow', 14: 'very'}\n"
          ]
        }
      ],
      "source": [
        "word_list =['<pad>'] + sorted(set(sum(sentences, []))) \n",
        "word2idx = {word:idx for idx, word in enumerate(word_list)}\n",
        "idx2word = {idx:word for idx, word in enumerate(word_list)}\n",
        "\n",
        "print(word_list)\n",
        "print(word2idx)\n",
        "print(idx2word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bq4SgCMkaMPD",
        "outputId": "0ecbe7b9-af5c-448f-f218-b3ebeea179c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<pad>', 'adjective', 'adverb', 'determiner', 'noun', 'preposition', 'pronoun', 'verb']\n",
            "{'<pad>': 0, 'adjective': 1, 'adverb': 2, 'determiner': 3, 'noun': 4, 'preposition': 5, 'pronoun': 6, 'verb': 7}\n",
            "{0: '<pad>', 1: 'adjective', 2: 'adverb', 3: 'determiner', 4: 'noun', 5: 'preposition', 6: 'pronoun', 7: 'verb'}\n"
          ]
        }
      ],
      "source": [
        "pos_list = ['<pad>'] + sorted(set(sum(pos, [])))\n",
        "pos2idx = {pos:idx for idx, pos in enumerate(pos_list)}\n",
        "idx2pos = {idx:pos for idx, pos in enumerate(pos_list)}\n",
        "\n",
        "print(pos_list)\n",
        "print(pos2idx)\n",
        "print(idx2pos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKZtvl43aMPE"
      },
      "source": [
        "We build the dictionary for dataset. Based on this, we can convert from sentence to numerical vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjLcJorkaMPE",
        "outputId": "a1562b0b-db40-4b9a-d19e-fed4649423d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 7, 10], [13, 11, 14, 5], [13, 11, 2, 9, 8, 4, 12], [13, 11, 14, 6, 3]]\n",
            "[[6, 7, 1], [4, 7, 2, 1], [4, 7, 3, 4, 5, 1, 4], [4, 7, 2, 1, 7]]\n"
          ]
        }
      ],
      "source": [
        "X = list(map(lambda sentence: [word2idx.get(token) for token in sentence], sentences))\n",
        "y = list(map(lambda sentence: [pos2idx.get(token) for token in sentence], pos))\n",
        "\n",
        "print(X)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcwGRzXlaMPF"
      },
      "source": [
        "As you can see, the length of each sentence is various. We can fix the the length with `pad_sequences`. Also, we need masking vector for filtering pad tokens. In order to this, we feed the length of each sentence without padding as an input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLM5Y2eIaMPF",
        "outputId": "4137827d-5c5f-402f-cc39-337a2beb616d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  7 10  0  0  0  0  0  0  0]\n",
            " [13 11 14  5  0  0  0  0  0  0]\n",
            " [13 11  2  9  8  4 12  0  0  0]\n",
            " [13 11 14  6  3  0  0  0  0  0]]\n",
            "[[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]]\n",
            "[3. 4. 7. 5.]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X = pad_sequences(X, maxlen=10, padding='post')\n",
        "X_mask = (X != 0).astype(np.float32)\n",
        "X_len = np.array(list((map(lambda sentence: len(sentence), sentences))), dtype=np.float32)\n",
        "\n",
        "print(X)\n",
        "print(X_mask)\n",
        "print(X_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZCNoOdPaMPG",
        "outputId": "62d18647-3c38-4e01-b728-85658c93b2f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6 7 1 0 0 0 0 0 0 0]\n",
            " [4 7 2 1 0 0 0 0 0 0]\n",
            " [4 7 3 4 5 1 4 0 0 0]\n",
            " [4 7 2 1 7 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "y = pad_sequences(y, maxlen=10, padding='post')\n",
        "\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2qWyVcraMPG",
        "outputId": "e434dd66-e4e6-4d73-8262-2e50a7bbdb06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BatchDataset element_spec=(TensorSpec(shape=(None, 10), dtype=tf.int32, name=None), TensorSpec(shape=(None, 10), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.float32, name=None))>\n"
          ]
        }
      ],
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((X, y, X_len)).shuffle(buffer_size=4).batch(batch_size=2)\n",
        "\n",
        "print(train_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsE1vj-5aMPG"
      },
      "source": [
        "### Model implementation\n",
        "\n",
        "For many-to-many model, the output node must be number of classes. In our example, we need to predict the type of POS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzwsQPDzaMPH"
      },
      "outputs": [],
      "source": [
        "num_classes = len(pos2idx)\n",
        "input_dim = len(word2idx)\n",
        "output_dim = len(word2idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_7NvI9AaMPH",
        "outputId": "588f40e1-9f5e-449b-9ebb-e947a04e2071",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 10, 15)            225       \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 10, 10)            260       \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 10, 8)            88        \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 573\n",
            "Trainable params: 348\n",
            "Non-trainable params: 225\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, TimeDistributed, Dense, SimpleRNN\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=input_dim, output_dim=output_dim,\n",
        "              mask_zero=True, trainable=False, input_length=10,\n",
        "              embeddings_initializer=tf.keras.initializers.random_normal()),\n",
        "    SimpleRNN(units=10, return_sequences=True),\n",
        "    TimeDistributed(Dense(units=num_classes))\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPR3nIBXaMPH"
      },
      "source": [
        "So, here is important section, the loss definition. As we saw before, we need to filter the pad tokens, and calculate the sequence loss with each POS losses. Actually, tensorflow has API for masking. (`sequence_mask`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChWw18m-aMPH"
      },
      "outputs": [],
      "source": [
        "def loss_fn(model, x, y, x_len, max_sequence):\n",
        "    masking = tf.sequence_mask(x_len, maxlen=max_sequence, dtype=tf.float32)\n",
        "    sequence_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "        y_true=y, y_pred=model(x), from_logits=True\n",
        "    ) * masking\n",
        "    sequence_loss = tf.reduce_mean(tf.reduce_sum(sequence_loss, axis=1) / x_len)\n",
        "    return sequence_loss\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzHcsZ4xaMPI",
        "outputId": "e2b69e65-cbbb-44b7-f714-95dff3956143",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:   5, tr_loss: 0.655\n",
            "Epoch:  10, tr_loss: 0.341\n",
            "Epoch:  15, tr_loss: 0.183\n",
            "Epoch:  20, tr_loss: 0.067\n",
            "Epoch:  25, tr_loss: 0.025\n",
            "Epoch:  30, tr_loss: 0.009\n"
          ]
        }
      ],
      "source": [
        "tr_loss_hist = []\n",
        "\n",
        "for e in range(30):\n",
        "    avg_tr_loss = 0\n",
        "    tr_step = 0\n",
        "    \n",
        "    for x_mb, y_mb, x_mb_len in train_ds:\n",
        "        with tf.GradientTape() as tape:\n",
        "            tr_loss = loss_fn(model, x_mb, y_mb, x_mb_len, max_sequence=10)\n",
        "        grads = tape.gradient(tr_loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(grads_and_vars=zip(grads, model.trainable_variables))\n",
        "        avg_tr_loss += tr_loss\n",
        "        tr_step += 1\n",
        "    avg_tr_loss /= tr_step\n",
        "    tr_loss_hist.append(avg_tr_loss)\n",
        "    \n",
        "    if (e + 1) % 5 == 0:\n",
        "        print('Epoch: {:3}, tr_loss: {:.3f}'.format(e+1, avg_tr_loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwIj5EbBaMPI"
      },
      "source": [
        "We trained the model with 0.003 loss. Then we can enter the X data into the model as an input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxGKrgWtaMPI",
        "outputId": "c2a37f37-4bf0-41a4-ad97-3570a52bc8f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6., 7., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [4., 7., 2., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [4., 7., 3., 4., 5., 1., 4., 0., 0., 0.],\n",
              "       [4., 7., 2., 1., 7., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "y_pred = model.predict(X)\n",
        "y_pred = np.argmax(y_pred, axis=-1) * X_mask\n",
        "\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg6YsvDyaMPJ"
      },
      "source": [
        "To understand the model more visually, we can convert from numerical vector to POS with `idx2pos` dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PL-7aqfaaMPJ",
        "outputId": "494a3f0f-2558-46bd-c6cc-f615770894b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['pronoun',\n",
            "  'verb',\n",
            "  'adjective',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>'],\n",
            " ['noun',\n",
            "  'verb',\n",
            "  'adverb',\n",
            "  'adjective',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>'],\n",
            " ['noun',\n",
            "  'verb',\n",
            "  'determiner',\n",
            "  'noun',\n",
            "  'preposition',\n",
            "  'adjective',\n",
            "  'noun',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>'],\n",
            " ['noun',\n",
            "  'verb',\n",
            "  'adverb',\n",
            "  'adjective',\n",
            "  'verb',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>']]\n",
            "[['pronoun', 'verb', 'adjective'],\n",
            " ['noun', 'verb', 'adverb', 'adjective'],\n",
            " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
            " ['noun', 'verb', 'adverb', 'adjective', 'verb']]\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "y_pred_pos = list(map(lambda row: [idx2pos.get(elm) for elm in row], y_pred.astype(np.int32).tolist()))\n",
        "\n",
        "pprint(y_pred_pos)\n",
        "\n",
        "pprint(pos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AF1DvesoaMPJ",
        "outputId": "427ae37c-e0f3-4340-9573-55bbfdcd874f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure()\n",
        "plt.plot(tr_loss_hist)\n",
        "plt.title('Training loss for many-to-many model')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy3ZgmLhaMPJ"
      },
      "source": [
        "## Summary\n",
        " we tried to understand the basic concept of many-to-many RNN model, and how it can used for POS tagging. the output node is more than 2, not one, and measuring the sequence loss. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_f1SDa6aMPJ"
      },
      "source": [
        "{{ 'Reference from stanford CS231n lecture note' | fndetail: 1}}\n",
        "{{ 'Bring the definition from [wikipedia](https://en.wikipedia.org/wiki/Part_of_speech)' | fndetail: 2}}"
      ]
    }
  ]
}