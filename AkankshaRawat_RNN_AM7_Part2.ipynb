{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AkankshaRawat_RNN_AM7_Part2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOsXSjsRmYyXG1L9v/BVdx4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akanksha0911/DeepLearning_7/blob/main/AkankshaRawat_RNN_AM7_Part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**1. RNN- One-to-many**\n"
      ],
      "metadata": {
        "id": "FAeof87u4H2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-to-many sequence problems are sequence problems where the input data has one time-step, and the output contains a vector of multiple values or multiple time-steps. Thus, we have a single input and a sequence of outputs.\n",
        "A typical example is image captioning, where the description of an image is generated."
      ],
      "metadata": {
        "id": "mhdbe6UCn9pi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten, LSTM\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Input\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.layers import Bidirectional\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "ICeIJPBWxkVD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating the Dataset**"
      ],
      "metadata": {
        "id": "oTVufy0-5r6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = list()\n",
        "Y = list()\n",
        "X = [x+3 for x in range(-2, 43, 3)]\n",
        "\n",
        "for i in X:\n",
        "    output_vector = list()\n",
        "    output_vector.append(i+1)\n",
        "    output_vector.append(i+2)\n",
        "    Y.append(output_vector)\n",
        "\n",
        "print(X)\n",
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRHoIATzuf0B",
        "outputId": "c90d4e71-922c-440e-fb20-ecf8c4f307bf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 7, 10, 13, 16, 19, 22, 25, 28, 31, 34, 37, 40, 43]\n",
            "[[2, 3], [5, 6], [8, 9], [11, 12], [14, 15], [17, 18], [20, 21], [23, 24], [26, 27], [29, 30], [32, 33], [35, 36], [38, 39], [41, 42], [44, 45]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our input contains 15 samples with one time-step and one feature value. For each value in the input sample, the corresponding output vector contains the next two integers. For instance, if the input is 4, the output vector will contain values 5 and 6. Hence, the problem is a simple one-to-many sequence problem."
      ],
      "metadata": {
        "id": "o0SLCu-z52s7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following script reshapes our data as required by the LSTM:"
      ],
      "metadata": {
        "id": "2oOhQRo457az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X).reshape(15, 1, 1)\n",
        "Y = np.array(Y)"
      ],
      "metadata": {
        "id": "EH7Cp1aBujeA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution via Simple LSTM"
      ],
      "metadata": {
        "id": "wp4ZPYmT5ySw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(1, 1)))\n",
        "model.add(Dense(2))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(X, Y, epochs=1000, validation_split=0.2, batch_size=3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFoVbglTuuRa",
        "outputId": "bbb1c820-5a48-49a3-d812-5c9b4bca8ebb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/1000\n",
            "4/4 [==============================] - 3s 73ms/step - loss: 447.5462 - val_loss: 1632.8048\n",
            "Epoch 2/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 438.2929 - val_loss: 1602.0114\n",
            "Epoch 3/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 429.7032 - val_loss: 1570.7174\n",
            "Epoch 4/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 421.1010 - val_loss: 1537.3418\n",
            "Epoch 5/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 410.9883 - val_loss: 1503.0049\n",
            "Epoch 6/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 402.3784 - val_loss: 1465.3539\n",
            "Epoch 7/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 391.1396 - val_loss: 1426.4082\n",
            "Epoch 8/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 380.1814 - val_loss: 1384.7383\n",
            "Epoch 9/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 369.2033 - val_loss: 1340.0092\n",
            "Epoch 10/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 357.5016 - val_loss: 1290.6854\n",
            "Epoch 11/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 343.2231 - val_loss: 1238.1196\n",
            "Epoch 12/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 331.0421 - val_loss: 1178.3817\n",
            "Epoch 13/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 314.0802 - val_loss: 1115.5576\n",
            "Epoch 14/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 297.5025 - val_loss: 1047.2826\n",
            "Epoch 15/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 280.8678 - val_loss: 972.4407\n",
            "Epoch 16/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 261.6447 - val_loss: 893.0193\n",
            "Epoch 17/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 243.6688 - val_loss: 808.4495\n",
            "Epoch 18/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 220.3289 - val_loss: 726.1196\n",
            "Epoch 19/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 200.5433 - val_loss: 641.3705\n",
            "Epoch 20/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 180.9248 - val_loss: 554.6830\n",
            "Epoch 21/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 158.3269 - val_loss: 472.3338\n",
            "Epoch 22/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 141.4604 - val_loss: 390.5836\n",
            "Epoch 23/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 116.9477 - val_loss: 320.0818\n",
            "Epoch 24/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 101.1725 - val_loss: 251.4030\n",
            "Epoch 25/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 83.6923 - val_loss: 190.3852\n",
            "Epoch 26/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 66.7449 - val_loss: 138.6888\n",
            "Epoch 27/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 54.3413 - val_loss: 94.1671\n",
            "Epoch 28/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 40.7893 - val_loss: 60.5312\n",
            "Epoch 29/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 31.7050 - val_loss: 35.0864\n",
            "Epoch 30/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 23.1568 - val_loss: 18.4792\n",
            "Epoch 31/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 17.0506 - val_loss: 8.9450\n",
            "Epoch 32/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 13.2171 - val_loss: 4.6833\n",
            "Epoch 33/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 9.9937 - val_loss: 4.5069\n",
            "Epoch 34/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 7.8803 - val_loss: 6.8114\n",
            "Epoch 35/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 6.7283 - val_loss: 10.3351\n",
            "Epoch 36/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 6.0427 - val_loss: 14.0426\n",
            "Epoch 37/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 5.6309 - val_loss: 17.3125\n",
            "Epoch 38/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 5.2913 - val_loss: 19.3603\n",
            "Epoch 39/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 5.1618 - val_loss: 20.6883\n",
            "Epoch 40/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 5.0325 - val_loss: 21.1688\n",
            "Epoch 41/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 4.9480 - val_loss: 21.1472\n",
            "Epoch 42/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 4.8614 - val_loss: 20.8717\n",
            "Epoch 43/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 4.7805 - val_loss: 20.5224\n",
            "Epoch 44/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 4.7109 - val_loss: 20.2361\n",
            "Epoch 45/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 4.6410 - val_loss: 19.4438\n",
            "Epoch 46/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 4.5821 - val_loss: 18.8660\n",
            "Epoch 47/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 4.5369 - val_loss: 18.0301\n",
            "Epoch 48/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 4.4943 - val_loss: 17.2417\n",
            "Epoch 49/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 4.4710 - val_loss: 16.4280\n",
            "Epoch 50/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 4.4141 - val_loss: 16.3358\n",
            "Epoch 51/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 4.3956 - val_loss: 15.7531\n",
            "Epoch 52/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 4.3441 - val_loss: 15.6609\n",
            "Epoch 53/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 4.3124 - val_loss: 15.7225\n",
            "Epoch 54/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 4.2958 - val_loss: 16.0593\n",
            "Epoch 55/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 4.2494 - val_loss: 15.6452\n",
            "Epoch 56/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 4.2174 - val_loss: 15.5262\n",
            "Epoch 57/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 4.1905 - val_loss: 15.1702\n",
            "Epoch 58/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 4.1577 - val_loss: 15.2632\n",
            "Epoch 59/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 4.1256 - val_loss: 15.0069\n",
            "Epoch 60/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 4.1012 - val_loss: 15.2057\n",
            "Epoch 61/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 4.0670 - val_loss: 14.7913\n",
            "Epoch 62/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 4.0318 - val_loss: 14.5759\n",
            "Epoch 63/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.9997 - val_loss: 14.3992\n",
            "Epoch 64/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.9694 - val_loss: 14.4313\n",
            "Epoch 65/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.9400 - val_loss: 14.5437\n",
            "Epoch 66/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 3.9048 - val_loss: 14.3781\n",
            "Epoch 67/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 3.8874 - val_loss: 13.7904\n",
            "Epoch 68/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.8422 - val_loss: 13.6632\n",
            "Epoch 69/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.8128 - val_loss: 13.5840\n",
            "Epoch 70/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.7827 - val_loss: 13.5379\n",
            "Epoch 71/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.7502 - val_loss: 13.2356\n",
            "Epoch 72/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.7294 - val_loss: 12.8241\n",
            "Epoch 73/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.7095 - val_loss: 13.2456\n",
            "Epoch 74/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.6664 - val_loss: 13.1954\n",
            "Epoch 75/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.6374 - val_loss: 13.2760\n",
            "Epoch 76/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.6090 - val_loss: 12.5009\n",
            "Epoch 77/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.5752 - val_loss: 11.9376\n",
            "Epoch 78/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.5386 - val_loss: 11.9454\n",
            "Epoch 79/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.5147 - val_loss: 11.4805\n",
            "Epoch 80/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.4824 - val_loss: 11.1998\n",
            "Epoch 81/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.4658 - val_loss: 11.6816\n",
            "Epoch 82/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.4049 - val_loss: 11.5677\n",
            "Epoch 83/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.3809 - val_loss: 11.2181\n",
            "Epoch 84/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.3519 - val_loss: 10.8740\n",
            "Epoch 85/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 3.3268 - val_loss: 11.1827\n",
            "Epoch 86/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 3.2898 - val_loss: 10.8467\n",
            "Epoch 87/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.2607 - val_loss: 10.6799\n",
            "Epoch 88/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 3.2218 - val_loss: 10.7274\n",
            "Epoch 89/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 3.1955 - val_loss: 10.4072\n",
            "Epoch 90/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 3.1734 - val_loss: 10.4984\n",
            "Epoch 91/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 3.1313 - val_loss: 10.2402\n",
            "Epoch 92/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 3.0982 - val_loss: 9.8270\n",
            "Epoch 93/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 3.0702 - val_loss: 9.5596\n",
            "Epoch 94/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.0372 - val_loss: 9.3734\n",
            "Epoch 95/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.0082 - val_loss: 9.2672\n",
            "Epoch 96/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.9831 - val_loss: 9.2468\n",
            "Epoch 97/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.9510 - val_loss: 8.8473\n",
            "Epoch 98/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.9215 - val_loss: 8.6642\n",
            "Epoch 99/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.8876 - val_loss: 8.5505\n",
            "Epoch 100/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.8616 - val_loss: 8.2464\n",
            "Epoch 101/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.8396 - val_loss: 7.9085\n",
            "Epoch 102/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.8046 - val_loss: 8.0847\n",
            "Epoch 103/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.7673 - val_loss: 8.0205\n",
            "Epoch 104/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.7380 - val_loss: 7.8708\n",
            "Epoch 105/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.7132 - val_loss: 7.7028\n",
            "Epoch 106/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.6878 - val_loss: 7.7447\n",
            "Epoch 107/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.6531 - val_loss: 7.5306\n",
            "Epoch 108/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.6322 - val_loss: 7.6746\n",
            "Epoch 109/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.5941 - val_loss: 7.4822\n",
            "Epoch 110/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.5782 - val_loss: 7.0027\n",
            "Epoch 111/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.5437 - val_loss: 6.8370\n",
            "Epoch 112/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.5146 - val_loss: 6.5628\n",
            "Epoch 113/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.4851 - val_loss: 6.4116\n",
            "Epoch 114/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.4608 - val_loss: 6.2319\n",
            "Epoch 115/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.4255 - val_loss: 6.1848\n",
            "Epoch 116/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.4030 - val_loss: 6.3098\n",
            "Epoch 117/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.3729 - val_loss: 6.2099\n",
            "Epoch 118/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.3469 - val_loss: 6.1210\n",
            "Epoch 119/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.3228 - val_loss: 6.0807\n",
            "Epoch 120/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.3019 - val_loss: 5.8167\n",
            "Epoch 121/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.2702 - val_loss: 5.7921\n",
            "Epoch 122/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.2487 - val_loss: 5.8472\n",
            "Epoch 123/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.2209 - val_loss: 5.4797\n",
            "Epoch 124/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.1911 - val_loss: 5.2543\n",
            "Epoch 125/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.1685 - val_loss: 5.3034\n",
            "Epoch 126/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.1430 - val_loss: 5.2570\n",
            "Epoch 127/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.1186 - val_loss: 4.9160\n",
            "Epoch 128/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.1018 - val_loss: 4.6636\n",
            "Epoch 129/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.0684 - val_loss: 4.5560\n",
            "Epoch 130/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.0615 - val_loss: 4.8103\n",
            "Epoch 131/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.0189 - val_loss: 4.6789\n",
            "Epoch 132/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.9965 - val_loss: 4.5570\n",
            "Epoch 133/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.9730 - val_loss: 4.5569\n",
            "Epoch 134/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.9480 - val_loss: 4.3544\n",
            "Epoch 135/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.9260 - val_loss: 4.1318\n",
            "Epoch 136/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.9058 - val_loss: 4.0086\n",
            "Epoch 137/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.8823 - val_loss: 3.9906\n",
            "Epoch 138/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.8562 - val_loss: 3.9082\n",
            "Epoch 139/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.8471 - val_loss: 4.0218\n",
            "Epoch 140/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.8117 - val_loss: 3.9009\n",
            "Epoch 141/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.7995 - val_loss: 3.5909\n",
            "Epoch 142/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.7745 - val_loss: 3.6221\n",
            "Epoch 143/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.7478 - val_loss: 3.5759\n",
            "Epoch 144/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.7286 - val_loss: 3.3774\n",
            "Epoch 145/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.7114 - val_loss: 3.2136\n",
            "Epoch 146/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.6875 - val_loss: 3.1251\n",
            "Epoch 147/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.6742 - val_loss: 3.2944\n",
            "Epoch 148/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.6461 - val_loss: 3.2305\n",
            "Epoch 149/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.6352 - val_loss: 3.3277\n",
            "Epoch 150/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.6067 - val_loss: 3.2312\n",
            "Epoch 151/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.5943 - val_loss: 3.2568\n",
            "Epoch 152/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.5680 - val_loss: 2.9775\n",
            "Epoch 153/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.5460 - val_loss: 2.8940\n",
            "Epoch 154/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.5332 - val_loss: 2.6597\n",
            "Epoch 155/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.5103 - val_loss: 2.5901\n",
            "Epoch 156/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.4928 - val_loss: 2.5589\n",
            "Epoch 157/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.4738 - val_loss: 2.5650\n",
            "Epoch 158/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.4525 - val_loss: 2.5461\n",
            "Epoch 159/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.4368 - val_loss: 2.5398\n",
            "Epoch 160/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.4201 - val_loss: 2.3969\n",
            "Epoch 161/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.4030 - val_loss: 2.4283\n",
            "Epoch 162/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.3850 - val_loss: 2.4278\n",
            "Epoch 163/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.3664 - val_loss: 2.3091\n",
            "Epoch 164/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.3482 - val_loss: 2.1906\n",
            "Epoch 165/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.3381 - val_loss: 2.2599\n",
            "Epoch 166/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.3154 - val_loss: 2.2376\n",
            "Epoch 167/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.3025 - val_loss: 2.2112\n",
            "Epoch 168/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.2852 - val_loss: 1.9866\n",
            "Epoch 169/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.2666 - val_loss: 1.9629\n",
            "Epoch 170/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.2538 - val_loss: 1.7708\n",
            "Epoch 171/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.2353 - val_loss: 1.6724\n",
            "Epoch 172/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.2180 - val_loss: 1.7096\n",
            "Epoch 173/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.2022 - val_loss: 1.6754\n",
            "Epoch 174/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.1868 - val_loss: 1.7025\n",
            "Epoch 175/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.1731 - val_loss: 1.7277\n",
            "Epoch 176/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.1567 - val_loss: 1.6671\n",
            "Epoch 177/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.1404 - val_loss: 1.6123\n",
            "Epoch 178/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.1255 - val_loss: 1.6097\n",
            "Epoch 179/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.1167 - val_loss: 1.6727\n",
            "Epoch 180/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.1002 - val_loss: 1.6093\n",
            "Epoch 181/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.0809 - val_loss: 1.5087\n",
            "Epoch 182/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.0706 - val_loss: 1.3687\n",
            "Epoch 183/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.0598 - val_loss: 1.2437\n",
            "Epoch 184/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.0440 - val_loss: 1.2494\n",
            "Epoch 185/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.0272 - val_loss: 1.2682\n",
            "Epoch 186/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0143 - val_loss: 1.2482\n",
            "Epoch 187/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.0001 - val_loss: 1.2378\n",
            "Epoch 188/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.9874 - val_loss: 1.2485\n",
            "Epoch 189/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.9757 - val_loss: 1.2530\n",
            "Epoch 190/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.9619 - val_loss: 1.1394\n",
            "Epoch 191/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.9513 - val_loss: 1.0377\n",
            "Epoch 192/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.9394 - val_loss: 1.0744\n",
            "Epoch 193/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.9238 - val_loss: 1.0206\n",
            "Epoch 194/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.9104 - val_loss: 1.0143\n",
            "Epoch 195/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.9008 - val_loss: 0.9250\n",
            "Epoch 196/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.8867 - val_loss: 0.8906\n",
            "Epoch 197/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.8754 - val_loss: 0.8784\n",
            "Epoch 198/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.8634 - val_loss: 0.8690\n",
            "Epoch 199/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.8520 - val_loss: 0.8674\n",
            "Epoch 200/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.8413 - val_loss: 0.8325\n",
            "Epoch 201/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.8329 - val_loss: 0.8808\n",
            "Epoch 202/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.8180 - val_loss: 0.8530\n",
            "Epoch 203/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.8080 - val_loss: 0.8180\n",
            "Epoch 204/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7973 - val_loss: 0.7457\n",
            "Epoch 205/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7898 - val_loss: 0.6551\n",
            "Epoch 206/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7761 - val_loss: 0.6700\n",
            "Epoch 207/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7649 - val_loss: 0.6428\n",
            "Epoch 208/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7592 - val_loss: 0.6883\n",
            "Epoch 209/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7440 - val_loss: 0.6597\n",
            "Epoch 210/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7357 - val_loss: 0.6184\n",
            "Epoch 211/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7242 - val_loss: 0.5991\n",
            "Epoch 212/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7161 - val_loss: 0.5550\n",
            "Epoch 213/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7063 - val_loss: 0.5442\n",
            "Epoch 214/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6956 - val_loss: 0.5278\n",
            "Epoch 215/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.6869 - val_loss: 0.5311\n",
            "Epoch 216/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6779 - val_loss: 0.5127\n",
            "Epoch 217/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6681 - val_loss: 0.4773\n",
            "Epoch 218/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.6599 - val_loss: 0.4288\n",
            "Epoch 219/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.6517 - val_loss: 0.3906\n",
            "Epoch 220/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6416 - val_loss: 0.4087\n",
            "Epoch 221/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6331 - val_loss: 0.4092\n",
            "Epoch 222/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.6241 - val_loss: 0.4302\n",
            "Epoch 223/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6157 - val_loss: 0.4353\n",
            "Epoch 224/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6081 - val_loss: 0.4010\n",
            "Epoch 225/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6005 - val_loss: 0.4068\n",
            "Epoch 226/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5927 - val_loss: 0.3534\n",
            "Epoch 227/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.5845 - val_loss: 0.3265\n",
            "Epoch 228/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5756 - val_loss: 0.3279\n",
            "Epoch 229/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5672 - val_loss: 0.3067\n",
            "Epoch 230/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5605 - val_loss: 0.3016\n",
            "Epoch 231/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5532 - val_loss: 0.2775\n",
            "Epoch 232/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5460 - val_loss: 0.2875\n",
            "Epoch 233/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5382 - val_loss: 0.2594\n",
            "Epoch 234/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5302 - val_loss: 0.2567\n",
            "Epoch 235/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5232 - val_loss: 0.2469\n",
            "Epoch 236/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5166 - val_loss: 0.2414\n",
            "Epoch 237/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5090 - val_loss: 0.2417\n",
            "Epoch 238/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5021 - val_loss: 0.2383\n",
            "Epoch 239/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4967 - val_loss: 0.2258\n",
            "Epoch 240/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4889 - val_loss: 0.2119\n",
            "Epoch 241/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4843 - val_loss: 0.2090\n",
            "Epoch 242/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4784 - val_loss: 0.1675\n",
            "Epoch 243/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4711 - val_loss: 0.1670\n",
            "Epoch 244/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4642 - val_loss: 0.1689\n",
            "Epoch 245/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4571 - val_loss: 0.1633\n",
            "Epoch 246/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4515 - val_loss: 0.1488\n",
            "Epoch 247/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4455 - val_loss: 0.1328\n",
            "Epoch 248/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4406 - val_loss: 0.1356\n",
            "Epoch 249/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4335 - val_loss: 0.1264\n",
            "Epoch 250/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4280 - val_loss: 0.1238\n",
            "Epoch 251/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4222 - val_loss: 0.1201\n",
            "Epoch 252/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4169 - val_loss: 0.1211\n",
            "Epoch 253/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4117 - val_loss: 0.1186\n",
            "Epoch 254/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4057 - val_loss: 0.1159\n",
            "Epoch 255/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4010 - val_loss: 0.1101\n",
            "Epoch 256/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3945 - val_loss: 0.1014\n",
            "Epoch 257/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3901 - val_loss: 0.0884\n",
            "Epoch 258/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3846 - val_loss: 0.0818\n",
            "Epoch 259/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3805 - val_loss: 0.0788\n",
            "Epoch 260/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3746 - val_loss: 0.0718\n",
            "Epoch 261/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3708 - val_loss: 0.0594\n",
            "Epoch 262/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3656 - val_loss: 0.0596\n",
            "Epoch 263/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3611 - val_loss: 0.0565\n",
            "Epoch 264/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3562 - val_loss: 0.0595\n",
            "Epoch 265/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3514 - val_loss: 0.0552\n",
            "Epoch 266/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3469 - val_loss: 0.0552\n",
            "Epoch 267/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3424 - val_loss: 0.0545\n",
            "Epoch 268/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3383 - val_loss: 0.0508\n",
            "Epoch 269/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3342 - val_loss: 0.0461\n",
            "Epoch 270/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3291 - val_loss: 0.0413\n",
            "Epoch 271/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3255 - val_loss: 0.0341\n",
            "Epoch 272/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3216 - val_loss: 0.0305\n",
            "Epoch 273/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3179 - val_loss: 0.0316\n",
            "Epoch 274/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3135 - val_loss: 0.0300\n",
            "Epoch 275/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3093 - val_loss: 0.0255\n",
            "Epoch 276/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3053 - val_loss: 0.0255\n",
            "Epoch 277/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3019 - val_loss: 0.0259\n",
            "Epoch 278/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2977 - val_loss: 0.0226\n",
            "Epoch 279/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2943 - val_loss: 0.0167\n",
            "Epoch 280/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2907 - val_loss: 0.0150\n",
            "Epoch 281/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2891 - val_loss: 0.0189\n",
            "Epoch 282/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2831 - val_loss: 0.0159\n",
            "Epoch 283/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2806 - val_loss: 0.0150\n",
            "Epoch 284/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2761 - val_loss: 0.0107\n",
            "Epoch 285/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2735 - val_loss: 0.0099\n",
            "Epoch 286/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2699 - val_loss: 0.0081\n",
            "Epoch 287/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2670 - val_loss: 0.0051\n",
            "Epoch 288/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2635 - val_loss: 0.0048\n",
            "Epoch 289/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2603 - val_loss: 0.0049\n",
            "Epoch 290/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2577 - val_loss: 0.0054\n",
            "Epoch 291/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2541 - val_loss: 0.0044\n",
            "Epoch 292/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2511 - val_loss: 0.0045\n",
            "Epoch 293/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2480 - val_loss: 0.0041\n",
            "Epoch 294/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2458 - val_loss: 0.0036\n",
            "Epoch 295/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2425 - val_loss: 0.0031\n",
            "Epoch 296/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2396 - val_loss: 0.0019\n",
            "Epoch 297/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2371 - val_loss: 0.0017\n",
            "Epoch 298/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2343 - val_loss: 0.0015\n",
            "Epoch 299/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2312 - val_loss: 0.0012\n",
            "Epoch 300/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2286 - val_loss: 0.0011\n",
            "Epoch 301/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2263 - val_loss: 0.0012\n",
            "Epoch 302/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2242 - val_loss: 0.0012\n",
            "Epoch 303/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2214 - val_loss: 0.0012\n",
            "Epoch 304/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2186 - val_loss: 0.0014\n",
            "Epoch 305/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2166 - val_loss: 0.0014\n",
            "Epoch 306/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2146 - val_loss: 0.0015\n",
            "Epoch 307/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2121 - val_loss: 0.0016\n",
            "Epoch 308/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2092 - val_loss: 0.0021\n",
            "Epoch 309/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2071 - val_loss: 0.0029\n",
            "Epoch 310/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2046 - val_loss: 0.0037\n",
            "Epoch 311/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2025 - val_loss: 0.0042\n",
            "Epoch 312/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2007 - val_loss: 0.0047\n",
            "Epoch 313/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1982 - val_loss: 0.0052\n",
            "Epoch 314/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1966 - val_loss: 0.0043\n",
            "Epoch 315/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1943 - val_loss: 0.0052\n",
            "Epoch 316/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1928 - val_loss: 0.0049\n",
            "Epoch 317/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1903 - val_loss: 0.0062\n",
            "Epoch 318/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1883 - val_loss: 0.0086\n",
            "Epoch 319/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1866 - val_loss: 0.0094\n",
            "Epoch 320/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1847 - val_loss: 0.0087\n",
            "Epoch 321/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1826 - val_loss: 0.0085\n",
            "Epoch 322/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1810 - val_loss: 0.0089\n",
            "Epoch 323/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1791 - val_loss: 0.0112\n",
            "Epoch 324/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1772 - val_loss: 0.0118\n",
            "Epoch 325/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1758 - val_loss: 0.0125\n",
            "Epoch 326/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1740 - val_loss: 0.0140\n",
            "Epoch 327/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1723 - val_loss: 0.0132\n",
            "Epoch 328/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1705 - val_loss: 0.0133\n",
            "Epoch 329/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1690 - val_loss: 0.0149\n",
            "Epoch 330/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1674 - val_loss: 0.0165\n",
            "Epoch 331/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1663 - val_loss: 0.0156\n",
            "Epoch 332/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1642 - val_loss: 0.0188\n",
            "Epoch 333/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1627 - val_loss: 0.0195\n",
            "Epoch 334/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1614 - val_loss: 0.0195\n",
            "Epoch 335/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1595 - val_loss: 0.0208\n",
            "Epoch 336/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1584 - val_loss: 0.0211\n",
            "Epoch 337/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1569 - val_loss: 0.0220\n",
            "Epoch 338/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1557 - val_loss: 0.0213\n",
            "Epoch 339/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1539 - val_loss: 0.0254\n",
            "Epoch 340/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1526 - val_loss: 0.0265\n",
            "Epoch 341/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1514 - val_loss: 0.0267\n",
            "Epoch 342/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1500 - val_loss: 0.0264\n",
            "Epoch 343/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1489 - val_loss: 0.0273\n",
            "Epoch 344/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1473 - val_loss: 0.0289\n",
            "Epoch 345/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1463 - val_loss: 0.0293\n",
            "Epoch 346/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1451 - val_loss: 0.0316\n",
            "Epoch 347/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1439 - val_loss: 0.0314\n",
            "Epoch 348/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1427 - val_loss: 0.0314\n",
            "Epoch 349/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1414 - val_loss: 0.0323\n",
            "Epoch 350/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1401 - val_loss: 0.0344\n",
            "Epoch 351/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1389 - val_loss: 0.0353\n",
            "Epoch 352/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1385 - val_loss: 0.0321\n",
            "Epoch 353/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1369 - val_loss: 0.0338\n",
            "Epoch 354/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1358 - val_loss: 0.0347\n",
            "Epoch 355/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1347 - val_loss: 0.0375\n",
            "Epoch 356/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1334 - val_loss: 0.0400\n",
            "Epoch 357/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1328 - val_loss: 0.0442\n",
            "Epoch 358/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1320 - val_loss: 0.0408\n",
            "Epoch 359/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1305 - val_loss: 0.0393\n",
            "Epoch 360/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1296 - val_loss: 0.0398\n",
            "Epoch 361/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1286 - val_loss: 0.0418\n",
            "Epoch 362/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1275 - val_loss: 0.0415\n",
            "Epoch 363/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1266 - val_loss: 0.0436\n",
            "Epoch 364/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1261 - val_loss: 0.0406\n",
            "Epoch 365/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1248 - val_loss: 0.0429\n",
            "Epoch 366/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1240 - val_loss: 0.0442\n",
            "Epoch 367/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1228 - val_loss: 0.0463\n",
            "Epoch 368/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1220 - val_loss: 0.0457\n",
            "Epoch 369/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1214 - val_loss: 0.0459\n",
            "Epoch 370/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1203 - val_loss: 0.0477\n",
            "Epoch 371/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1198 - val_loss: 0.0447\n",
            "Epoch 372/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1187 - val_loss: 0.0460\n",
            "Epoch 373/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1178 - val_loss: 0.0481\n",
            "Epoch 374/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1171 - val_loss: 0.0478\n",
            "Epoch 375/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1163 - val_loss: 0.0518\n",
            "Epoch 376/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1155 - val_loss: 0.0516\n",
            "Epoch 377/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1147 - val_loss: 0.0523\n",
            "Epoch 378/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1137 - val_loss: 0.0523\n",
            "Epoch 379/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1132 - val_loss: 0.0472\n",
            "Epoch 380/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1123 - val_loss: 0.0465\n",
            "Epoch 381/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1115 - val_loss: 0.0470\n",
            "Epoch 382/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1110 - val_loss: 0.0474\n",
            "Epoch 383/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1100 - val_loss: 0.0513\n",
            "Epoch 384/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1093 - val_loss: 0.0556\n",
            "Epoch 385/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1086 - val_loss: 0.0563\n",
            "Epoch 386/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1079 - val_loss: 0.0544\n",
            "Epoch 387/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1075 - val_loss: 0.0560\n",
            "Epoch 388/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1072 - val_loss: 0.0489\n",
            "Epoch 389/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1061 - val_loss: 0.0538\n",
            "Epoch 390/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1052 - val_loss: 0.0540\n",
            "Epoch 391/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1045 - val_loss: 0.0521\n",
            "Epoch 392/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1041 - val_loss: 0.0484\n",
            "Epoch 393/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1032 - val_loss: 0.0514\n",
            "Epoch 394/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1028 - val_loss: 0.0504\n",
            "Epoch 395/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1019 - val_loss: 0.0531\n",
            "Epoch 396/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1015 - val_loss: 0.0545\n",
            "Epoch 397/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1006 - val_loss: 0.0575\n",
            "Epoch 398/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1002 - val_loss: 0.0541\n",
            "Epoch 399/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0997 - val_loss: 0.0525\n",
            "Epoch 400/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0993 - val_loss: 0.0588\n",
            "Epoch 401/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0985 - val_loss: 0.0575\n",
            "Epoch 402/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0979 - val_loss: 0.0523\n",
            "Epoch 403/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0977 - val_loss: 0.0464\n",
            "Epoch 404/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0965 - val_loss: 0.0464\n",
            "Epoch 405/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0962 - val_loss: 0.0533\n",
            "Epoch 406/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0954 - val_loss: 0.0530\n",
            "Epoch 407/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0949 - val_loss: 0.0570\n",
            "Epoch 408/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0944 - val_loss: 0.0569\n",
            "Epoch 409/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0939 - val_loss: 0.0525\n",
            "Epoch 410/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0932 - val_loss: 0.0515\n",
            "Epoch 411/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0927 - val_loss: 0.0504\n",
            "Epoch 412/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0924 - val_loss: 0.0480\n",
            "Epoch 413/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0916 - val_loss: 0.0484\n",
            "Epoch 414/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0912 - val_loss: 0.0485\n",
            "Epoch 415/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0905 - val_loss: 0.0524\n",
            "Epoch 416/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0903 - val_loss: 0.0586\n",
            "Epoch 417/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0897 - val_loss: 0.0540\n",
            "Epoch 418/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0891 - val_loss: 0.0523\n",
            "Epoch 419/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0886 - val_loss: 0.0501\n",
            "Epoch 420/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0882 - val_loss: 0.0511\n",
            "Epoch 421/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0875 - val_loss: 0.0484\n",
            "Epoch 422/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0870 - val_loss: 0.0462\n",
            "Epoch 423/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0866 - val_loss: 0.0472\n",
            "Epoch 424/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0863 - val_loss: 0.0501\n",
            "Epoch 425/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0856 - val_loss: 0.0458\n",
            "Epoch 426/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0851 - val_loss: 0.0466\n",
            "Epoch 427/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0846 - val_loss: 0.0454\n",
            "Epoch 428/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0843 - val_loss: 0.0459\n",
            "Epoch 429/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0841 - val_loss: 0.0507\n",
            "Epoch 430/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0835 - val_loss: 0.0448\n",
            "Epoch 431/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0829 - val_loss: 0.0430\n",
            "Epoch 432/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0825 - val_loss: 0.0462\n",
            "Epoch 433/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0820 - val_loss: 0.0438\n",
            "Epoch 434/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0816 - val_loss: 0.0464\n",
            "Epoch 435/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0810 - val_loss: 0.0455\n",
            "Epoch 436/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0805 - val_loss: 0.0453\n",
            "Epoch 437/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0803 - val_loss: 0.0410\n",
            "Epoch 438/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0796 - val_loss: 0.0399\n",
            "Epoch 439/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0794 - val_loss: 0.0373\n",
            "Epoch 440/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0789 - val_loss: 0.0385\n",
            "Epoch 441/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0784 - val_loss: 0.0433\n",
            "Epoch 442/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0784 - val_loss: 0.0406\n",
            "Epoch 443/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0780 - val_loss: 0.0465\n",
            "Epoch 444/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0774 - val_loss: 0.0424\n",
            "Epoch 445/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0768 - val_loss: 0.0402\n",
            "Epoch 446/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0765 - val_loss: 0.0417\n",
            "Epoch 447/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0763 - val_loss: 0.0358\n",
            "Epoch 448/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0755 - val_loss: 0.0354\n",
            "Epoch 449/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0751 - val_loss: 0.0378\n",
            "Epoch 450/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0749 - val_loss: 0.0398\n",
            "Epoch 451/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0747 - val_loss: 0.0359\n",
            "Epoch 452/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0740 - val_loss: 0.0367\n",
            "Epoch 453/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0736 - val_loss: 0.0378\n",
            "Epoch 454/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0732 - val_loss: 0.0383\n",
            "Epoch 455/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0731 - val_loss: 0.0332\n",
            "Epoch 456/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0725 - val_loss: 0.0317\n",
            "Epoch 457/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0721 - val_loss: 0.0349\n",
            "Epoch 458/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0717 - val_loss: 0.0327\n",
            "Epoch 459/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0712 - val_loss: 0.0327\n",
            "Epoch 460/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0708 - val_loss: 0.0326\n",
            "Epoch 461/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0705 - val_loss: 0.0335\n",
            "Epoch 462/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0702 - val_loss: 0.0318\n",
            "Epoch 463/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0700 - val_loss: 0.0290\n",
            "Epoch 464/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0695 - val_loss: 0.0320\n",
            "Epoch 465/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0692 - val_loss: 0.0297\n",
            "Epoch 466/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0686 - val_loss: 0.0304\n",
            "Epoch 467/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0684 - val_loss: 0.0326\n",
            "Epoch 468/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0681 - val_loss: 0.0299\n",
            "Epoch 469/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0676 - val_loss: 0.0281\n",
            "Epoch 470/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0673 - val_loss: 0.0293\n",
            "Epoch 471/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0670 - val_loss: 0.0301\n",
            "Epoch 472/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0668 - val_loss: 0.0264\n",
            "Epoch 473/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0662 - val_loss: 0.0271\n",
            "Epoch 474/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0659 - val_loss: 0.0258\n",
            "Epoch 475/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0655 - val_loss: 0.0276\n",
            "Epoch 476/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0651 - val_loss: 0.0280\n",
            "Epoch 477/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0651 - val_loss: 0.0290\n",
            "Epoch 478/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0644 - val_loss: 0.0269\n",
            "Epoch 479/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0642 - val_loss: 0.0236\n",
            "Epoch 480/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0638 - val_loss: 0.0234\n",
            "Epoch 481/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0635 - val_loss: 0.0219\n",
            "Epoch 482/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0632 - val_loss: 0.0225\n",
            "Epoch 483/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0627 - val_loss: 0.0225\n",
            "Epoch 484/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0627 - val_loss: 0.0239\n",
            "Epoch 485/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0623 - val_loss: 0.0229\n",
            "Epoch 486/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0618 - val_loss: 0.0233\n",
            "Epoch 487/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0616 - val_loss: 0.0222\n",
            "Epoch 488/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0614 - val_loss: 0.0240\n",
            "Epoch 489/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0610 - val_loss: 0.0227\n",
            "Epoch 490/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0608 - val_loss: 0.0246\n",
            "Epoch 491/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0602 - val_loss: 0.0221\n",
            "Epoch 492/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0601 - val_loss: 0.0199\n",
            "Epoch 493/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0597 - val_loss: 0.0197\n",
            "Epoch 494/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0594 - val_loss: 0.0211\n",
            "Epoch 495/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0594 - val_loss: 0.0226\n",
            "Epoch 496/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0587 - val_loss: 0.0205\n",
            "Epoch 497/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0586 - val_loss: 0.0183\n",
            "Epoch 498/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0582 - val_loss: 0.0188\n",
            "Epoch 499/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0578 - val_loss: 0.0188\n",
            "Epoch 500/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0575 - val_loss: 0.0185\n",
            "Epoch 501/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0573 - val_loss: 0.0178\n",
            "Epoch 502/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0569 - val_loss: 0.0192\n",
            "Epoch 503/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0566 - val_loss: 0.0195\n",
            "Epoch 504/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0564 - val_loss: 0.0205\n",
            "Epoch 505/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0560 - val_loss: 0.0200\n",
            "Epoch 506/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0557 - val_loss: 0.0189\n",
            "Epoch 507/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0555 - val_loss: 0.0182\n",
            "Epoch 508/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0551 - val_loss: 0.0183\n",
            "Epoch 509/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0549 - val_loss: 0.0179\n",
            "Epoch 510/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0548 - val_loss: 0.0174\n",
            "Epoch 511/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0545 - val_loss: 0.0185\n",
            "Epoch 512/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0542 - val_loss: 0.0186\n",
            "Epoch 513/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0537 - val_loss: 0.0180\n",
            "Epoch 514/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0535 - val_loss: 0.0180\n",
            "Epoch 515/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0532 - val_loss: 0.0183\n",
            "Epoch 516/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0530 - val_loss: 0.0180\n",
            "Epoch 517/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0527 - val_loss: 0.0176\n",
            "Epoch 518/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0524 - val_loss: 0.0176\n",
            "Epoch 519/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0521 - val_loss: 0.0175\n",
            "Epoch 520/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0518 - val_loss: 0.0176\n",
            "Epoch 521/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0517 - val_loss: 0.0177\n",
            "Epoch 522/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0513 - val_loss: 0.0175\n",
            "Epoch 523/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0511 - val_loss: 0.0178\n",
            "Epoch 524/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0509 - val_loss: 0.0175\n",
            "Epoch 525/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0506 - val_loss: 0.0179\n",
            "Epoch 526/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0503 - val_loss: 0.0186\n",
            "Epoch 527/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0504 - val_loss: 0.0183\n",
            "Epoch 528/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0499 - val_loss: 0.0186\n",
            "Epoch 529/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0496 - val_loss: 0.0181\n",
            "Epoch 530/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0493 - val_loss: 0.0181\n",
            "Epoch 531/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0490 - val_loss: 0.0183\n",
            "Epoch 532/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0488 - val_loss: 0.0187\n",
            "Epoch 533/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0486 - val_loss: 0.0186\n",
            "Epoch 534/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0484 - val_loss: 0.0187\n",
            "Epoch 535/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0480 - val_loss: 0.0187\n",
            "Epoch 536/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0477 - val_loss: 0.0195\n",
            "Epoch 537/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0476 - val_loss: 0.0199\n",
            "Epoch 538/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0473 - val_loss: 0.0196\n",
            "Epoch 539/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0470 - val_loss: 0.0199\n",
            "Epoch 540/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0468 - val_loss: 0.0198\n",
            "Epoch 541/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0467 - val_loss: 0.0201\n",
            "Epoch 542/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0463 - val_loss: 0.0201\n",
            "Epoch 543/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0462 - val_loss: 0.0201\n",
            "Epoch 544/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0459 - val_loss: 0.0205\n",
            "Epoch 545/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0459 - val_loss: 0.0207\n",
            "Epoch 546/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0455 - val_loss: 0.0208\n",
            "Epoch 547/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0453 - val_loss: 0.0215\n",
            "Epoch 548/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0450 - val_loss: 0.0227\n",
            "Epoch 549/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0449 - val_loss: 0.0232\n",
            "Epoch 550/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0445 - val_loss: 0.0230\n",
            "Epoch 551/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0443 - val_loss: 0.0225\n",
            "Epoch 552/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0441 - val_loss: 0.0225\n",
            "Epoch 553/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0440 - val_loss: 0.0225\n",
            "Epoch 554/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0436 - val_loss: 0.0235\n",
            "Epoch 555/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0435 - val_loss: 0.0243\n",
            "Epoch 556/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0432 - val_loss: 0.0247\n",
            "Epoch 557/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0430 - val_loss: 0.0255\n",
            "Epoch 558/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0428 - val_loss: 0.0250\n",
            "Epoch 559/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0426 - val_loss: 0.0251\n",
            "Epoch 560/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0424 - val_loss: 0.0254\n",
            "Epoch 561/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0422 - val_loss: 0.0251\n",
            "Epoch 562/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0419 - val_loss: 0.0253\n",
            "Epoch 563/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0418 - val_loss: 0.0264\n",
            "Epoch 564/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0416 - val_loss: 0.0267\n",
            "Epoch 565/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0414 - val_loss: 0.0281\n",
            "Epoch 566/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0412 - val_loss: 0.0291\n",
            "Epoch 567/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0409 - val_loss: 0.0287\n",
            "Epoch 568/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0408 - val_loss: 0.0289\n",
            "Epoch 569/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0406 - val_loss: 0.0285\n",
            "Epoch 570/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0403 - val_loss: 0.0283\n",
            "Epoch 571/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0402 - val_loss: 0.0295\n",
            "Epoch 572/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0400 - val_loss: 0.0307\n",
            "Epoch 573/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0398 - val_loss: 0.0308\n",
            "Epoch 574/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0395 - val_loss: 0.0303\n",
            "Epoch 575/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0394 - val_loss: 0.0306\n",
            "Epoch 576/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0392 - val_loss: 0.0321\n",
            "Epoch 577/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0391 - val_loss: 0.0334\n",
            "Epoch 578/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0388 - val_loss: 0.0331\n",
            "Epoch 579/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0386 - val_loss: 0.0332\n",
            "Epoch 580/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0386 - val_loss: 0.0329\n",
            "Epoch 581/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0382 - val_loss: 0.0352\n",
            "Epoch 582/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0381 - val_loss: 0.0358\n",
            "Epoch 583/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0379 - val_loss: 0.0377\n",
            "Epoch 584/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0377 - val_loss: 0.0378\n",
            "Epoch 585/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0375 - val_loss: 0.0365\n",
            "Epoch 586/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0374 - val_loss: 0.0361\n",
            "Epoch 587/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0372 - val_loss: 0.0351\n",
            "Epoch 588/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0370 - val_loss: 0.0368\n",
            "Epoch 589/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0370 - val_loss: 0.0402\n",
            "Epoch 590/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0367 - val_loss: 0.0383\n",
            "Epoch 591/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0365 - val_loss: 0.0404\n",
            "Epoch 592/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0364 - val_loss: 0.0410\n",
            "Epoch 593/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0361 - val_loss: 0.0402\n",
            "Epoch 594/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0360 - val_loss: 0.0411\n",
            "Epoch 595/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0358 - val_loss: 0.0415\n",
            "Epoch 596/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0356 - val_loss: 0.0419\n",
            "Epoch 597/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0355 - val_loss: 0.0432\n",
            "Epoch 598/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0353 - val_loss: 0.0441\n",
            "Epoch 599/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0351 - val_loss: 0.0447\n",
            "Epoch 600/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0349 - val_loss: 0.0462\n",
            "Epoch 601/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0348 - val_loss: 0.0464\n",
            "Epoch 602/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0348 - val_loss: 0.0441\n",
            "Epoch 603/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0347 - val_loss: 0.0483\n",
            "Epoch 604/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0343 - val_loss: 0.0478\n",
            "Epoch 605/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0342 - val_loss: 0.0480\n",
            "Epoch 606/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0341 - val_loss: 0.0466\n",
            "Epoch 607/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0339 - val_loss: 0.0468\n",
            "Epoch 608/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0337 - val_loss: 0.0488\n",
            "Epoch 609/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0335 - val_loss: 0.0505\n",
            "Epoch 610/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0334 - val_loss: 0.0529\n",
            "Epoch 611/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0332 - val_loss: 0.0543\n",
            "Epoch 612/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0332 - val_loss: 0.0546\n",
            "Epoch 613/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0330 - val_loss: 0.0545\n",
            "Epoch 614/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0328 - val_loss: 0.0522\n",
            "Epoch 615/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0326 - val_loss: 0.0526\n",
            "Epoch 616/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0326 - val_loss: 0.0505\n",
            "Epoch 617/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0325 - val_loss: 0.0522\n",
            "Epoch 618/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0323 - val_loss: 0.0537\n",
            "Epoch 619/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0322 - val_loss: 0.0605\n",
            "Epoch 620/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0320 - val_loss: 0.0628\n",
            "Epoch 621/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0319 - val_loss: 0.0617\n",
            "Epoch 622/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0318 - val_loss: 0.0554\n",
            "Epoch 623/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0315 - val_loss: 0.0564\n",
            "Epoch 624/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0315 - val_loss: 0.0562\n",
            "Epoch 625/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0313 - val_loss: 0.0577\n",
            "Epoch 626/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0311 - val_loss: 0.0632\n",
            "Epoch 627/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0310 - val_loss: 0.0672\n",
            "Epoch 628/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0309 - val_loss: 0.0678\n",
            "Epoch 629/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0307 - val_loss: 0.0650\n",
            "Epoch 630/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0305 - val_loss: 0.0618\n",
            "Epoch 631/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0305 - val_loss: 0.0614\n",
            "Epoch 632/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0304 - val_loss: 0.0622\n",
            "Epoch 633/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0303 - val_loss: 0.0609\n",
            "Epoch 634/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0301 - val_loss: 0.0640\n",
            "Epoch 635/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0299 - val_loss: 0.0695\n",
            "Epoch 636/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0298 - val_loss: 0.0719\n",
            "Epoch 637/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0297 - val_loss: 0.0727\n",
            "Epoch 638/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0296 - val_loss: 0.0703\n",
            "Epoch 639/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0295 - val_loss: 0.0665\n",
            "Epoch 640/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0293 - val_loss: 0.0684\n",
            "Epoch 641/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0292 - val_loss: 0.0721\n",
            "Epoch 642/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0291 - val_loss: 0.0717\n",
            "Epoch 643/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0291 - val_loss: 0.0749\n",
            "Epoch 644/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0288 - val_loss: 0.0750\n",
            "Epoch 645/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0287 - val_loss: 0.0713\n",
            "Epoch 646/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0286 - val_loss: 0.0725\n",
            "Epoch 647/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0284 - val_loss: 0.0753\n",
            "Epoch 648/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0283 - val_loss: 0.0765\n",
            "Epoch 649/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0282 - val_loss: 0.0759\n",
            "Epoch 650/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0281 - val_loss: 0.0782\n",
            "Epoch 651/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0279 - val_loss: 0.0756\n",
            "Epoch 652/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0280 - val_loss: 0.0734\n",
            "Epoch 653/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0279 - val_loss: 0.0758\n",
            "Epoch 654/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0276 - val_loss: 0.0838\n",
            "Epoch 655/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0276 - val_loss: 0.0855\n",
            "Epoch 656/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0274 - val_loss: 0.0840\n",
            "Epoch 657/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0273 - val_loss: 0.0832\n",
            "Epoch 658/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0272 - val_loss: 0.0811\n",
            "Epoch 659/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0271 - val_loss: 0.0819\n",
            "Epoch 660/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0270 - val_loss: 0.0816\n",
            "Epoch 661/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0268 - val_loss: 0.0812\n",
            "Epoch 662/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0268 - val_loss: 0.0831\n",
            "Epoch 663/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0267 - val_loss: 0.0837\n",
            "Epoch 664/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0265 - val_loss: 0.0890\n",
            "Epoch 665/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.0941\n",
            "Epoch 666/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0880\n",
            "Epoch 667/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0850\n",
            "Epoch 668/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0262 - val_loss: 0.0833\n",
            "Epoch 669/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0888\n",
            "Epoch 670/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0259 - val_loss: 0.0920\n",
            "Epoch 671/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0917\n",
            "Epoch 672/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0257 - val_loss: 0.0914\n",
            "Epoch 673/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0256 - val_loss: 0.0893\n",
            "Epoch 674/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0257 - val_loss: 0.0971\n",
            "Epoch 675/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.0997\n",
            "Epoch 676/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0254 - val_loss: 0.0912\n",
            "Epoch 677/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0253 - val_loss: 0.0874\n",
            "Epoch 678/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0252 - val_loss: 0.0884\n",
            "Epoch 679/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0953\n",
            "Epoch 680/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.1001\n",
            "Epoch 681/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.1022\n",
            "Epoch 682/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0249 - val_loss: 0.0981\n",
            "Epoch 683/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0972\n",
            "Epoch 684/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0980\n",
            "Epoch 685/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0245 - val_loss: 0.0971\n",
            "Epoch 686/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.1022\n",
            "Epoch 687/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.1033\n",
            "Epoch 688/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 0.1060\n",
            "Epoch 689/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.1034\n",
            "Epoch 690/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0241 - val_loss: 0.1058\n",
            "Epoch 691/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.0992\n",
            "Epoch 692/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0239 - val_loss: 0.1004\n",
            "Epoch 693/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0238 - val_loss: 0.1045\n",
            "Epoch 694/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.1011\n",
            "Epoch 695/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0236 - val_loss: 0.1043\n",
            "Epoch 696/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0235 - val_loss: 0.1081\n",
            "Epoch 697/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0234 - val_loss: 0.1100\n",
            "Epoch 698/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.1125\n",
            "Epoch 699/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0233 - val_loss: 0.1089\n",
            "Epoch 700/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.1111\n",
            "Epoch 701/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.1104\n",
            "Epoch 702/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0231 - val_loss: 0.1110\n",
            "Epoch 703/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.1045\n",
            "Epoch 704/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0229 - val_loss: 0.1086\n",
            "Epoch 705/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.1155\n",
            "Epoch 706/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.1116\n",
            "Epoch 707/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0227 - val_loss: 0.1081\n",
            "Epoch 708/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0228 - val_loss: 0.1197\n",
            "Epoch 709/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.1154\n",
            "Epoch 710/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0225 - val_loss: 0.1156\n",
            "Epoch 711/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0223 - val_loss: 0.1120\n",
            "Epoch 712/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.1157\n",
            "Epoch 713/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.1161\n",
            "Epoch 714/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.1155\n",
            "Epoch 715/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0221 - val_loss: 0.1132\n",
            "Epoch 716/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.1211\n",
            "Epoch 717/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.1206\n",
            "Epoch 718/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0219 - val_loss: 0.1228\n",
            "Epoch 719/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0218 - val_loss: 0.1234\n",
            "Epoch 720/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.1194\n",
            "Epoch 721/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.1164\n",
            "Epoch 722/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.1109\n",
            "Epoch 723/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.1192\n",
            "Epoch 724/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.1266\n",
            "Epoch 725/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.1350\n",
            "Epoch 726/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0214 - val_loss: 0.1214\n",
            "Epoch 727/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.1202\n",
            "Epoch 728/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0211 - val_loss: 0.1218\n",
            "Epoch 729/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.1224\n",
            "Epoch 730/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0210 - val_loss: 0.1215\n",
            "Epoch 731/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.1276\n",
            "Epoch 732/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.1244\n",
            "Epoch 733/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0208 - val_loss: 0.1295\n",
            "Epoch 734/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.1284\n",
            "Epoch 735/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.1314\n",
            "Epoch 736/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0206 - val_loss: 0.1282\n",
            "Epoch 737/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.1334\n",
            "Epoch 738/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.1362\n",
            "Epoch 739/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.1283\n",
            "Epoch 740/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.1236\n",
            "Epoch 741/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.1262\n",
            "Epoch 742/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0202 - val_loss: 0.1290\n",
            "Epoch 743/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.1279\n",
            "Epoch 744/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.1373\n",
            "Epoch 745/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0200 - val_loss: 0.1336\n",
            "Epoch 746/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0199 - val_loss: 0.1359\n",
            "Epoch 747/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.1408\n",
            "Epoch 748/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.1336\n",
            "Epoch 749/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.1275\n",
            "Epoch 750/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.1310\n",
            "Epoch 751/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0196 - val_loss: 0.1350\n",
            "Epoch 752/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.1339\n",
            "Epoch 753/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0195 - val_loss: 0.1388\n",
            "Epoch 754/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.1417\n",
            "Epoch 755/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.1364\n",
            "Epoch 756/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.1351\n",
            "Epoch 757/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.1310\n",
            "Epoch 758/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.1350\n",
            "Epoch 759/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.1403\n",
            "Epoch 760/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.1395\n",
            "Epoch 761/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.1408\n",
            "Epoch 762/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.1475\n",
            "Epoch 763/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.1520\n",
            "Epoch 764/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.1328\n",
            "Epoch 765/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.1244\n",
            "Epoch 766/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.1434\n",
            "Epoch 767/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.1538\n",
            "Epoch 768/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0188 - val_loss: 0.1451\n",
            "Epoch 769/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.1418\n",
            "Epoch 770/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.1434\n",
            "Epoch 771/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.1361\n",
            "Epoch 772/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.1465\n",
            "Epoch 773/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0185 - val_loss: 0.1504\n",
            "Epoch 774/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.1436\n",
            "Epoch 775/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.1352\n",
            "Epoch 776/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.1361\n",
            "Epoch 777/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0182 - val_loss: 0.1434\n",
            "Epoch 778/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.1560\n",
            "Epoch 779/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0183 - val_loss: 0.1581\n",
            "Epoch 780/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.1495\n",
            "Epoch 781/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.1371\n",
            "Epoch 782/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.1364\n",
            "Epoch 783/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0179 - val_loss: 0.1436\n",
            "Epoch 784/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.1504\n",
            "Epoch 785/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.1497\n",
            "Epoch 786/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0178 - val_loss: 0.1515\n",
            "Epoch 787/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.1580\n",
            "Epoch 788/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.1540\n",
            "Epoch 789/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.1460\n",
            "Epoch 790/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.1376\n",
            "Epoch 791/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.1397\n",
            "Epoch 792/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.1461\n",
            "Epoch 793/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.1543\n",
            "Epoch 794/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.1611\n",
            "Epoch 795/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.1624\n",
            "Epoch 796/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.1484\n",
            "Epoch 797/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.1461\n",
            "Epoch 798/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.1454\n",
            "Epoch 799/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.1415\n",
            "Epoch 800/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.1557\n",
            "Epoch 801/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.1549\n",
            "Epoch 802/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.1591\n",
            "Epoch 803/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.1615\n",
            "Epoch 804/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.1534\n",
            "Epoch 805/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.1427\n",
            "Epoch 806/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.1498\n",
            "Epoch 807/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.1541\n",
            "Epoch 808/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0167 - val_loss: 0.1588\n",
            "Epoch 809/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.1583\n",
            "Epoch 810/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.1611\n",
            "Epoch 811/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.1522\n",
            "Epoch 812/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.1472\n",
            "Epoch 813/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0165 - val_loss: 0.1500\n",
            "Epoch 814/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.1572\n",
            "Epoch 815/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.1630\n",
            "Epoch 816/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.1666\n",
            "Epoch 817/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.1569\n",
            "Epoch 818/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.1520\n",
            "Epoch 819/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.1445\n",
            "Epoch 820/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.1544\n",
            "Epoch 821/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.1638\n",
            "Epoch 822/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.1655\n",
            "Epoch 823/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.1520\n",
            "Epoch 824/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.1579\n",
            "Epoch 825/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.1724\n",
            "Epoch 826/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.1616\n",
            "Epoch 827/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.1465\n",
            "Epoch 828/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0160 - val_loss: 0.1567\n",
            "Epoch 829/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.1609\n",
            "Epoch 830/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.1536\n",
            "Epoch 831/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.1620\n",
            "Epoch 832/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.1613\n",
            "Epoch 833/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.1635\n",
            "Epoch 834/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0157 - val_loss: 0.1616\n",
            "Epoch 835/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.1523\n",
            "Epoch 836/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.1518\n",
            "Epoch 837/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.1417\n",
            "Epoch 838/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.1567\n",
            "Epoch 839/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.1737\n",
            "Epoch 840/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.1675\n",
            "Epoch 841/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.1661\n",
            "Epoch 842/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.1560\n",
            "Epoch 843/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.1493\n",
            "Epoch 844/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.1580\n",
            "Epoch 845/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.1623\n",
            "Epoch 846/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.1635\n",
            "Epoch 847/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.1627\n",
            "Epoch 848/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.1473\n",
            "Epoch 849/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.1492\n",
            "Epoch 850/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.1562\n",
            "Epoch 851/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.1698\n",
            "Epoch 852/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.1783\n",
            "Epoch 853/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.1548\n",
            "Epoch 854/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.1559\n",
            "Epoch 855/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.1602\n",
            "Epoch 856/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.1669\n",
            "Epoch 857/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.1598\n",
            "Epoch 858/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.1586\n",
            "Epoch 859/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.1522\n",
            "Epoch 860/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0149 - val_loss: 0.1673\n",
            "Epoch 861/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.1609\n",
            "Epoch 862/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 0.1571\n",
            "Epoch 863/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.1557\n",
            "Epoch 864/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.1514\n",
            "Epoch 865/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.1607\n",
            "Epoch 866/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0144 - val_loss: 0.1678\n",
            "Epoch 867/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.1747\n",
            "Epoch 868/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 0.1594\n",
            "Epoch 869/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.1527\n",
            "Epoch 870/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.1522\n",
            "Epoch 871/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.1720\n",
            "Epoch 872/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 0.1688\n",
            "Epoch 873/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.1629\n",
            "Epoch 874/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.1538\n",
            "Epoch 875/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.1631\n",
            "Epoch 876/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.1683\n",
            "Epoch 877/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.1525\n",
            "Epoch 878/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.1575\n",
            "Epoch 879/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.1618\n",
            "Epoch 880/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.1616\n",
            "Epoch 881/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.1570\n",
            "Epoch 882/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.1570\n",
            "Epoch 883/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.1581\n",
            "Epoch 884/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.1628\n",
            "Epoch 885/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.1538\n",
            "Epoch 886/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.1712\n",
            "Epoch 887/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.1764\n",
            "Epoch 888/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.1584\n",
            "Epoch 889/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.1439\n",
            "Epoch 890/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 0.1468\n",
            "Epoch 891/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.1716\n",
            "Epoch 892/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.1758\n",
            "Epoch 893/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.1586\n",
            "Epoch 894/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.1489\n",
            "Epoch 895/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.1524\n",
            "Epoch 896/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.1531\n",
            "Epoch 897/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.1625\n",
            "Epoch 898/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.1730\n",
            "Epoch 899/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.1648\n",
            "Epoch 900/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.1553\n",
            "Epoch 901/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.1427\n",
            "Epoch 902/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.1514\n",
            "Epoch 903/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.1717\n",
            "Epoch 904/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.1681\n",
            "Epoch 905/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.1515\n",
            "Epoch 906/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.1535\n",
            "Epoch 907/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.1531\n",
            "Epoch 908/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.1580\n",
            "Epoch 909/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.1519\n",
            "Epoch 910/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.1609\n",
            "Epoch 911/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.1649\n",
            "Epoch 912/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.1626\n",
            "Epoch 913/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.1692\n",
            "Epoch 914/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.1662\n",
            "Epoch 915/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.1532\n",
            "Epoch 916/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.1414\n",
            "Epoch 917/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.1585\n",
            "Epoch 918/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.1545\n",
            "Epoch 919/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.1594\n",
            "Epoch 920/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.1630\n",
            "Epoch 921/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.1565\n",
            "Epoch 922/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.1480\n",
            "Epoch 923/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.1509\n",
            "Epoch 924/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0127 - val_loss: 0.1679\n",
            "Epoch 925/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.1733\n",
            "Epoch 926/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.1449\n",
            "Epoch 927/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.1383\n",
            "Epoch 928/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.1461\n",
            "Epoch 929/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.1725\n",
            "Epoch 930/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.1567\n",
            "Epoch 931/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.1514\n",
            "Epoch 932/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.1480\n",
            "Epoch 933/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.1567\n",
            "Epoch 934/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0124 - val_loss: 0.1656\n",
            "Epoch 935/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.1489\n",
            "Epoch 936/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.1454\n",
            "Epoch 937/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.1558\n",
            "Epoch 938/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.1584\n",
            "Epoch 939/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.1603\n",
            "Epoch 940/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.1529\n",
            "Epoch 941/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.1512\n",
            "Epoch 942/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.1455\n",
            "Epoch 943/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.1456\n",
            "Epoch 944/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.1654\n",
            "Epoch 945/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.1694\n",
            "Epoch 946/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.1383\n",
            "Epoch 947/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.1285\n",
            "Epoch 948/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.1645\n",
            "Epoch 949/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.1633\n",
            "Epoch 950/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.1642\n",
            "Epoch 951/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.1458\n",
            "Epoch 952/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.1457\n",
            "Epoch 953/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.1316\n",
            "Epoch 954/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.1454\n",
            "Epoch 955/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.1448\n",
            "Epoch 956/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.1580\n",
            "Epoch 957/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.1659\n",
            "Epoch 958/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.1628\n",
            "Epoch 959/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.1380\n",
            "Epoch 960/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.1389\n",
            "Epoch 961/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.1427\n",
            "Epoch 962/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.1471\n",
            "Epoch 963/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.1463\n",
            "Epoch 964/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.1496\n",
            "Epoch 965/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.1561\n",
            "Epoch 966/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.1459\n",
            "Epoch 967/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.1336\n",
            "Epoch 968/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.1369\n",
            "Epoch 969/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.1570\n",
            "Epoch 970/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.1533\n",
            "Epoch 971/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.1535\n",
            "Epoch 972/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.1358\n",
            "Epoch 973/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.1393\n",
            "Epoch 974/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.1410\n",
            "Epoch 975/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.1458\n",
            "Epoch 976/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.1479\n",
            "Epoch 977/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.1356\n",
            "Epoch 978/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.1481\n",
            "Epoch 979/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.1568\n",
            "Epoch 980/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.1440\n",
            "Epoch 981/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.1315\n",
            "Epoch 982/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.1451\n",
            "Epoch 983/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.1574\n",
            "Epoch 984/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.1494\n",
            "Epoch 985/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.1398\n",
            "Epoch 986/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.1406\n",
            "Epoch 987/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.1322\n",
            "Epoch 988/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.1479\n",
            "Epoch 989/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.1395\n",
            "Epoch 990/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.1370\n",
            "Epoch 991/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.1426\n",
            "Epoch 992/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.1342\n",
            "Epoch 993/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.1300\n",
            "Epoch 994/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.1426\n",
            "Epoch 995/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.1571\n",
            "Epoch 996/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.1542\n",
            "Epoch 997/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.1295\n",
            "Epoch 998/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.1294\n",
            "Epoch 999/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.1375\n",
            "Epoch 1000/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.1446\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7080248d50>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the model is trained we can make predictions on the test data:"
      ],
      "metadata": {
        "id": "H2tUPxfjTpFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = array([10])\n",
        "test_input = test_input.reshape((1, 1, 1))\n",
        "test_output = model.predict(test_input, verbose=0)\n",
        "print(test_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9hDRXvvuzrO",
        "outputId": "be02b5b5-d395-4ab2-c6b0-efc47177e322"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[11.069507 12.115809]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test data contains a value 10. In the output, we should get a vector containing 11 and 12. The output I received is [11.047798 12.01309 ] which is actually very close to the expected output."
      ],
      "metadata": {
        "id": "x0zGypfsTpFD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SQH5h6vGUKFw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. RNN - One-to-one**"
      ],
      "metadata": {
        "id": "sbZaBLq5xh5l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> In this section, we will see how to solve one-to-one sequence problem where each time-step has a single feature."
      ],
      "metadata": {
        "id": "2OHv6xyt4wfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten, LSTM\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Input\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.layers import Bidirectional\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "5zQUBr21UKfr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating the Dataset**\n",
        "\n",
        "In this next step, we will prepare the dataset that we are going to use for this section."
      ],
      "metadata": {
        "id": "DRt4Sekm42Jd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the script above, we create 20 inputs and 20 outputs. Each input consists of one time-step, which in turn contains a single feature. Each output value is 15 times the corresponding input value. If you run the above script, you should see the input and output values as shown below:"
      ],
      "metadata": {
        "id": "rqRjFz7p5AtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = list()\n",
        "Y = list()\n",
        "X = [x+1 for x in range(20)]\n",
        "Y = [y * 15 for y in X]\n",
        "\n",
        "print(X)\n",
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLy9m1ROxnip",
        "outputId": "b02f93e9-4b0a-42ee-c575-bf839e04c683"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "[15, 30, 45, 60, 75, 90, 105, 120, 135, 150, 165, 180, 195, 210, 225, 240, 255, 270, 285, 300]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The input to LSTM layer should be in 3D shape i.e. (samples, time-steps, features). The samples are the number of samples in the input data. We have 20 samples in the input. The time-steps is the number of time-steps per sample. We have 1 time-step. Finally, features correspond to the number of features per time-step. We have one feature per time-step.\n",
        "\n",
        "We can reshape our data via the following command:"
      ],
      "metadata": {
        "id": "EJzK_ppw5ENd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X).reshape(20, 1, 1)\n",
        "Y = np.array(Y)"
      ],
      "metadata": {
        "id": "JPmbF7udxtrd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution via Simple LSTM**\n",
        "\n",
        "Now we can create our simple LSTM model with one LSTM layer.\n",
        "\n"
      ],
      "metadata": {
        "id": "BdlRdvp8xwtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(1, 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3fJ7pF8xxCE",
        "outputId": "4e84be3a-11a1-4074-c566-9534a30d7cde"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_1 (LSTM)               (None, 50)                10400     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,451\n",
            "Trainable params: 10,451\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the script above, we create an LSTM model with one LSTM layer of 50 neurons and relu activation functions. You can see the input shape is (1,1) since our data has one time-step with one feature. Executing the above script prints the following summary:"
      ],
      "metadata": {
        "id": "t2gTdw9gx3Qa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now train our model:"
      ],
      "metadata": {
        "id": "NWZiizYnx6A1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, Y, epochs=2000, validation_split=0.2, batch_size=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTtMUI27x69G",
        "outputId": "5ee2d48d-1b5b-4af2-a060-9444b88bb019"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "4/4 [==============================] - 1s 105ms/step - loss: 20984.3379 - val_loss: 76944.0312\n",
            "Epoch 2/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 20952.6406 - val_loss: 76815.7344\n",
            "Epoch 3/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 20913.6016 - val_loss: 76696.1797\n",
            "Epoch 4/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 20886.2441 - val_loss: 76566.0391\n",
            "Epoch 5/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 20848.8301 - val_loss: 76438.7812\n",
            "Epoch 6/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 20814.1426 - val_loss: 76305.0078\n",
            "Epoch 7/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 20777.4355 - val_loss: 76163.1562\n",
            "Epoch 8/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 20735.8203 - val_loss: 76021.9922\n",
            "Epoch 9/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 20701.4199 - val_loss: 75861.6719\n",
            "Epoch 10/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 20655.5781 - val_loss: 75688.7344\n",
            "Epoch 11/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 20609.2090 - val_loss: 75508.7422\n",
            "Epoch 12/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 20562.7559 - val_loss: 75319.2578\n",
            "Epoch 13/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 20515.1523 - val_loss: 75116.4219\n",
            "Epoch 14/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 20459.5840 - val_loss: 74906.7422\n",
            "Epoch 15/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 20401.9922 - val_loss: 74677.3281\n",
            "Epoch 16/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 20343.2266 - val_loss: 74406.1406\n",
            "Epoch 17/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 20272.3008 - val_loss: 74123.3906\n",
            "Epoch 18/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 20204.6250 - val_loss: 73825.6250\n",
            "Epoch 19/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 20121.5566 - val_loss: 73509.6562\n",
            "Epoch 20/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 20045.3008 - val_loss: 73146.0312\n",
            "Epoch 21/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 19955.7090 - val_loss: 72761.1719\n",
            "Epoch 22/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 19871.8359 - val_loss: 72355.3516\n",
            "Epoch 23/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 19747.7793 - val_loss: 71950.4922\n",
            "Epoch 24/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 19649.3770 - val_loss: 71479.6250\n",
            "Epoch 25/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 19538.6699 - val_loss: 71001.7969\n",
            "Epoch 26/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 19429.6914 - val_loss: 70487.8281\n",
            "Epoch 27/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 19298.6641 - val_loss: 69945.9375\n",
            "Epoch 28/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 19161.7344 - val_loss: 69395.0938\n",
            "Epoch 29/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 19035.7168 - val_loss: 68812.2344\n",
            "Epoch 30/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 18893.2598 - val_loss: 68224.8281\n",
            "Epoch 31/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 18739.9180 - val_loss: 67622.4844\n",
            "Epoch 32/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 18584.9785 - val_loss: 66977.0312\n",
            "Epoch 33/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 18424.3730 - val_loss: 66286.9844\n",
            "Epoch 34/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 18252.0938 - val_loss: 65601.3594\n",
            "Epoch 35/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 18080.0312 - val_loss: 64904.1328\n",
            "Epoch 36/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 17921.8398 - val_loss: 64148.3555\n",
            "Epoch 37/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 17717.7188 - val_loss: 63407.2070\n",
            "Epoch 38/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 17521.0059 - val_loss: 62673.8320\n",
            "Epoch 39/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 17349.3887 - val_loss: 61900.8281\n",
            "Epoch 40/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 17149.0586 - val_loss: 61114.3164\n",
            "Epoch 41/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 16919.7402 - val_loss: 60286.0000\n",
            "Epoch 42/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 16706.8164 - val_loss: 59414.9297\n",
            "Epoch 43/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 16481.3125 - val_loss: 58501.2031\n",
            "Epoch 44/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 16243.0518 - val_loss: 57614.6445\n",
            "Epoch 45/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 16006.1201 - val_loss: 56705.2383\n",
            "Epoch 46/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 15767.9561 - val_loss: 55827.3594\n",
            "Epoch 47/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 15518.0469 - val_loss: 54940.2266\n",
            "Epoch 48/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 15283.5918 - val_loss: 54097.7188\n",
            "Epoch 49/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 15060.0938 - val_loss: 53274.8320\n",
            "Epoch 50/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 14841.8965 - val_loss: 52445.4766\n",
            "Epoch 51/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 14591.9531 - val_loss: 51628.9414\n",
            "Epoch 52/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 14376.1787 - val_loss: 50747.2109\n",
            "Epoch 53/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 14117.9316 - val_loss: 49857.4688\n",
            "Epoch 54/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 13895.2207 - val_loss: 48916.6094\n",
            "Epoch 55/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 13626.0615 - val_loss: 48028.4297\n",
            "Epoch 56/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 13381.2178 - val_loss: 47151.4688\n",
            "Epoch 57/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 13113.4111 - val_loss: 46265.8984\n",
            "Epoch 58/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 12869.8350 - val_loss: 45342.5391\n",
            "Epoch 59/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 12613.2246 - val_loss: 44445.6953\n",
            "Epoch 60/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 12370.8770 - val_loss: 43510.9297\n",
            "Epoch 61/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 12110.8691 - val_loss: 42649.3047\n",
            "Epoch 62/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 11877.1611 - val_loss: 41811.6719\n",
            "Epoch 63/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 11619.5850 - val_loss: 40971.2148\n",
            "Epoch 64/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 11399.9434 - val_loss: 40079.7812\n",
            "Epoch 65/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 11133.5469 - val_loss: 39186.7188\n",
            "Epoch 66/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 10873.8047 - val_loss: 38278.8203\n",
            "Epoch 67/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 10633.5088 - val_loss: 37359.3125\n",
            "Epoch 68/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 10372.9150 - val_loss: 36496.2656\n",
            "Epoch 69/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 10125.1777 - val_loss: 35685.1250\n",
            "Epoch 70/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 9900.9033 - val_loss: 34854.0156\n",
            "Epoch 71/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 9651.6748 - val_loss: 34026.2461\n",
            "Epoch 72/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 9426.9492 - val_loss: 33149.9688\n",
            "Epoch 73/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 9166.3916 - val_loss: 32272.9551\n",
            "Epoch 74/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 8928.4648 - val_loss: 31364.7910\n",
            "Epoch 75/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 8685.2705 - val_loss: 30505.5977\n",
            "Epoch 76/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 8432.6221 - val_loss: 29711.7695\n",
            "Epoch 77/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 8212.0830 - val_loss: 28942.2266\n",
            "Epoch 78/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 7989.0820 - val_loss: 28131.7617\n",
            "Epoch 79/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 7754.3984 - val_loss: 27305.7422\n",
            "Epoch 80/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 7526.2051 - val_loss: 26478.9531\n",
            "Epoch 81/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 7284.9414 - val_loss: 25723.8203\n",
            "Epoch 82/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 7075.8130 - val_loss: 24952.9688\n",
            "Epoch 83/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 6865.2407 - val_loss: 24130.2539\n",
            "Epoch 84/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 6636.7686 - val_loss: 23362.5898\n",
            "Epoch 85/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 6397.7739 - val_loss: 22657.6406\n",
            "Epoch 86/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 6200.6040 - val_loss: 21918.4727\n",
            "Epoch 87/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 6004.8799 - val_loss: 21130.3027\n",
            "Epoch 88/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 5763.1562 - val_loss: 20354.2812\n",
            "Epoch 89/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 5542.4102 - val_loss: 19579.6504\n",
            "Epoch 90/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5357.7227 - val_loss: 18840.7266\n",
            "Epoch 91/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5142.7686 - val_loss: 18178.2070\n",
            "Epoch 92/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 4974.7852 - val_loss: 17504.9727\n",
            "Epoch 93/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 4769.2891 - val_loss: 16865.6016\n",
            "Epoch 94/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 4604.8169 - val_loss: 16251.4961\n",
            "Epoch 95/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 4436.2979 - val_loss: 15681.7930\n",
            "Epoch 96/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 4285.2720 - val_loss: 15128.5371\n",
            "Epoch 97/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 4119.3994 - val_loss: 14597.7168\n",
            "Epoch 98/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 3967.0125 - val_loss: 14073.7559\n",
            "Epoch 99/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 3825.6584 - val_loss: 13520.4521\n",
            "Epoch 100/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 3680.3379 - val_loss: 12994.3066\n",
            "Epoch 101/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 3533.3325 - val_loss: 12495.5723\n",
            "Epoch 102/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 3376.9990 - val_loss: 12035.9346\n",
            "Epoch 103/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 3255.0420 - val_loss: 11565.4180\n",
            "Epoch 104/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 3119.9255 - val_loss: 11109.3379\n",
            "Epoch 105/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2996.3523 - val_loss: 10667.7305\n",
            "Epoch 106/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2871.7271 - val_loss: 10242.5117\n",
            "Epoch 107/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2758.1982 - val_loss: 9823.6230\n",
            "Epoch 108/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2630.6045 - val_loss: 9411.0957\n",
            "Epoch 109/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2511.0569 - val_loss: 8988.4219\n",
            "Epoch 110/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2403.2915 - val_loss: 8584.8584\n",
            "Epoch 111/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 2283.4824 - val_loss: 8211.0508\n",
            "Epoch 112/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2184.1196 - val_loss: 7832.1587\n",
            "Epoch 113/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2078.7654 - val_loss: 7465.8027\n",
            "Epoch 114/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1972.3223 - val_loss: 7094.8784\n",
            "Epoch 115/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1874.6101 - val_loss: 6713.9858\n",
            "Epoch 116/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1766.0165 - val_loss: 6330.6855\n",
            "Epoch 117/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1661.8890 - val_loss: 5953.1211\n",
            "Epoch 118/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1561.0715 - val_loss: 5600.5361\n",
            "Epoch 119/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1459.5869 - val_loss: 5256.5610\n",
            "Epoch 120/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1369.5896 - val_loss: 4932.1465\n",
            "Epoch 121/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1277.4318 - val_loss: 4635.6934\n",
            "Epoch 122/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1205.4274 - val_loss: 4345.6855\n",
            "Epoch 123/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1118.8617 - val_loss: 4087.5950\n",
            "Epoch 124/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1050.8308 - val_loss: 3854.3994\n",
            "Epoch 125/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 988.5199 - val_loss: 3631.1921\n",
            "Epoch 126/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 929.4954 - val_loss: 3430.5049\n",
            "Epoch 127/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 875.8469 - val_loss: 3246.0486\n",
            "Epoch 128/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 824.4025 - val_loss: 3074.0618\n",
            "Epoch 129/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 777.5934 - val_loss: 2905.2312\n",
            "Epoch 130/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 733.2967 - val_loss: 2737.3516\n",
            "Epoch 131/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 685.2413 - val_loss: 2579.9272\n",
            "Epoch 132/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 642.9703 - val_loss: 2421.6499\n",
            "Epoch 133/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 599.8772 - val_loss: 2261.4390\n",
            "Epoch 134/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 559.1457 - val_loss: 2114.7095\n",
            "Epoch 135/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 520.5109 - val_loss: 1982.9449\n",
            "Epoch 136/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 487.0645 - val_loss: 1862.1196\n",
            "Epoch 137/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 452.3234 - val_loss: 1746.9641\n",
            "Epoch 138/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 419.8004 - val_loss: 1626.8931\n",
            "Epoch 139/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 388.9806 - val_loss: 1508.6538\n",
            "Epoch 140/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 359.3559 - val_loss: 1403.5625\n",
            "Epoch 141/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 331.7855 - val_loss: 1307.2217\n",
            "Epoch 142/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 308.4713 - val_loss: 1217.3352\n",
            "Epoch 143/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 285.6304 - val_loss: 1133.0726\n",
            "Epoch 144/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 262.5088 - val_loss: 1058.4305\n",
            "Epoch 145/2000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 243.2343 - val_loss: 986.6785\n",
            "Epoch 146/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 226.0372 - val_loss: 919.4324\n",
            "Epoch 147/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 209.7563 - val_loss: 859.0428\n",
            "Epoch 148/2000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 193.2223 - val_loss: 806.2954\n",
            "Epoch 149/2000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 180.6920 - val_loss: 756.4694\n",
            "Epoch 150/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 167.7995 - val_loss: 708.3777\n",
            "Epoch 151/2000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 155.6999 - val_loss: 657.6033\n",
            "Epoch 152/2000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 143.3824 - val_loss: 612.8885\n",
            "Epoch 153/2000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 131.9002 - val_loss: 572.9614\n",
            "Epoch 154/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 121.8349 - val_loss: 534.6483\n",
            "Epoch 155/2000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 112.3785 - val_loss: 497.7342\n",
            "Epoch 156/2000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 104.1017 - val_loss: 463.9650\n",
            "Epoch 157/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 95.3636 - val_loss: 433.7571\n",
            "Epoch 158/2000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 88.2535 - val_loss: 405.3718\n",
            "Epoch 159/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 81.5314 - val_loss: 378.6172\n",
            "Epoch 160/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 75.2527 - val_loss: 354.1054\n",
            "Epoch 161/2000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 69.6096 - val_loss: 330.8095\n",
            "Epoch 162/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 63.9442 - val_loss: 308.7043\n",
            "Epoch 163/2000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 58.9760 - val_loss: 286.4094\n",
            "Epoch 164/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 53.6603 - val_loss: 266.8953\n",
            "Epoch 165/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 49.0635 - val_loss: 248.4424\n",
            "Epoch 166/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 44.8243 - val_loss: 229.5542\n",
            "Epoch 167/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 40.8964 - val_loss: 211.7590\n",
            "Epoch 168/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 36.8392 - val_loss: 196.0093\n",
            "Epoch 169/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 33.7186 - val_loss: 180.4032\n",
            "Epoch 170/2000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 30.3270 - val_loss: 167.0905\n",
            "Epoch 171/2000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 27.3875 - val_loss: 155.2066\n",
            "Epoch 172/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 25.0935 - val_loss: 143.2259\n",
            "Epoch 173/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 22.6505 - val_loss: 132.7368\n",
            "Epoch 174/2000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 20.5737 - val_loss: 123.7393\n",
            "Epoch 175/2000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 18.8164 - val_loss: 115.6465\n",
            "Epoch 176/2000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 17.1813 - val_loss: 108.0834\n",
            "Epoch 177/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 15.7519 - val_loss: 100.5214\n",
            "Epoch 178/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 14.3074 - val_loss: 93.7587\n",
            "Epoch 179/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 12.9564 - val_loss: 86.9794\n",
            "Epoch 180/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 11.7153 - val_loss: 80.9166\n",
            "Epoch 181/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 10.8335 - val_loss: 75.1936\n",
            "Epoch 182/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 9.8020 - val_loss: 70.2282\n",
            "Epoch 183/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 8.9986 - val_loss: 65.3376\n",
            "Epoch 184/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 8.1668 - val_loss: 61.0975\n",
            "Epoch 185/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 7.4820 - val_loss: 57.3282\n",
            "Epoch 186/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 6.9739 - val_loss: 53.6650\n",
            "Epoch 187/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 6.3967 - val_loss: 50.5528\n",
            "Epoch 188/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 5.9267 - val_loss: 47.8277\n",
            "Epoch 189/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.5167 - val_loss: 45.2627\n",
            "Epoch 190/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 5.1766 - val_loss: 42.5602\n",
            "Epoch 191/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 4.8374 - val_loss: 40.2515\n",
            "Epoch 192/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 4.4866 - val_loss: 38.3336\n",
            "Epoch 193/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 4.2555 - val_loss: 36.4627\n",
            "Epoch 194/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 4.0136 - val_loss: 34.6182\n",
            "Epoch 195/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 3.8112 - val_loss: 33.0096\n",
            "Epoch 196/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 3.6438 - val_loss: 31.5388\n",
            "Epoch 197/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 3.4751 - val_loss: 30.2680\n",
            "Epoch 198/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 3.3410 - val_loss: 29.0661\n",
            "Epoch 199/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 3.2144 - val_loss: 27.9837\n",
            "Epoch 200/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 3.0930 - val_loss: 27.0096\n",
            "Epoch 201/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 3.0084 - val_loss: 26.0692\n",
            "Epoch 202/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.9121 - val_loss: 25.2044\n",
            "Epoch 203/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.8283 - val_loss: 24.3754\n",
            "Epoch 204/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.7691 - val_loss: 23.4785\n",
            "Epoch 205/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.6895 - val_loss: 22.7594\n",
            "Epoch 206/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.6262 - val_loss: 22.0857\n",
            "Epoch 207/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.5706 - val_loss: 21.3567\n",
            "Epoch 208/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.5186 - val_loss: 20.6722\n",
            "Epoch 209/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.4864 - val_loss: 20.0348\n",
            "Epoch 210/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.4338 - val_loss: 19.5659\n",
            "Epoch 211/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.4098 - val_loss: 19.0784\n",
            "Epoch 212/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.3772 - val_loss: 18.6119\n",
            "Epoch 213/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.3462 - val_loss: 18.1881\n",
            "Epoch 214/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.3233 - val_loss: 17.8354\n",
            "Epoch 215/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.3094 - val_loss: 17.4855\n",
            "Epoch 216/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.2879 - val_loss: 17.1196\n",
            "Epoch 217/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.2703 - val_loss: 16.8240\n",
            "Epoch 218/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.2558 - val_loss: 16.5206\n",
            "Epoch 219/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.2483 - val_loss: 16.1772\n",
            "Epoch 220/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.2348 - val_loss: 15.9325\n",
            "Epoch 221/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.2223 - val_loss: 15.7090\n",
            "Epoch 222/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.2116 - val_loss: 15.4864\n",
            "Epoch 223/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.2103 - val_loss: 15.2681\n",
            "Epoch 224/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.1967 - val_loss: 15.1604\n",
            "Epoch 225/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.1916 - val_loss: 15.1094\n",
            "Epoch 226/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.1879 - val_loss: 15.1186\n",
            "Epoch 227/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.1842 - val_loss: 15.0862\n",
            "Epoch 228/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.1816 - val_loss: 15.0469\n",
            "Epoch 229/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.1773 - val_loss: 14.9582\n",
            "Epoch 230/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.1717 - val_loss: 14.8792\n",
            "Epoch 231/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.1667 - val_loss: 14.8057\n",
            "Epoch 232/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.1612 - val_loss: 14.6287\n",
            "Epoch 233/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 2.1581 - val_loss: 14.5020\n",
            "Epoch 234/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 2.1527 - val_loss: 14.4097\n",
            "Epoch 235/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.1510 - val_loss: 14.3258\n",
            "Epoch 236/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.1470 - val_loss: 14.2391\n",
            "Epoch 237/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.1422 - val_loss: 14.0739\n",
            "Epoch 238/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.1399 - val_loss: 14.0053\n",
            "Epoch 239/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 2.1374 - val_loss: 13.9564\n",
            "Epoch 240/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.1356 - val_loss: 13.8771\n",
            "Epoch 241/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.1339 - val_loss: 13.7206\n",
            "Epoch 242/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 2.1320 - val_loss: 13.6730\n",
            "Epoch 243/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 2.1279 - val_loss: 13.7333\n",
            "Epoch 244/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.1255 - val_loss: 13.8217\n",
            "Epoch 245/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.1244 - val_loss: 13.8717\n",
            "Epoch 246/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.1227 - val_loss: 13.9060\n",
            "Epoch 247/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.1211 - val_loss: 14.0055\n",
            "Epoch 248/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.1192 - val_loss: 14.1145\n",
            "Epoch 249/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.1184 - val_loss: 14.2521\n",
            "Epoch 250/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.1168 - val_loss: 14.3216\n",
            "Epoch 251/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.1189 - val_loss: 14.4372\n",
            "Epoch 252/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.1140 - val_loss: 14.4682\n",
            "Epoch 253/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.1099 - val_loss: 14.5267\n",
            "Epoch 254/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.1078 - val_loss: 14.5746\n",
            "Epoch 255/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.1060 - val_loss: 14.6287\n",
            "Epoch 256/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.1046 - val_loss: 14.7109\n",
            "Epoch 257/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.1025 - val_loss: 14.7218\n",
            "Epoch 258/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.0987 - val_loss: 14.7658\n",
            "Epoch 259/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0966 - val_loss: 14.7509\n",
            "Epoch 260/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0936 - val_loss: 14.7692\n",
            "Epoch 261/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0910 - val_loss: 14.8114\n",
            "Epoch 262/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0879 - val_loss: 14.8936\n",
            "Epoch 263/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0895 - val_loss: 15.0205\n",
            "Epoch 264/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0867 - val_loss: 15.0996\n",
            "Epoch 265/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0850 - val_loss: 15.1638\n",
            "Epoch 266/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0849 - val_loss: 15.1823\n",
            "Epoch 267/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0822 - val_loss: 15.2031\n",
            "Epoch 268/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0797 - val_loss: 15.1166\n",
            "Epoch 269/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0743 - val_loss: 15.0298\n",
            "Epoch 270/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0706 - val_loss: 14.9815\n",
            "Epoch 271/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0674 - val_loss: 14.9762\n",
            "Epoch 272/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0663 - val_loss: 15.0358\n",
            "Epoch 273/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0641 - val_loss: 15.0506\n",
            "Epoch 274/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0621 - val_loss: 15.0769\n",
            "Epoch 275/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0602 - val_loss: 15.1255\n",
            "Epoch 276/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 2.0600 - val_loss: 15.2074\n",
            "Epoch 277/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.0566 - val_loss: 15.1763\n",
            "Epoch 278/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.0539 - val_loss: 15.0947\n",
            "Epoch 279/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.0483 - val_loss: 14.9895\n",
            "Epoch 280/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 2.0434 - val_loss: 14.8260\n",
            "Epoch 281/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0369 - val_loss: 14.5407\n",
            "Epoch 282/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0349 - val_loss: 14.2556\n",
            "Epoch 283/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0318 - val_loss: 14.0556\n",
            "Epoch 284/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 2.0264 - val_loss: 13.9662\n",
            "Epoch 285/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0243 - val_loss: 14.0028\n",
            "Epoch 286/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0221 - val_loss: 14.0938\n",
            "Epoch 287/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0202 - val_loss: 14.2227\n",
            "Epoch 288/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 2.0215 - val_loss: 14.3590\n",
            "Epoch 289/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.0184 - val_loss: 14.4520\n",
            "Epoch 290/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0164 - val_loss: 14.5000\n",
            "Epoch 291/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 2.0148 - val_loss: 14.5865\n",
            "Epoch 292/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 2.0128 - val_loss: 14.6101\n",
            "Epoch 293/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0103 - val_loss: 14.5374\n",
            "Epoch 294/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0052 - val_loss: 14.4220\n",
            "Epoch 295/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.0009 - val_loss: 14.2792\n",
            "Epoch 296/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.9995 - val_loss: 14.0286\n",
            "Epoch 297/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.9945 - val_loss: 13.9383\n",
            "Epoch 298/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.9933 - val_loss: 13.9258\n",
            "Epoch 299/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.9926 - val_loss: 13.9537\n",
            "Epoch 300/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.9890 - val_loss: 14.0691\n",
            "Epoch 301/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.9883 - val_loss: 14.1395\n",
            "Epoch 302/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.9856 - val_loss: 14.1509\n",
            "Epoch 303/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.9863 - val_loss: 14.2622\n",
            "Epoch 304/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.9803 - val_loss: 14.2435\n",
            "Epoch 305/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.9768 - val_loss: 14.2148\n",
            "Epoch 306/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.9750 - val_loss: 14.1890\n",
            "Epoch 307/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.9719 - val_loss: 14.1715\n",
            "Epoch 308/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.9683 - val_loss: 14.1729\n",
            "Epoch 309/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.9681 - val_loss: 14.2111\n",
            "Epoch 310/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.9636 - val_loss: 14.0806\n",
            "Epoch 311/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.9619 - val_loss: 14.0271\n",
            "Epoch 312/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.9601 - val_loss: 14.0086\n",
            "Epoch 313/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.9589 - val_loss: 13.9943\n",
            "Epoch 314/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.9570 - val_loss: 14.0760\n",
            "Epoch 315/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.9541 - val_loss: 14.0575\n",
            "Epoch 316/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.9507 - val_loss: 14.1558\n",
            "Epoch 317/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.9478 - val_loss: 14.3224\n",
            "Epoch 318/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.9478 - val_loss: 14.4792\n",
            "Epoch 319/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.9460 - val_loss: 14.4900\n",
            "Epoch 320/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.9435 - val_loss: 14.4411\n",
            "Epoch 321/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.9405 - val_loss: 14.4299\n",
            "Epoch 322/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.9373 - val_loss: 14.3575\n",
            "Epoch 323/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.9366 - val_loss: 14.2945\n",
            "Epoch 324/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.9346 - val_loss: 14.3091\n",
            "Epoch 325/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.9324 - val_loss: 14.1425\n",
            "Epoch 326/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.9284 - val_loss: 14.1482\n",
            "Epoch 327/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.9259 - val_loss: 14.2334\n",
            "Epoch 328/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.9246 - val_loss: 14.2737\n",
            "Epoch 329/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.9230 - val_loss: 14.3477\n",
            "Epoch 330/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.9204 - val_loss: 14.4494\n",
            "Epoch 331/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.9177 - val_loss: 14.4800\n",
            "Epoch 332/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.9154 - val_loss: 14.4888\n",
            "Epoch 333/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.9131 - val_loss: 14.5476\n",
            "Epoch 334/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.9105 - val_loss: 14.5281\n",
            "Epoch 335/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.9087 - val_loss: 14.4995\n",
            "Epoch 336/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.9057 - val_loss: 14.4821\n",
            "Epoch 337/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.9027 - val_loss: 14.4449\n",
            "Epoch 338/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.9012 - val_loss: 14.3581\n",
            "Epoch 339/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.9004 - val_loss: 14.1523\n",
            "Epoch 340/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8975 - val_loss: 14.0830\n",
            "Epoch 341/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.8966 - val_loss: 14.0943\n",
            "Epoch 342/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8943 - val_loss: 14.0809\n",
            "Epoch 343/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8942 - val_loss: 14.0045\n",
            "Epoch 344/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8916 - val_loss: 13.9757\n",
            "Epoch 345/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.8876 - val_loss: 14.0803\n",
            "Epoch 346/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8854 - val_loss: 14.1873\n",
            "Epoch 347/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8840 - val_loss: 14.2167\n",
            "Epoch 348/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.8811 - val_loss: 14.3420\n",
            "Epoch 349/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.8766 - val_loss: 14.3818\n",
            "Epoch 350/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.8749 - val_loss: 14.3452\n",
            "Epoch 351/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8744 - val_loss: 14.2820\n",
            "Epoch 352/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.8694 - val_loss: 14.3571\n",
            "Epoch 353/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8643 - val_loss: 14.4297\n",
            "Epoch 354/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8628 - val_loss: 14.5258\n",
            "Epoch 355/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8604 - val_loss: 14.6079\n",
            "Epoch 356/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8577 - val_loss: 14.6864\n",
            "Epoch 357/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.8586 - val_loss: 14.9095\n",
            "Epoch 358/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8545 - val_loss: 15.0797\n",
            "Epoch 359/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.8531 - val_loss: 15.1341\n",
            "Epoch 360/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.8512 - val_loss: 15.0996\n",
            "Epoch 361/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.8450 - val_loss: 14.8922\n",
            "Epoch 362/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.8439 - val_loss: 14.7353\n",
            "Epoch 363/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.8441 - val_loss: 14.6014\n",
            "Epoch 364/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8417 - val_loss: 14.4962\n",
            "Epoch 365/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8411 - val_loss: 14.3930\n",
            "Epoch 366/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.8415 - val_loss: 14.1257\n",
            "Epoch 367/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8380 - val_loss: 13.9545\n",
            "Epoch 368/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.8387 - val_loss: 13.8237\n",
            "Epoch 369/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.8362 - val_loss: 13.7688\n",
            "Epoch 370/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8368 - val_loss: 13.6725\n",
            "Epoch 371/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.8348 - val_loss: 13.6322\n",
            "Epoch 372/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.8333 - val_loss: 13.6269\n",
            "Epoch 373/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.8314 - val_loss: 13.4571\n",
            "Epoch 374/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.8324 - val_loss: 13.3365\n",
            "Epoch 375/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8317 - val_loss: 13.2761\n",
            "Epoch 376/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8315 - val_loss: 13.2407\n",
            "Epoch 377/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8299 - val_loss: 13.2463\n",
            "Epoch 378/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8274 - val_loss: 13.3033\n",
            "Epoch 379/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.8237 - val_loss: 13.4979\n",
            "Epoch 380/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8187 - val_loss: 13.7422\n",
            "Epoch 381/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8134 - val_loss: 13.9615\n",
            "Epoch 382/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8088 - val_loss: 14.1834\n",
            "Epoch 383/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8051 - val_loss: 14.3002\n",
            "Epoch 384/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8031 - val_loss: 14.3797\n",
            "Epoch 385/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.7998 - val_loss: 14.4039\n",
            "Epoch 386/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.7978 - val_loss: 14.4689\n",
            "Epoch 387/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.7949 - val_loss: 14.5689\n",
            "Epoch 388/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.7932 - val_loss: 14.6867\n",
            "Epoch 389/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7911 - val_loss: 14.7049\n",
            "Epoch 390/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7880 - val_loss: 14.6651\n",
            "Epoch 391/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7864 - val_loss: 14.6398\n",
            "Epoch 392/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.7856 - val_loss: 14.6996\n",
            "Epoch 393/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.7825 - val_loss: 14.8073\n",
            "Epoch 394/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.7815 - val_loss: 14.8010\n",
            "Epoch 395/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7780 - val_loss: 14.5987\n",
            "Epoch 396/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.7790 - val_loss: 14.4692\n",
            "Epoch 397/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.7775 - val_loss: 14.4415\n",
            "Epoch 398/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7749 - val_loss: 14.5794\n",
            "Epoch 399/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.7756 - val_loss: 14.8437\n",
            "Epoch 400/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7696 - val_loss: 15.0642\n",
            "Epoch 401/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7683 - val_loss: 15.2011\n",
            "Epoch 402/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7654 - val_loss: 15.2601\n",
            "Epoch 403/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7636 - val_loss: 15.3832\n",
            "Epoch 404/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7622 - val_loss: 15.5007\n",
            "Epoch 405/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7594 - val_loss: 15.6033\n",
            "Epoch 406/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7587 - val_loss: 15.6229\n",
            "Epoch 407/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7574 - val_loss: 15.6297\n",
            "Epoch 408/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7546 - val_loss: 15.6964\n",
            "Epoch 409/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7544 - val_loss: 15.8033\n",
            "Epoch 410/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7527 - val_loss: 15.8610\n",
            "Epoch 411/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7502 - val_loss: 15.9558\n",
            "Epoch 412/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7499 - val_loss: 16.1140\n",
            "Epoch 413/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7485 - val_loss: 16.2228\n",
            "Epoch 414/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.7488 - val_loss: 16.2626\n",
            "Epoch 415/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7474 - val_loss: 16.2926\n",
            "Epoch 416/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.7468 - val_loss: 16.3623\n",
            "Epoch 417/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7455 - val_loss: 16.3713\n",
            "Epoch 418/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.7425 - val_loss: 16.3545\n",
            "Epoch 419/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.7407 - val_loss: 16.3472\n",
            "Epoch 420/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7395 - val_loss: 16.2524\n",
            "Epoch 421/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.7353 - val_loss: 16.2578\n",
            "Epoch 422/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7336 - val_loss: 16.2128\n",
            "Epoch 423/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7327 - val_loss: 16.3176\n",
            "Epoch 424/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7307 - val_loss: 16.4050\n",
            "Epoch 425/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7286 - val_loss: 16.3317\n",
            "Epoch 426/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7262 - val_loss: 16.3677\n",
            "Epoch 427/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7265 - val_loss: 16.3131\n",
            "Epoch 428/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.7198 - val_loss: 16.0860\n",
            "Epoch 429/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7200 - val_loss: 15.8863\n",
            "Epoch 430/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7221 - val_loss: 15.7360\n",
            "Epoch 431/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.7172 - val_loss: 15.7443\n",
            "Epoch 432/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7162 - val_loss: 15.6953\n",
            "Epoch 433/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.7221 - val_loss: 15.4878\n",
            "Epoch 434/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7136 - val_loss: 15.4866\n",
            "Epoch 435/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.7130 - val_loss: 15.5014\n",
            "Epoch 436/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.7091 - val_loss: 15.6090\n",
            "Epoch 437/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7068 - val_loss: 15.8525\n",
            "Epoch 438/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7050 - val_loss: 16.0954\n",
            "Epoch 439/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.7060 - val_loss: 16.1455\n",
            "Epoch 440/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.7044 - val_loss: 16.0987\n",
            "Epoch 441/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7030 - val_loss: 16.1491\n",
            "Epoch 442/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7002 - val_loss: 16.2798\n",
            "Epoch 443/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.7009 - val_loss: 16.4116\n",
            "Epoch 444/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7025 - val_loss: 16.6003\n",
            "Epoch 445/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6991 - val_loss: 16.6502\n",
            "Epoch 446/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.7017 - val_loss: 16.8247\n",
            "Epoch 447/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6984 - val_loss: 16.8859\n",
            "Epoch 448/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6997 - val_loss: 16.9205\n",
            "Epoch 449/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.6962 - val_loss: 16.8202\n",
            "Epoch 450/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.6944 - val_loss: 16.6645\n",
            "Epoch 451/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.6902 - val_loss: 16.6650\n",
            "Epoch 452/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6891 - val_loss: 16.5660\n",
            "Epoch 453/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.6851 - val_loss: 16.4394\n",
            "Epoch 454/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6817 - val_loss: 16.2911\n",
            "Epoch 455/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.6852 - val_loss: 16.0193\n",
            "Epoch 456/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6797 - val_loss: 15.9680\n",
            "Epoch 457/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6762 - val_loss: 16.0747\n",
            "Epoch 458/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6739 - val_loss: 16.0677\n",
            "Epoch 459/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.6712 - val_loss: 16.1797\n",
            "Epoch 460/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6705 - val_loss: 16.3572\n",
            "Epoch 461/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.6692 - val_loss: 16.4354\n",
            "Epoch 462/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6675 - val_loss: 16.4308\n",
            "Epoch 463/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6664 - val_loss: 16.3251\n",
            "Epoch 464/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.6620 - val_loss: 15.9758\n",
            "Epoch 465/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6614 - val_loss: 15.7062\n",
            "Epoch 466/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6591 - val_loss: 15.5433\n",
            "Epoch 467/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6644 - val_loss: 15.1805\n",
            "Epoch 468/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.6634 - val_loss: 15.1060\n",
            "Epoch 469/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.6592 - val_loss: 15.2157\n",
            "Epoch 470/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6584 - val_loss: 15.3023\n",
            "Epoch 471/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.6555 - val_loss: 15.4009\n",
            "Epoch 472/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6521 - val_loss: 15.5905\n",
            "Epoch 473/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.6478 - val_loss: 15.8405\n",
            "Epoch 474/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6522 - val_loss: 16.1156\n",
            "Epoch 475/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6519 - val_loss: 16.2239\n",
            "Epoch 476/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.6447 - val_loss: 16.0318\n",
            "Epoch 477/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.6544 - val_loss: 15.7508\n",
            "Epoch 478/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6461 - val_loss: 15.6096\n",
            "Epoch 479/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6442 - val_loss: 15.6218\n",
            "Epoch 480/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6436 - val_loss: 15.6517\n",
            "Epoch 481/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.6423 - val_loss: 15.7390\n",
            "Epoch 482/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6405 - val_loss: 15.7673\n",
            "Epoch 483/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6394 - val_loss: 15.8230\n",
            "Epoch 484/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.6391 - val_loss: 15.9726\n",
            "Epoch 485/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6361 - val_loss: 16.0239\n",
            "Epoch 486/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6343 - val_loss: 16.0116\n",
            "Epoch 487/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6344 - val_loss: 16.0269\n",
            "Epoch 488/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6318 - val_loss: 16.0004\n",
            "Epoch 489/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.6311 - val_loss: 16.0278\n",
            "Epoch 490/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.6283 - val_loss: 15.8815\n",
            "Epoch 491/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6343 - val_loss: 15.6106\n",
            "Epoch 492/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.6292 - val_loss: 15.5617\n",
            "Epoch 493/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6272 - val_loss: 15.6119\n",
            "Epoch 494/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6274 - val_loss: 15.5920\n",
            "Epoch 495/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6251 - val_loss: 15.5056\n",
            "Epoch 496/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.6254 - val_loss: 15.4363\n",
            "Epoch 497/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.6231 - val_loss: 15.1535\n",
            "Epoch 498/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6247 - val_loss: 14.9682\n",
            "Epoch 499/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6300 - val_loss: 14.7620\n",
            "Epoch 500/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6278 - val_loss: 14.7909\n",
            "Epoch 501/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6276 - val_loss: 14.7250\n",
            "Epoch 502/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.6250 - val_loss: 14.8176\n",
            "Epoch 503/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6233 - val_loss: 14.9463\n",
            "Epoch 504/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.6230 - val_loss: 15.0644\n",
            "Epoch 505/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6184 - val_loss: 15.1031\n",
            "Epoch 506/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6163 - val_loss: 15.0755\n",
            "Epoch 507/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.6147 - val_loss: 15.0027\n",
            "Epoch 508/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6142 - val_loss: 14.9538\n",
            "Epoch 509/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6137 - val_loss: 14.9493\n",
            "Epoch 510/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6155 - val_loss: 14.8263\n",
            "Epoch 511/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6155 - val_loss: 14.7858\n",
            "Epoch 512/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.6113 - val_loss: 14.9796\n",
            "Epoch 513/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6055 - val_loss: 15.1021\n",
            "Epoch 514/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.6030 - val_loss: 15.3845\n",
            "Epoch 515/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5990 - val_loss: 15.6635\n",
            "Epoch 516/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5952 - val_loss: 15.8810\n",
            "Epoch 517/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.5953 - val_loss: 16.0781\n",
            "Epoch 518/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5906 - val_loss: 16.1831\n",
            "Epoch 519/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.5912 - val_loss: 16.4222\n",
            "Epoch 520/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5879 - val_loss: 16.6730\n",
            "Epoch 521/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5864 - val_loss: 16.7414\n",
            "Epoch 522/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5842 - val_loss: 16.7440\n",
            "Epoch 523/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.5828 - val_loss: 16.7221\n",
            "Epoch 524/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5790 - val_loss: 16.5776\n",
            "Epoch 525/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.5785 - val_loss: 16.2695\n",
            "Epoch 526/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5745 - val_loss: 16.0657\n",
            "Epoch 527/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5746 - val_loss: 15.8966\n",
            "Epoch 528/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5750 - val_loss: 15.7993\n",
            "Epoch 529/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.5736 - val_loss: 15.8637\n",
            "Epoch 530/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.5727 - val_loss: 16.0881\n",
            "Epoch 531/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5748 - val_loss: 16.3323\n",
            "Epoch 532/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5688 - val_loss: 16.4261\n",
            "Epoch 533/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.5675 - val_loss: 16.5128\n",
            "Epoch 534/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.5652 - val_loss: 16.5392\n",
            "Epoch 535/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5637 - val_loss: 16.4674\n",
            "Epoch 536/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5615 - val_loss: 16.4025\n",
            "Epoch 537/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5592 - val_loss: 16.2875\n",
            "Epoch 538/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.5583 - val_loss: 16.1861\n",
            "Epoch 539/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5580 - val_loss: 16.1128\n",
            "Epoch 540/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.5574 - val_loss: 16.2834\n",
            "Epoch 541/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.5538 - val_loss: 16.5210\n",
            "Epoch 542/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5503 - val_loss: 16.8536\n",
            "Epoch 543/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5514 - val_loss: 17.1879\n",
            "Epoch 544/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5522 - val_loss: 17.2957\n",
            "Epoch 545/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5518 - val_loss: 17.3305\n",
            "Epoch 546/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.5497 - val_loss: 17.1537\n",
            "Epoch 547/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5488 - val_loss: 16.6300\n",
            "Epoch 548/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5453 - val_loss: 16.2422\n",
            "Epoch 549/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.5474 - val_loss: 15.8917\n",
            "Epoch 550/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.5430 - val_loss: 15.6567\n",
            "Epoch 551/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.5474 - val_loss: 15.5087\n",
            "Epoch 552/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.5466 - val_loss: 15.6856\n",
            "Epoch 553/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5396 - val_loss: 15.8120\n",
            "Epoch 554/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.5368 - val_loss: 15.8892\n",
            "Epoch 555/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5367 - val_loss: 15.9711\n",
            "Epoch 556/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5334 - val_loss: 16.1137\n",
            "Epoch 557/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.5358 - val_loss: 16.2960\n",
            "Epoch 558/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.5296 - val_loss: 16.1226\n",
            "Epoch 559/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5306 - val_loss: 16.1192\n",
            "Epoch 560/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5333 - val_loss: 16.2807\n",
            "Epoch 561/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5279 - val_loss: 16.2777\n",
            "Epoch 562/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5270 - val_loss: 16.2537\n",
            "Epoch 563/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5254 - val_loss: 16.3028\n",
            "Epoch 564/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5241 - val_loss: 16.3647\n",
            "Epoch 565/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5269 - val_loss: 16.6258\n",
            "Epoch 566/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5247 - val_loss: 16.8071\n",
            "Epoch 567/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5200 - val_loss: 16.8751\n",
            "Epoch 568/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5191 - val_loss: 17.0613\n",
            "Epoch 569/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.5181 - val_loss: 17.1750\n",
            "Epoch 570/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.5180 - val_loss: 17.3471\n",
            "Epoch 571/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5208 - val_loss: 17.4913\n",
            "Epoch 572/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5182 - val_loss: 17.5038\n",
            "Epoch 573/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.5172 - val_loss: 17.5747\n",
            "Epoch 574/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5163 - val_loss: 17.7046\n",
            "Epoch 575/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.5195 - val_loss: 17.9946\n",
            "Epoch 576/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5243 - val_loss: 18.2952\n",
            "Epoch 577/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5204 - val_loss: 18.3464\n",
            "Epoch 578/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.5214 - val_loss: 18.3964\n",
            "Epoch 579/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5206 - val_loss: 18.4549\n",
            "Epoch 580/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.5206 - val_loss: 18.5876\n",
            "Epoch 581/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.5216 - val_loss: 18.6553\n",
            "Epoch 582/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.5219 - val_loss: 18.7870\n",
            "Epoch 583/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5234 - val_loss: 18.9106\n",
            "Epoch 584/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.5270 - val_loss: 18.9213\n",
            "Epoch 585/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5214 - val_loss: 18.7377\n",
            "Epoch 586/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5170 - val_loss: 18.6132\n",
            "Epoch 587/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.5127 - val_loss: 18.3125\n",
            "Epoch 588/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5064 - val_loss: 17.8303\n",
            "Epoch 589/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4941 - val_loss: 17.1811\n",
            "Epoch 590/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5025 - val_loss: 16.8460\n",
            "Epoch 591/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.4951 - val_loss: 16.7929\n",
            "Epoch 592/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4935 - val_loss: 16.6823\n",
            "Epoch 593/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.4914 - val_loss: 16.3890\n",
            "Epoch 594/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.4927 - val_loss: 16.2218\n",
            "Epoch 595/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.4930 - val_loss: 16.1529\n",
            "Epoch 596/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4923 - val_loss: 16.2270\n",
            "Epoch 597/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4921 - val_loss: 16.3619\n",
            "Epoch 598/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4898 - val_loss: 16.4482\n",
            "Epoch 599/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4882 - val_loss: 16.5185\n",
            "Epoch 600/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.4847 - val_loss: 16.7298\n",
            "Epoch 601/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4827 - val_loss: 16.9351\n",
            "Epoch 602/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4818 - val_loss: 17.2562\n",
            "Epoch 603/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4847 - val_loss: 17.5774\n",
            "Epoch 604/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4838 - val_loss: 17.7367\n",
            "Epoch 605/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.4848 - val_loss: 17.9402\n",
            "Epoch 606/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4850 - val_loss: 17.9902\n",
            "Epoch 607/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.4880 - val_loss: 17.9749\n",
            "Epoch 608/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4885 - val_loss: 17.7116\n",
            "Epoch 609/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.4807 - val_loss: 17.6815\n",
            "Epoch 610/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.4803 - val_loss: 17.7594\n",
            "Epoch 611/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4787 - val_loss: 17.9624\n",
            "Epoch 612/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4800 - val_loss: 18.1675\n",
            "Epoch 613/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4813 - val_loss: 18.1696\n",
            "Epoch 614/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.4794 - val_loss: 18.2786\n",
            "Epoch 615/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4807 - val_loss: 18.4287\n",
            "Epoch 616/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.4801 - val_loss: 18.5929\n",
            "Epoch 617/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4846 - val_loss: 18.7385\n",
            "Epoch 618/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4846 - val_loss: 18.7587\n",
            "Epoch 619/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4839 - val_loss: 18.8170\n",
            "Epoch 620/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4852 - val_loss: 19.0062\n",
            "Epoch 621/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.4867 - val_loss: 19.0766\n",
            "Epoch 622/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.4914 - val_loss: 18.7555\n",
            "Epoch 623/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4803 - val_loss: 18.6896\n",
            "Epoch 624/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4805 - val_loss: 18.5845\n",
            "Epoch 625/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.4773 - val_loss: 18.7114\n",
            "Epoch 626/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.4777 - val_loss: 18.6784\n",
            "Epoch 627/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4736 - val_loss: 18.4356\n",
            "Epoch 628/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.4712 - val_loss: 18.2926\n",
            "Epoch 629/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4683 - val_loss: 18.1249\n",
            "Epoch 630/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4673 - val_loss: 18.1248\n",
            "Epoch 631/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4668 - val_loss: 17.9261\n",
            "Epoch 632/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4610 - val_loss: 17.7859\n",
            "Epoch 633/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.4633 - val_loss: 17.6857\n",
            "Epoch 634/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4581 - val_loss: 17.8118\n",
            "Epoch 635/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4651 - val_loss: 18.0106\n",
            "Epoch 636/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4548 - val_loss: 17.5933\n",
            "Epoch 637/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4578 - val_loss: 17.2085\n",
            "Epoch 638/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4519 - val_loss: 17.1101\n",
            "Epoch 639/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.4506 - val_loss: 17.0269\n",
            "Epoch 640/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4443 - val_loss: 16.7022\n",
            "Epoch 641/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4501 - val_loss: 16.4732\n",
            "Epoch 642/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4460 - val_loss: 16.5846\n",
            "Epoch 643/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.4458 - val_loss: 16.9077\n",
            "Epoch 644/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4403 - val_loss: 17.3304\n",
            "Epoch 645/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4441 - val_loss: 17.7645\n",
            "Epoch 646/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4535 - val_loss: 17.8691\n",
            "Epoch 647/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4388 - val_loss: 17.2852\n",
            "Epoch 648/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4377 - val_loss: 16.4358\n",
            "Epoch 649/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4476 - val_loss: 15.8812\n",
            "Epoch 650/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.4416 - val_loss: 15.7486\n",
            "Epoch 651/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.4410 - val_loss: 15.7853\n",
            "Epoch 652/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4413 - val_loss: 15.8755\n",
            "Epoch 653/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.4402 - val_loss: 15.9010\n",
            "Epoch 654/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4365 - val_loss: 16.0341\n",
            "Epoch 655/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.4345 - val_loss: 16.1652\n",
            "Epoch 656/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4399 - val_loss: 16.3996\n",
            "Epoch 657/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4327 - val_loss: 16.5311\n",
            "Epoch 658/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.4315 - val_loss: 16.7773\n",
            "Epoch 659/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4296 - val_loss: 16.8246\n",
            "Epoch 660/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4293 - val_loss: 16.7815\n",
            "Epoch 661/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4278 - val_loss: 16.6681\n",
            "Epoch 662/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4266 - val_loss: 16.6693\n",
            "Epoch 663/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.4235 - val_loss: 16.8297\n",
            "Epoch 664/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.4221 - val_loss: 17.0217\n",
            "Epoch 665/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4265 - val_loss: 17.3185\n",
            "Epoch 666/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4215 - val_loss: 17.6444\n",
            "Epoch 667/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4240 - val_loss: 17.9774\n",
            "Epoch 668/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4261 - val_loss: 18.1035\n",
            "Epoch 669/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.4318 - val_loss: 18.1419\n",
            "Epoch 670/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.4290 - val_loss: 17.5094\n",
            "Epoch 671/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.4234 - val_loss: 17.0171\n",
            "Epoch 672/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4165 - val_loss: 16.7818\n",
            "Epoch 673/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.4237 - val_loss: 16.1223\n",
            "Epoch 674/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.4125 - val_loss: 15.7628\n",
            "Epoch 675/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.4218 - val_loss: 15.1263\n",
            "Epoch 676/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.4264 - val_loss: 14.9280\n",
            "Epoch 677/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4239 - val_loss: 15.1373\n",
            "Epoch 678/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4292 - val_loss: 15.6718\n",
            "Epoch 679/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4134 - val_loss: 16.1856\n",
            "Epoch 680/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.4050 - val_loss: 16.6116\n",
            "Epoch 681/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.4102 - val_loss: 17.1927\n",
            "Epoch 682/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.4094 - val_loss: 17.6798\n",
            "Epoch 683/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4242 - val_loss: 17.9061\n",
            "Epoch 684/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4071 - val_loss: 17.4924\n",
            "Epoch 685/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.4068 - val_loss: 17.0315\n",
            "Epoch 686/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4074 - val_loss: 16.5441\n",
            "Epoch 687/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4045 - val_loss: 16.0101\n",
            "Epoch 688/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3993 - val_loss: 15.6583\n",
            "Epoch 689/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.4009 - val_loss: 15.0535\n",
            "Epoch 690/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4118 - val_loss: 14.6023\n",
            "Epoch 691/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.4097 - val_loss: 14.1341\n",
            "Epoch 692/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4259 - val_loss: 13.9604\n",
            "Epoch 693/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4250 - val_loss: 14.1425\n",
            "Epoch 694/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4192 - val_loss: 14.5890\n",
            "Epoch 695/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4047 - val_loss: 15.1884\n",
            "Epoch 696/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3966 - val_loss: 15.7888\n",
            "Epoch 697/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3948 - val_loss: 16.1425\n",
            "Epoch 698/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3913 - val_loss: 16.3674\n",
            "Epoch 699/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3930 - val_loss: 16.7298\n",
            "Epoch 700/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.3969 - val_loss: 17.0065\n",
            "Epoch 701/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3900 - val_loss: 17.0173\n",
            "Epoch 702/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3910 - val_loss: 16.9556\n",
            "Epoch 703/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3813 - val_loss: 16.3867\n",
            "Epoch 704/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3805 - val_loss: 15.9492\n",
            "Epoch 705/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.3862 - val_loss: 15.4318\n",
            "Epoch 706/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.3912 - val_loss: 14.7494\n",
            "Epoch 707/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3914 - val_loss: 14.4764\n",
            "Epoch 708/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.3978 - val_loss: 14.2933\n",
            "Epoch 709/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4025 - val_loss: 14.2572\n",
            "Epoch 710/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.3993 - val_loss: 14.2881\n",
            "Epoch 711/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3987 - val_loss: 14.3073\n",
            "Epoch 712/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3952 - val_loss: 14.3995\n",
            "Epoch 713/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3923 - val_loss: 14.4983\n",
            "Epoch 714/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3897 - val_loss: 14.6178\n",
            "Epoch 715/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.3857 - val_loss: 14.7859\n",
            "Epoch 716/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3789 - val_loss: 15.2065\n",
            "Epoch 717/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3706 - val_loss: 15.5490\n",
            "Epoch 718/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.3764 - val_loss: 16.0742\n",
            "Epoch 719/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3651 - val_loss: 16.1501\n",
            "Epoch 720/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3642 - val_loss: 16.4683\n",
            "Epoch 721/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3645 - val_loss: 16.8103\n",
            "Epoch 722/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.3602 - val_loss: 17.1309\n",
            "Epoch 723/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3623 - val_loss: 17.3286\n",
            "Epoch 724/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3633 - val_loss: 17.6417\n",
            "Epoch 725/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3710 - val_loss: 18.0689\n",
            "Epoch 726/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.3734 - val_loss: 18.1725\n",
            "Epoch 727/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3642 - val_loss: 17.5281\n",
            "Epoch 728/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3611 - val_loss: 16.8685\n",
            "Epoch 729/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3505 - val_loss: 16.4432\n",
            "Epoch 730/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.3521 - val_loss: 16.0028\n",
            "Epoch 731/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3532 - val_loss: 15.5463\n",
            "Epoch 732/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3540 - val_loss: 15.3515\n",
            "Epoch 733/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.3518 - val_loss: 14.8579\n",
            "Epoch 734/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3724 - val_loss: 14.4502\n",
            "Epoch 735/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3670 - val_loss: 14.3255\n",
            "Epoch 736/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.3664 - val_loss: 14.2201\n",
            "Epoch 737/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.3684 - val_loss: 14.1984\n",
            "Epoch 738/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3681 - val_loss: 14.3452\n",
            "Epoch 739/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3627 - val_loss: 14.4883\n",
            "Epoch 740/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3558 - val_loss: 14.9021\n",
            "Epoch 741/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.3453 - val_loss: 15.3594\n",
            "Epoch 742/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3447 - val_loss: 15.7306\n",
            "Epoch 743/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3390 - val_loss: 16.0021\n",
            "Epoch 744/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.3368 - val_loss: 16.1323\n",
            "Epoch 745/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3348 - val_loss: 16.3986\n",
            "Epoch 746/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3405 - val_loss: 16.6090\n",
            "Epoch 747/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.3357 - val_loss: 16.1659\n",
            "Epoch 748/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.3306 - val_loss: 15.8809\n",
            "Epoch 749/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3404 - val_loss: 15.5931\n",
            "Epoch 750/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.3325 - val_loss: 15.7340\n",
            "Epoch 751/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3333 - val_loss: 16.1394\n",
            "Epoch 752/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3298 - val_loss: 16.3717\n",
            "Epoch 753/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3276 - val_loss: 16.3508\n",
            "Epoch 754/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3261 - val_loss: 16.3506\n",
            "Epoch 755/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3232 - val_loss: 16.6044\n",
            "Epoch 756/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.3244 - val_loss: 17.0408\n",
            "Epoch 757/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3225 - val_loss: 17.3296\n",
            "Epoch 758/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3282 - val_loss: 17.6998\n",
            "Epoch 759/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3284 - val_loss: 17.9287\n",
            "Epoch 760/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3329 - val_loss: 18.2421\n",
            "Epoch 761/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3370 - val_loss: 18.3699\n",
            "Epoch 762/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3361 - val_loss: 18.2866\n",
            "Epoch 763/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.3345 - val_loss: 18.3054\n",
            "Epoch 764/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3335 - val_loss: 18.1659\n",
            "Epoch 765/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3307 - val_loss: 17.8655\n",
            "Epoch 766/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.3279 - val_loss: 17.2860\n",
            "Epoch 767/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.3180 - val_loss: 17.1149\n",
            "Epoch 768/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3165 - val_loss: 17.0382\n",
            "Epoch 769/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3161 - val_loss: 17.0447\n",
            "Epoch 770/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.3150 - val_loss: 16.8356\n",
            "Epoch 771/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3213 - val_loss: 16.0892\n",
            "Epoch 772/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3101 - val_loss: 15.9072\n",
            "Epoch 773/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3242 - val_loss: 15.3747\n",
            "Epoch 774/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3103 - val_loss: 15.3670\n",
            "Epoch 775/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3094 - val_loss: 15.4133\n",
            "Epoch 776/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3071 - val_loss: 15.8002\n",
            "Epoch 777/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3073 - val_loss: 16.3440\n",
            "Epoch 778/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3023 - val_loss: 16.8892\n",
            "Epoch 779/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.3039 - val_loss: 17.2474\n",
            "Epoch 780/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3111 - val_loss: 17.7343\n",
            "Epoch 781/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3088 - val_loss: 18.0678\n",
            "Epoch 782/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3208 - val_loss: 18.2438\n",
            "Epoch 783/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3183 - val_loss: 18.0061\n",
            "Epoch 784/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3132 - val_loss: 17.8263\n",
            "Epoch 785/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3116 - val_loss: 17.8650\n",
            "Epoch 786/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3122 - val_loss: 17.9997\n",
            "Epoch 787/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3183 - val_loss: 17.9496\n",
            "Epoch 788/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3030 - val_loss: 17.0112\n",
            "Epoch 789/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3071 - val_loss: 15.9549\n",
            "Epoch 790/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3095 - val_loss: 15.2591\n",
            "Epoch 791/2000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1.2945 - val_loss: 14.9983\n",
            "Epoch 792/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.2937 - val_loss: 14.9648\n",
            "Epoch 793/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2943 - val_loss: 14.9380\n",
            "Epoch 794/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.2928 - val_loss: 14.6266\n",
            "Epoch 795/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2942 - val_loss: 14.2332\n",
            "Epoch 796/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3011 - val_loss: 13.9944\n",
            "Epoch 797/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3031 - val_loss: 14.1293\n",
            "Epoch 798/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.2982 - val_loss: 14.5538\n",
            "Epoch 799/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.2916 - val_loss: 14.9457\n",
            "Epoch 800/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2843 - val_loss: 15.3236\n",
            "Epoch 801/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.2809 - val_loss: 15.8311\n",
            "Epoch 802/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.2811 - val_loss: 16.1915\n",
            "Epoch 803/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.2796 - val_loss: 16.2849\n",
            "Epoch 804/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.2805 - val_loss: 16.3338\n",
            "Epoch 805/2000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.2807 - val_loss: 16.5649\n",
            "Epoch 806/2000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.2786 - val_loss: 16.5736\n",
            "Epoch 807/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2769 - val_loss: 16.7904\n",
            "Epoch 808/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2901 - val_loss: 17.1999\n",
            "Epoch 809/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.2808 - val_loss: 17.1304\n",
            "Epoch 810/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.2774 - val_loss: 16.7880\n",
            "Epoch 811/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2889 - val_loss: 15.7977\n",
            "Epoch 812/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2681 - val_loss: 15.2678\n",
            "Epoch 813/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2682 - val_loss: 14.9256\n",
            "Epoch 814/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2708 - val_loss: 14.6232\n",
            "Epoch 815/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.2768 - val_loss: 13.9084\n",
            "Epoch 816/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2900 - val_loss: 13.5064\n",
            "Epoch 817/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2898 - val_loss: 13.5065\n",
            "Epoch 818/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.2880 - val_loss: 13.6160\n",
            "Epoch 819/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2830 - val_loss: 13.8349\n",
            "Epoch 820/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2816 - val_loss: 14.3584\n",
            "Epoch 821/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2712 - val_loss: 14.6750\n",
            "Epoch 822/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2628 - val_loss: 14.6590\n",
            "Epoch 823/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.2650 - val_loss: 14.6557\n",
            "Epoch 824/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.2595 - val_loss: 14.9884\n",
            "Epoch 825/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2562 - val_loss: 15.1551\n",
            "Epoch 826/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.2537 - val_loss: 15.3624\n",
            "Epoch 827/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2517 - val_loss: 15.5482\n",
            "Epoch 828/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2514 - val_loss: 16.0885\n",
            "Epoch 829/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.2443 - val_loss: 16.6504\n",
            "Epoch 830/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2544 - val_loss: 17.2253\n",
            "Epoch 831/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2572 - val_loss: 17.3393\n",
            "Epoch 832/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.2600 - val_loss: 17.4145\n",
            "Epoch 833/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2575 - val_loss: 17.4865\n",
            "Epoch 834/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.2579 - val_loss: 17.6346\n",
            "Epoch 835/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2591 - val_loss: 17.5633\n",
            "Epoch 836/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2549 - val_loss: 17.3585\n",
            "Epoch 837/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2496 - val_loss: 16.8855\n",
            "Epoch 838/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.2373 - val_loss: 15.9435\n",
            "Epoch 839/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2389 - val_loss: 15.4694\n",
            "Epoch 840/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2369 - val_loss: 15.3983\n",
            "Epoch 841/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2349 - val_loss: 15.5273\n",
            "Epoch 842/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.2333 - val_loss: 15.7553\n",
            "Epoch 843/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.2368 - val_loss: 16.2884\n",
            "Epoch 844/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2391 - val_loss: 16.8236\n",
            "Epoch 845/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2379 - val_loss: 17.0634\n",
            "Epoch 846/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.2381 - val_loss: 17.2272\n",
            "Epoch 847/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2392 - val_loss: 17.1893\n",
            "Epoch 848/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2362 - val_loss: 16.8834\n",
            "Epoch 849/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.2311 - val_loss: 16.6180\n",
            "Epoch 850/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2320 - val_loss: 16.6984\n",
            "Epoch 851/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2295 - val_loss: 16.8738\n",
            "Epoch 852/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.2296 - val_loss: 16.9729\n",
            "Epoch 853/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2290 - val_loss: 17.1428\n",
            "Epoch 854/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2320 - val_loss: 17.1951\n",
            "Epoch 855/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2299 - val_loss: 17.0953\n",
            "Epoch 856/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.2251 - val_loss: 16.8202\n",
            "Epoch 857/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2183 - val_loss: 16.4749\n",
            "Epoch 858/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2110 - val_loss: 16.0484\n",
            "Epoch 859/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2193 - val_loss: 15.4403\n",
            "Epoch 860/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2149 - val_loss: 15.1195\n",
            "Epoch 861/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2139 - val_loss: 14.9893\n",
            "Epoch 862/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2120 - val_loss: 14.9895\n",
            "Epoch 863/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2115 - val_loss: 15.0152\n",
            "Epoch 864/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.2075 - val_loss: 15.2118\n",
            "Epoch 865/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2084 - val_loss: 15.2616\n",
            "Epoch 866/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2128 - val_loss: 14.9105\n",
            "Epoch 867/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2064 - val_loss: 14.8955\n",
            "Epoch 868/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2073 - val_loss: 14.7856\n",
            "Epoch 869/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2007 - val_loss: 14.2949\n",
            "Epoch 870/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.2078 - val_loss: 14.0897\n",
            "Epoch 871/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.2143 - val_loss: 13.8752\n",
            "Epoch 872/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.2127 - val_loss: 14.0740\n",
            "Epoch 873/2000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.2017 - val_loss: 14.6035\n",
            "Epoch 874/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.1948 - val_loss: 15.2134\n",
            "Epoch 875/2000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.1975 - val_loss: 15.6387\n",
            "Epoch 876/2000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.1941 - val_loss: 15.7553\n",
            "Epoch 877/2000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.2032 - val_loss: 16.1269\n",
            "Epoch 878/2000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.1918 - val_loss: 15.8661\n",
            "Epoch 879/2000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.1893 - val_loss: 15.6304\n",
            "Epoch 880/2000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.1865 - val_loss: 15.1726\n",
            "Epoch 881/2000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.1915 - val_loss: 14.2449\n",
            "Epoch 882/2000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.1959 - val_loss: 13.7912\n",
            "Epoch 883/2000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.1997 - val_loss: 13.5276\n",
            "Epoch 884/2000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.2039 - val_loss: 13.3884\n",
            "Epoch 885/2000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.2043 - val_loss: 13.4106\n",
            "Epoch 886/2000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.1990 - val_loss: 13.8602\n",
            "Epoch 887/2000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.1896 - val_loss: 14.5234\n",
            "Epoch 888/2000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1.1922 - val_loss: 15.0504\n",
            "Epoch 889/2000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.1797 - val_loss: 15.2578\n",
            "Epoch 890/2000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.1765 - val_loss: 15.2002\n",
            "Epoch 891/2000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.1835 - val_loss: 14.7801\n",
            "Epoch 892/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.1780 - val_loss: 14.6494\n",
            "Epoch 893/2000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.1782 - val_loss: 14.8274\n",
            "Epoch 894/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.1798 - val_loss: 15.0491\n",
            "Epoch 895/2000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1.1744 - val_loss: 14.6385\n",
            "Epoch 896/2000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1.1739 - val_loss: 14.6826\n",
            "Epoch 897/2000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.1698 - val_loss: 15.0582\n",
            "Epoch 898/2000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.1704 - val_loss: 15.1586\n",
            "Epoch 899/2000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.1706 - val_loss: 14.8755\n",
            "Epoch 900/2000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.1655 - val_loss: 15.0046\n",
            "Epoch 901/2000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.1636 - val_loss: 15.0081\n",
            "Epoch 902/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.1623 - val_loss: 14.8215\n",
            "Epoch 903/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1632 - val_loss: 14.6115\n",
            "Epoch 904/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.1612 - val_loss: 14.5968\n",
            "Epoch 905/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1636 - val_loss: 14.5241\n",
            "Epoch 906/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.1587 - val_loss: 14.7496\n",
            "Epoch 907/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1565 - val_loss: 14.8786\n",
            "Epoch 908/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1549 - val_loss: 14.9898\n",
            "Epoch 909/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.1537 - val_loss: 15.0702\n",
            "Epoch 910/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.1503 - val_loss: 15.3410\n",
            "Epoch 911/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1493 - val_loss: 15.5566\n",
            "Epoch 912/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1548 - val_loss: 15.7948\n",
            "Epoch 913/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1493 - val_loss: 15.1843\n",
            "Epoch 914/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.1438 - val_loss: 14.6302\n",
            "Epoch 915/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1669 - val_loss: 13.9270\n",
            "Epoch 916/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.1534 - val_loss: 13.9777\n",
            "Epoch 917/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1535 - val_loss: 14.5633\n",
            "Epoch 918/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1481 - val_loss: 15.3038\n",
            "Epoch 919/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1398 - val_loss: 15.8683\n",
            "Epoch 920/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1535 - val_loss: 16.3726\n",
            "Epoch 921/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1495 - val_loss: 16.5027\n",
            "Epoch 922/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1482 - val_loss: 16.5675\n",
            "Epoch 923/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.1512 - val_loss: 16.7918\n",
            "Epoch 924/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1494 - val_loss: 16.9054\n",
            "Epoch 925/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1534 - val_loss: 17.0471\n",
            "Epoch 926/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.1501 - val_loss: 16.7900\n",
            "Epoch 927/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.1413 - val_loss: 16.2989\n",
            "Epoch 928/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1276 - val_loss: 15.3195\n",
            "Epoch 929/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.1227 - val_loss: 14.5560\n",
            "Epoch 930/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.1253 - val_loss: 14.3720\n",
            "Epoch 931/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.1254 - val_loss: 14.2505\n",
            "Epoch 932/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1234 - val_loss: 14.1334\n",
            "Epoch 933/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1252 - val_loss: 14.2241\n",
            "Epoch 934/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1272 - val_loss: 14.1132\n",
            "Epoch 935/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1199 - val_loss: 14.2897\n",
            "Epoch 936/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1164 - val_loss: 14.5902\n",
            "Epoch 937/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1171 - val_loss: 15.2321\n",
            "Epoch 938/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1134 - val_loss: 15.8796\n",
            "Epoch 939/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1202 - val_loss: 16.4652\n",
            "Epoch 940/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.1285 - val_loss: 17.0272\n",
            "Epoch 941/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1404 - val_loss: 17.2559\n",
            "Epoch 942/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1367 - val_loss: 16.7666\n",
            "Epoch 943/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.1407 - val_loss: 16.0214\n",
            "Epoch 944/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.1162 - val_loss: 15.8490\n",
            "Epoch 945/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1167 - val_loss: 15.8481\n",
            "Epoch 946/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1169 - val_loss: 15.4682\n",
            "Epoch 947/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1087 - val_loss: 15.5079\n",
            "Epoch 948/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1113 - val_loss: 15.5105\n",
            "Epoch 949/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1119 - val_loss: 14.8384\n",
            "Epoch 950/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0946 - val_loss: 14.3062\n",
            "Epoch 951/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0951 - val_loss: 13.6705\n",
            "Epoch 952/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.1004 - val_loss: 13.5232\n",
            "Epoch 953/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.1000 - val_loss: 13.5523\n",
            "Epoch 954/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0960 - val_loss: 13.8750\n",
            "Epoch 955/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1031 - val_loss: 14.4774\n",
            "Epoch 956/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.0915 - val_loss: 14.6463\n",
            "Epoch 957/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0911 - val_loss: 14.8794\n",
            "Epoch 958/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0895 - val_loss: 15.3141\n",
            "Epoch 959/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0905 - val_loss: 15.7333\n",
            "Epoch 960/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0984 - val_loss: 15.9385\n",
            "Epoch 961/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0983 - val_loss: 15.8181\n",
            "Epoch 962/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0999 - val_loss: 15.4697\n",
            "Epoch 963/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0924 - val_loss: 15.4516\n",
            "Epoch 964/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0875 - val_loss: 15.5689\n",
            "Epoch 965/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0878 - val_loss: 15.5605\n",
            "Epoch 966/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0874 - val_loss: 15.7029\n",
            "Epoch 967/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0883 - val_loss: 15.9104\n",
            "Epoch 968/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0977 - val_loss: 15.7040\n",
            "Epoch 969/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0884 - val_loss: 15.9435\n",
            "Epoch 970/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0876 - val_loss: 15.7397\n",
            "Epoch 971/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0786 - val_loss: 15.1747\n",
            "Epoch 972/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0750 - val_loss: 15.0000\n",
            "Epoch 973/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0747 - val_loss: 14.8368\n",
            "Epoch 974/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0697 - val_loss: 14.9313\n",
            "Epoch 975/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0706 - val_loss: 14.8057\n",
            "Epoch 976/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0691 - val_loss: 14.5374\n",
            "Epoch 977/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0592 - val_loss: 13.3953\n",
            "Epoch 978/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0713 - val_loss: 12.1527\n",
            "Epoch 979/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0861 - val_loss: 11.6504\n",
            "Epoch 980/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0943 - val_loss: 11.4305\n",
            "Epoch 981/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.1052 - val_loss: 11.3188\n",
            "Epoch 982/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1052 - val_loss: 11.5644\n",
            "Epoch 983/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0900 - val_loss: 11.8994\n",
            "Epoch 984/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0713 - val_loss: 12.6267\n",
            "Epoch 985/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0623 - val_loss: 13.3138\n",
            "Epoch 986/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0530 - val_loss: 13.9438\n",
            "Epoch 987/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0481 - val_loss: 14.3868\n",
            "Epoch 988/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0521 - val_loss: 14.9353\n",
            "Epoch 989/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0522 - val_loss: 15.0349\n",
            "Epoch 990/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0545 - val_loss: 14.8524\n",
            "Epoch 991/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0410 - val_loss: 13.8465\n",
            "Epoch 992/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0444 - val_loss: 13.0344\n",
            "Epoch 993/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0649 - val_loss: 12.4651\n",
            "Epoch 994/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0513 - val_loss: 12.5881\n",
            "Epoch 995/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0502 - val_loss: 12.6224\n",
            "Epoch 996/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0448 - val_loss: 12.8265\n",
            "Epoch 997/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0397 - val_loss: 13.1951\n",
            "Epoch 998/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0454 - val_loss: 13.8149\n",
            "Epoch 999/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0408 - val_loss: 14.0553\n",
            "Epoch 1000/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0341 - val_loss: 13.4895\n",
            "Epoch 1001/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0288 - val_loss: 12.5809\n",
            "Epoch 1002/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0351 - val_loss: 12.0777\n",
            "Epoch 1003/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0525 - val_loss: 11.3517\n",
            "Epoch 1004/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0600 - val_loss: 11.1998\n",
            "Epoch 1005/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0745 - val_loss: 10.8042\n",
            "Epoch 1006/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0724 - val_loss: 11.1459\n",
            "Epoch 1007/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0540 - val_loss: 11.4289\n",
            "Epoch 1008/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0415 - val_loss: 12.0578\n",
            "Epoch 1009/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0353 - val_loss: 12.9588\n",
            "Epoch 1010/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0263 - val_loss: 13.2948\n",
            "Epoch 1011/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0135 - val_loss: 12.9261\n",
            "Epoch 1012/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0206 - val_loss: 12.7210\n",
            "Epoch 1013/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0163 - val_loss: 12.9048\n",
            "Epoch 1014/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0145 - val_loss: 12.7307\n",
            "Epoch 1015/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0141 - val_loss: 12.1374\n",
            "Epoch 1016/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0222 - val_loss: 11.9724\n",
            "Epoch 1017/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0201 - val_loss: 12.0023\n",
            "Epoch 1018/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0188 - val_loss: 11.8257\n",
            "Epoch 1019/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0130 - val_loss: 12.2354\n",
            "Epoch 1020/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0133 - val_loss: 13.0473\n",
            "Epoch 1021/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0025 - val_loss: 13.7337\n",
            "Epoch 1022/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0041 - val_loss: 14.0995\n",
            "Epoch 1023/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0062 - val_loss: 14.2211\n",
            "Epoch 1024/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0045 - val_loss: 14.0067\n",
            "Epoch 1025/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0021 - val_loss: 13.8602\n",
            "Epoch 1026/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9986 - val_loss: 13.7732\n",
            "Epoch 1027/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9973 - val_loss: 13.6817\n",
            "Epoch 1028/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9997 - val_loss: 13.5817\n",
            "Epoch 1029/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0054 - val_loss: 12.6699\n",
            "Epoch 1030/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9910 - val_loss: 12.3046\n",
            "Epoch 1031/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9868 - val_loss: 11.5721\n",
            "Epoch 1032/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0003 - val_loss: 11.2372\n",
            "Epoch 1033/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0118 - val_loss: 11.1312\n",
            "Epoch 1034/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0016 - val_loss: 11.6822\n",
            "Epoch 1035/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9871 - val_loss: 12.1038\n",
            "Epoch 1036/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.9825 - val_loss: 12.4602\n",
            "Epoch 1037/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9744 - val_loss: 13.0722\n",
            "Epoch 1038/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9727 - val_loss: 13.6856\n",
            "Epoch 1039/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9836 - val_loss: 14.0491\n",
            "Epoch 1040/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9844 - val_loss: 13.6701\n",
            "Epoch 1041/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9807 - val_loss: 13.1665\n",
            "Epoch 1042/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9745 - val_loss: 13.0651\n",
            "Epoch 1043/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9739 - val_loss: 13.2796\n",
            "Epoch 1044/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9785 - val_loss: 13.4926\n",
            "Epoch 1045/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9770 - val_loss: 13.0897\n",
            "Epoch 1046/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9700 - val_loss: 13.1531\n",
            "Epoch 1047/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9662 - val_loss: 13.4350\n",
            "Epoch 1048/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9846 - val_loss: 13.8811\n",
            "Epoch 1049/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9756 - val_loss: 13.8281\n",
            "Epoch 1050/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9752 - val_loss: 14.0214\n",
            "Epoch 1051/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9751 - val_loss: 13.8056\n",
            "Epoch 1052/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9687 - val_loss: 13.6368\n",
            "Epoch 1053/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9647 - val_loss: 13.4033\n",
            "Epoch 1054/2000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.9610 - val_loss: 13.1678\n",
            "Epoch 1055/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9629 - val_loss: 13.2740\n",
            "Epoch 1056/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9625 - val_loss: 13.2789\n",
            "Epoch 1057/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9526 - val_loss: 12.7956\n",
            "Epoch 1058/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9501 - val_loss: 12.2870\n",
            "Epoch 1059/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9497 - val_loss: 12.0982\n",
            "Epoch 1060/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9494 - val_loss: 12.1125\n",
            "Epoch 1061/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9497 - val_loss: 12.1369\n",
            "Epoch 1062/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9475 - val_loss: 11.9731\n",
            "Epoch 1063/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.9454 - val_loss: 11.8869\n",
            "Epoch 1064/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9451 - val_loss: 11.8907\n",
            "Epoch 1065/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9417 - val_loss: 12.2185\n",
            "Epoch 1066/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9502 - val_loss: 12.5504\n",
            "Epoch 1067/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9396 - val_loss: 12.3362\n",
            "Epoch 1068/2000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.9393 - val_loss: 12.4596\n",
            "Epoch 1069/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.9459 - val_loss: 12.9053\n",
            "Epoch 1070/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9430 - val_loss: 13.3452\n",
            "Epoch 1071/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9451 - val_loss: 13.6754\n",
            "Epoch 1072/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9472 - val_loss: 13.5012\n",
            "Epoch 1073/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9422 - val_loss: 13.1509\n",
            "Epoch 1074/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9326 - val_loss: 12.3991\n",
            "Epoch 1075/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9258 - val_loss: 11.8373\n",
            "Epoch 1076/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9343 - val_loss: 11.1113\n",
            "Epoch 1077/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9375 - val_loss: 10.8346\n",
            "Epoch 1078/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.9478 - val_loss: 10.5312\n",
            "Epoch 1079/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9354 - val_loss: 10.9647\n",
            "Epoch 1080/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9200 - val_loss: 11.6855\n",
            "Epoch 1081/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9124 - val_loss: 12.4830\n",
            "Epoch 1082/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9201 - val_loss: 13.2990\n",
            "Epoch 1083/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9361 - val_loss: 13.8519\n",
            "Epoch 1084/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9537 - val_loss: 13.9896\n",
            "Epoch 1085/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9503 - val_loss: 12.8302\n",
            "Epoch 1086/2000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.9208 - val_loss: 12.0898\n",
            "Epoch 1087/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9173 - val_loss: 11.5357\n",
            "Epoch 1088/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.9160 - val_loss: 11.0738\n",
            "Epoch 1089/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9237 - val_loss: 10.8799\n",
            "Epoch 1090/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9129 - val_loss: 11.2784\n",
            "Epoch 1091/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9075 - val_loss: 11.9241\n",
            "Epoch 1092/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9192 - val_loss: 12.7183\n",
            "Epoch 1093/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.9146 - val_loss: 13.0997\n",
            "Epoch 1094/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9223 - val_loss: 13.5232\n",
            "Epoch 1095/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9303 - val_loss: 13.6047\n",
            "Epoch 1096/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9353 - val_loss: 13.6974\n",
            "Epoch 1097/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9335 - val_loss: 13.5717\n",
            "Epoch 1098/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9272 - val_loss: 13.1104\n",
            "Epoch 1099/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9168 - val_loss: 12.1740\n",
            "Epoch 1100/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9023 - val_loss: 11.8317\n",
            "Epoch 1101/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8992 - val_loss: 11.5181\n",
            "Epoch 1102/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9000 - val_loss: 10.8009\n",
            "Epoch 1103/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9036 - val_loss: 10.3817\n",
            "Epoch 1104/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9025 - val_loss: 10.2461\n",
            "Epoch 1105/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9038 - val_loss: 10.2487\n",
            "Epoch 1106/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9093 - val_loss: 10.7307\n",
            "Epoch 1107/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8980 - val_loss: 10.9755\n",
            "Epoch 1108/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8934 - val_loss: 11.0288\n",
            "Epoch 1109/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8996 - val_loss: 10.9003\n",
            "Epoch 1110/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9045 - val_loss: 11.4502\n",
            "Epoch 1111/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8877 - val_loss: 11.5879\n",
            "Epoch 1112/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8848 - val_loss: 12.0772\n",
            "Epoch 1113/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8913 - val_loss: 12.2999\n",
            "Epoch 1114/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8887 - val_loss: 11.9454\n",
            "Epoch 1115/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8847 - val_loss: 11.8837\n",
            "Epoch 1116/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8830 - val_loss: 11.9546\n",
            "Epoch 1117/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8831 - val_loss: 12.2469\n",
            "Epoch 1118/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8843 - val_loss: 12.6632\n",
            "Epoch 1119/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8956 - val_loss: 13.1555\n",
            "Epoch 1120/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9092 - val_loss: 13.3714\n",
            "Epoch 1121/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9041 - val_loss: 13.0262\n",
            "Epoch 1122/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8939 - val_loss: 12.3502\n",
            "Epoch 1123/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8730 - val_loss: 11.6133\n",
            "Epoch 1124/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8653 - val_loss: 10.4374\n",
            "Epoch 1125/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8787 - val_loss: 9.1786\n",
            "Epoch 1126/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8975 - val_loss: 8.8008\n",
            "Epoch 1127/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9106 - val_loss: 8.8923\n",
            "Epoch 1128/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9023 - val_loss: 9.1151\n",
            "Epoch 1129/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8914 - val_loss: 9.8019\n",
            "Epoch 1130/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8685 - val_loss: 10.3255\n",
            "Epoch 1131/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8739 - val_loss: 11.0674\n",
            "Epoch 1132/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8606 - val_loss: 11.4813\n",
            "Epoch 1133/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8644 - val_loss: 11.4215\n",
            "Epoch 1134/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8601 - val_loss: 11.4710\n",
            "Epoch 1135/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8587 - val_loss: 11.5665\n",
            "Epoch 1136/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8611 - val_loss: 11.6491\n",
            "Epoch 1137/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8621 - val_loss: 11.3636\n",
            "Epoch 1138/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8551 - val_loss: 11.4475\n",
            "Epoch 1139/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8543 - val_loss: 11.6816\n",
            "Epoch 1140/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8591 - val_loss: 11.6873\n",
            "Epoch 1141/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8662 - val_loss: 10.9645\n",
            "Epoch 1142/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8478 - val_loss: 10.6569\n",
            "Epoch 1143/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8532 - val_loss: 10.3699\n",
            "Epoch 1144/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8483 - val_loss: 10.5760\n",
            "Epoch 1145/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8518 - val_loss: 10.6086\n",
            "Epoch 1146/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8463 - val_loss: 9.9623\n",
            "Epoch 1147/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8513 - val_loss: 9.8224\n",
            "Epoch 1148/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8566 - val_loss: 10.0392\n",
            "Epoch 1149/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8431 - val_loss: 9.8417\n",
            "Epoch 1150/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8507 - val_loss: 9.6059\n",
            "Epoch 1151/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8531 - val_loss: 9.6013\n",
            "Epoch 1152/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8682 - val_loss: 8.9294\n",
            "Epoch 1153/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8594 - val_loss: 8.9993\n",
            "Epoch 1154/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8506 - val_loss: 9.6185\n",
            "Epoch 1155/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8355 - val_loss: 10.4552\n",
            "Epoch 1156/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8293 - val_loss: 11.0332\n",
            "Epoch 1157/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8388 - val_loss: 11.5638\n",
            "Epoch 1158/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8419 - val_loss: 11.3459\n",
            "Epoch 1159/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8425 - val_loss: 10.1347\n",
            "Epoch 1160/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8231 - val_loss: 9.2491\n",
            "Epoch 1161/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8362 - val_loss: 8.1664\n",
            "Epoch 1162/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8794 - val_loss: 7.4659\n",
            "Epoch 1163/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8981 - val_loss: 7.4705\n",
            "Epoch 1164/2000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.8883 - val_loss: 8.1068\n",
            "Epoch 1165/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8840 - val_loss: 9.1023\n",
            "Epoch 1166/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8282 - val_loss: 9.5363\n",
            "Epoch 1167/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8188 - val_loss: 10.2643\n",
            "Epoch 1168/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8197 - val_loss: 11.1546\n",
            "Epoch 1169/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8322 - val_loss: 11.7255\n",
            "Epoch 1170/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8435 - val_loss: 11.9097\n",
            "Epoch 1171/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8387 - val_loss: 11.7917\n",
            "Epoch 1172/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8362 - val_loss: 11.7694\n",
            "Epoch 1173/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8305 - val_loss: 11.2174\n",
            "Epoch 1174/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8105 - val_loss: 9.8102\n",
            "Epoch 1175/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8149 - val_loss: 8.7522\n",
            "Epoch 1176/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8204 - val_loss: 8.0680\n",
            "Epoch 1177/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8425 - val_loss: 7.8221\n",
            "Epoch 1178/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8536 - val_loss: 7.7623\n",
            "Epoch 1179/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8540 - val_loss: 8.1246\n",
            "Epoch 1180/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8323 - val_loss: 8.5435\n",
            "Epoch 1181/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8250 - val_loss: 9.4289\n",
            "Epoch 1182/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8143 - val_loss: 9.8895\n",
            "Epoch 1183/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8017 - val_loss: 9.5983\n",
            "Epoch 1184/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8047 - val_loss: 9.6488\n",
            "Epoch 1185/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8067 - val_loss: 10.1972\n",
            "Epoch 1186/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8000 - val_loss: 10.7424\n",
            "Epoch 1187/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8025 - val_loss: 11.2779\n",
            "Epoch 1188/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8187 - val_loss: 11.7825\n",
            "Epoch 1189/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8267 - val_loss: 11.7683\n",
            "Epoch 1190/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8200 - val_loss: 11.3599\n",
            "Epoch 1191/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8077 - val_loss: 10.3481\n",
            "Epoch 1192/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7859 - val_loss: 8.9294\n",
            "Epoch 1193/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8128 - val_loss: 8.1993\n",
            "Epoch 1194/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8130 - val_loss: 8.3234\n",
            "Epoch 1195/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7989 - val_loss: 8.9919\n",
            "Epoch 1196/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7931 - val_loss: 9.6297\n",
            "Epoch 1197/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7904 - val_loss: 10.2525\n",
            "Epoch 1198/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7914 - val_loss: 10.3874\n",
            "Epoch 1199/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7938 - val_loss: 10.1336\n",
            "Epoch 1200/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7877 - val_loss: 9.9739\n",
            "Epoch 1201/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7846 - val_loss: 9.9258\n",
            "Epoch 1202/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7819 - val_loss: 10.1409\n",
            "Epoch 1203/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7877 - val_loss: 10.5762\n",
            "Epoch 1204/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7866 - val_loss: 10.5448\n",
            "Epoch 1205/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7972 - val_loss: 10.8086\n",
            "Epoch 1206/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7868 - val_loss: 10.6417\n",
            "Epoch 1207/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7847 - val_loss: 10.3081\n",
            "Epoch 1208/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7807 - val_loss: 10.0339\n",
            "Epoch 1209/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7782 - val_loss: 9.8738\n",
            "Epoch 1210/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7744 - val_loss: 9.8202\n",
            "Epoch 1211/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7751 - val_loss: 9.4850\n",
            "Epoch 1212/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7726 - val_loss: 9.0803\n",
            "Epoch 1213/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7742 - val_loss: 9.0996\n",
            "Epoch 1214/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7744 - val_loss: 9.0888\n",
            "Epoch 1215/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7719 - val_loss: 9.2228\n",
            "Epoch 1216/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7687 - val_loss: 9.4867\n",
            "Epoch 1217/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7727 - val_loss: 10.0604\n",
            "Epoch 1218/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7682 - val_loss: 10.1877\n",
            "Epoch 1219/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7697 - val_loss: 9.9591\n",
            "Epoch 1220/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7585 - val_loss: 9.0314\n",
            "Epoch 1221/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7861 - val_loss: 8.4631\n",
            "Epoch 1222/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7711 - val_loss: 8.6874\n",
            "Epoch 1223/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7681 - val_loss: 9.2512\n",
            "Epoch 1224/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7619 - val_loss: 9.3743\n",
            "Epoch 1225/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7598 - val_loss: 9.7012\n",
            "Epoch 1226/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7602 - val_loss: 10.2573\n",
            "Epoch 1227/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7684 - val_loss: 10.7699\n",
            "Epoch 1228/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7718 - val_loss: 10.9914\n",
            "Epoch 1229/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7770 - val_loss: 10.8108\n",
            "Epoch 1230/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7763 - val_loss: 10.2994\n",
            "Epoch 1231/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7626 - val_loss: 10.1542\n",
            "Epoch 1232/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7573 - val_loss: 9.7976\n",
            "Epoch 1233/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7542 - val_loss: 9.2508\n",
            "Epoch 1234/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7531 - val_loss: 9.0499\n",
            "Epoch 1235/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7531 - val_loss: 9.4568\n",
            "Epoch 1236/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7525 - val_loss: 9.9315\n",
            "Epoch 1237/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7525 - val_loss: 9.9927\n",
            "Epoch 1238/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7544 - val_loss: 10.0455\n",
            "Epoch 1239/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7541 - val_loss: 9.7814\n",
            "Epoch 1240/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7548 - val_loss: 9.6201\n",
            "Epoch 1241/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7537 - val_loss: 10.0677\n",
            "Epoch 1242/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7504 - val_loss: 10.2695\n",
            "Epoch 1243/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7523 - val_loss: 10.5879\n",
            "Epoch 1244/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7612 - val_loss: 10.6063\n",
            "Epoch 1245/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7608 - val_loss: 9.9991\n",
            "Epoch 1246/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7442 - val_loss: 9.5211\n",
            "Epoch 1247/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7435 - val_loss: 9.1714\n",
            "Epoch 1248/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7391 - val_loss: 9.1741\n",
            "Epoch 1249/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7388 - val_loss: 9.0439\n",
            "Epoch 1250/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7400 - val_loss: 8.8857\n",
            "Epoch 1251/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7307 - val_loss: 8.1553\n",
            "Epoch 1252/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7524 - val_loss: 7.8936\n",
            "Epoch 1253/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7447 - val_loss: 8.1111\n",
            "Epoch 1254/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7388 - val_loss: 8.4907\n",
            "Epoch 1255/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7445 - val_loss: 9.1755\n",
            "Epoch 1256/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7314 - val_loss: 9.5917\n",
            "Epoch 1257/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7355 - val_loss: 10.0592\n",
            "Epoch 1258/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7496 - val_loss: 10.4104\n",
            "Epoch 1259/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7455 - val_loss: 10.1751\n",
            "Epoch 1260/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7420 - val_loss: 9.6359\n",
            "Epoch 1261/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7309 - val_loss: 9.2790\n",
            "Epoch 1262/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7310 - val_loss: 9.1810\n",
            "Epoch 1263/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7265 - val_loss: 9.3259\n",
            "Epoch 1264/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7301 - val_loss: 9.7928\n",
            "Epoch 1265/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7342 - val_loss: 9.6830\n",
            "Epoch 1266/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7280 - val_loss: 9.7179\n",
            "Epoch 1267/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7299 - val_loss: 9.7262\n",
            "Epoch 1268/2000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.7233 - val_loss: 9.3734\n",
            "Epoch 1269/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7172 - val_loss: 8.8921\n",
            "Epoch 1270/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7267 - val_loss: 8.4653\n",
            "Epoch 1271/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7198 - val_loss: 8.4660\n",
            "Epoch 1272/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7188 - val_loss: 8.2807\n",
            "Epoch 1273/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7149 - val_loss: 7.5584\n",
            "Epoch 1274/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7328 - val_loss: 7.2318\n",
            "Epoch 1275/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7407 - val_loss: 7.2853\n",
            "Epoch 1276/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7261 - val_loss: 8.0250\n",
            "Epoch 1277/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7359 - val_loss: 8.9144\n",
            "Epoch 1278/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7143 - val_loss: 9.0421\n",
            "Epoch 1279/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7111 - val_loss: 9.1908\n",
            "Epoch 1280/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7100 - val_loss: 9.4453\n",
            "Epoch 1281/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7179 - val_loss: 9.9399\n",
            "Epoch 1282/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7268 - val_loss: 10.1962\n",
            "Epoch 1283/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7311 - val_loss: 10.3291\n",
            "Epoch 1284/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7319 - val_loss: 10.1181\n",
            "Epoch 1285/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7259 - val_loss: 9.8648\n",
            "Epoch 1286/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7224 - val_loss: 9.7377\n",
            "Epoch 1287/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7162 - val_loss: 9.7633\n",
            "Epoch 1288/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7162 - val_loss: 9.5300\n",
            "Epoch 1289/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7076 - val_loss: 8.9252\n",
            "Epoch 1290/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6977 - val_loss: 8.4249\n",
            "Epoch 1291/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7038 - val_loss: 8.0603\n",
            "Epoch 1292/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6985 - val_loss: 8.2400\n",
            "Epoch 1293/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6985 - val_loss: 8.6991\n",
            "Epoch 1294/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6913 - val_loss: 9.1485\n",
            "Epoch 1295/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6973 - val_loss: 9.6460\n",
            "Epoch 1296/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7165 - val_loss: 9.9850\n",
            "Epoch 1297/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7147 - val_loss: 9.7823\n",
            "Epoch 1298/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7080 - val_loss: 9.5830\n",
            "Epoch 1299/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7033 - val_loss: 9.0737\n",
            "Epoch 1300/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6951 - val_loss: 8.9237\n",
            "Epoch 1301/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6931 - val_loss: 8.9192\n",
            "Epoch 1302/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6984 - val_loss: 8.7525\n",
            "Epoch 1303/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6881 - val_loss: 7.5465\n",
            "Epoch 1304/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6841 - val_loss: 6.9026\n",
            "Epoch 1305/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7222 - val_loss: 6.4010\n",
            "Epoch 1306/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7222 - val_loss: 6.4759\n",
            "Epoch 1307/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7144 - val_loss: 6.8146\n",
            "Epoch 1308/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7064 - val_loss: 7.7978\n",
            "Epoch 1309/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6881 - val_loss: 8.6098\n",
            "Epoch 1310/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6860 - val_loss: 9.0930\n",
            "Epoch 1311/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6908 - val_loss: 8.9785\n",
            "Epoch 1312/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6899 - val_loss: 9.1059\n",
            "Epoch 1313/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6811 - val_loss: 8.5865\n",
            "Epoch 1314/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6778 - val_loss: 8.3553\n",
            "Epoch 1315/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6771 - val_loss: 8.0433\n",
            "Epoch 1316/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6756 - val_loss: 8.0599\n",
            "Epoch 1317/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6744 - val_loss: 8.5276\n",
            "Epoch 1318/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6756 - val_loss: 9.1542\n",
            "Epoch 1319/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6884 - val_loss: 9.5519\n",
            "Epoch 1320/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6893 - val_loss: 9.2506\n",
            "Epoch 1321/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6828 - val_loss: 8.7377\n",
            "Epoch 1322/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6794 - val_loss: 8.2243\n",
            "Epoch 1323/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6718 - val_loss: 7.8620\n",
            "Epoch 1324/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6679 - val_loss: 7.8687\n",
            "Epoch 1325/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6681 - val_loss: 7.6153\n",
            "Epoch 1326/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6613 - val_loss: 6.6980\n",
            "Epoch 1327/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6976 - val_loss: 5.6973\n",
            "Epoch 1328/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7263 - val_loss: 5.5202\n",
            "Epoch 1329/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7285 - val_loss: 5.7301\n",
            "Epoch 1330/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7077 - val_loss: 6.2394\n",
            "Epoch 1331/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6876 - val_loss: 6.9760\n",
            "Epoch 1332/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6676 - val_loss: 7.8863\n",
            "Epoch 1333/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6553 - val_loss: 8.3945\n",
            "Epoch 1334/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6758 - val_loss: 8.7893\n",
            "Epoch 1335/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6524 - val_loss: 7.6655\n",
            "Epoch 1336/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6384 - val_loss: 6.3197\n",
            "Epoch 1337/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6971 - val_loss: 5.6039\n",
            "Epoch 1338/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7067 - val_loss: 5.8196\n",
            "Epoch 1339/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6915 - val_loss: 6.4089\n",
            "Epoch 1340/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6585 - val_loss: 7.3883\n",
            "Epoch 1341/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6451 - val_loss: 8.5924\n",
            "Epoch 1342/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6823 - val_loss: 9.4243\n",
            "Epoch 1343/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6700 - val_loss: 8.9620\n",
            "Epoch 1344/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6737 - val_loss: 8.0295\n",
            "Epoch 1345/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6518 - val_loss: 7.5798\n",
            "Epoch 1346/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6469 - val_loss: 7.5727\n",
            "Epoch 1347/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6412 - val_loss: 7.8990\n",
            "Epoch 1348/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6569 - val_loss: 8.5132\n",
            "Epoch 1349/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6565 - val_loss: 8.3156\n",
            "Epoch 1350/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6695 - val_loss: 7.0460\n",
            "Epoch 1351/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6454 - val_loss: 6.7300\n",
            "Epoch 1352/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6471 - val_loss: 6.6848\n",
            "Epoch 1353/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6411 - val_loss: 7.0678\n",
            "Epoch 1354/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6298 - val_loss: 7.6375\n",
            "Epoch 1355/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6418 - val_loss: 8.4100\n",
            "Epoch 1356/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6469 - val_loss: 8.6979\n",
            "Epoch 1357/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6536 - val_loss: 8.7104\n",
            "Epoch 1358/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6572 - val_loss: 8.8607\n",
            "Epoch 1359/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6535 - val_loss: 8.7952\n",
            "Epoch 1360/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6510 - val_loss: 8.8903\n",
            "Epoch 1361/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6529 - val_loss: 8.8416\n",
            "Epoch 1362/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6539 - val_loss: 8.4681\n",
            "Epoch 1363/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6414 - val_loss: 8.2763\n",
            "Epoch 1364/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6379 - val_loss: 8.2886\n",
            "Epoch 1365/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6364 - val_loss: 8.1681\n",
            "Epoch 1366/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6389 - val_loss: 7.9260\n",
            "Epoch 1367/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6402 - val_loss: 6.8331\n",
            "Epoch 1368/2000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6290 - val_loss: 6.2696\n",
            "Epoch 1369/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6335 - val_loss: 6.3127\n",
            "Epoch 1370/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6304 - val_loss: 6.6162\n",
            "Epoch 1371/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6206 - val_loss: 7.0367\n",
            "Epoch 1372/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6233 - val_loss: 7.8429\n",
            "Epoch 1373/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6311 - val_loss: 8.4976\n",
            "Epoch 1374/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6437 - val_loss: 8.5411\n",
            "Epoch 1375/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6355 - val_loss: 8.0775\n",
            "Epoch 1376/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6281 - val_loss: 7.7315\n",
            "Epoch 1377/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6238 - val_loss: 7.3680\n",
            "Epoch 1378/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6167 - val_loss: 7.2963\n",
            "Epoch 1379/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6163 - val_loss: 7.0710\n",
            "Epoch 1380/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6156 - val_loss: 6.8987\n",
            "Epoch 1381/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6188 - val_loss: 6.6889\n",
            "Epoch 1382/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6144 - val_loss: 6.7763\n",
            "Epoch 1383/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6159 - val_loss: 7.0004\n",
            "Epoch 1384/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6182 - val_loss: 7.4489\n",
            "Epoch 1385/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6143 - val_loss: 7.6757\n",
            "Epoch 1386/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6156 - val_loss: 7.7373\n",
            "Epoch 1387/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6165 - val_loss: 7.6657\n",
            "Epoch 1388/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6156 - val_loss: 7.9235\n",
            "Epoch 1389/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6222 - val_loss: 8.1374\n",
            "Epoch 1390/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6208 - val_loss: 7.8606\n",
            "Epoch 1391/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6219 - val_loss: 7.8171\n",
            "Epoch 1392/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6114 - val_loss: 7.4533\n",
            "Epoch 1393/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6010 - val_loss: 6.7722\n",
            "Epoch 1394/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5919 - val_loss: 5.5165\n",
            "Epoch 1395/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6275 - val_loss: 4.8783\n",
            "Epoch 1396/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6502 - val_loss: 4.9662\n",
            "Epoch 1397/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6288 - val_loss: 5.7448\n",
            "Epoch 1398/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5958 - val_loss: 6.6004\n",
            "Epoch 1399/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6003 - val_loss: 7.7554\n",
            "Epoch 1400/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6096 - val_loss: 8.5140\n",
            "Epoch 1401/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6372 - val_loss: 8.8363\n",
            "Epoch 1402/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6463 - val_loss: 8.3179\n",
            "Epoch 1403/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6087 - val_loss: 7.0327\n",
            "Epoch 1404/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6003 - val_loss: 6.4398\n",
            "Epoch 1405/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5977 - val_loss: 6.4750\n",
            "Epoch 1406/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5942 - val_loss: 6.2576\n",
            "Epoch 1407/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5933 - val_loss: 6.2172\n",
            "Epoch 1408/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5961 - val_loss: 6.1784\n",
            "Epoch 1409/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5907 - val_loss: 5.5382\n",
            "Epoch 1410/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6052 - val_loss: 5.2749\n",
            "Epoch 1411/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6079 - val_loss: 5.4510\n",
            "Epoch 1412/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6000 - val_loss: 6.2162\n",
            "Epoch 1413/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5853 - val_loss: 6.6283\n",
            "Epoch 1414/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5928 - val_loss: 6.9513\n",
            "Epoch 1415/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5929 - val_loss: 7.2807\n",
            "Epoch 1416/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5927 - val_loss: 7.1522\n",
            "Epoch 1417/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5915 - val_loss: 6.9187\n",
            "Epoch 1418/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5869 - val_loss: 6.9771\n",
            "Epoch 1419/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5895 - val_loss: 7.0420\n",
            "Epoch 1420/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5858 - val_loss: 6.8578\n",
            "Epoch 1421/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5887 - val_loss: 6.6859\n",
            "Epoch 1422/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5683 - val_loss: 5.6953\n",
            "Epoch 1423/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5841 - val_loss: 4.9988\n",
            "Epoch 1424/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5989 - val_loss: 4.7457\n",
            "Epoch 1425/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6112 - val_loss: 4.7648\n",
            "Epoch 1426/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6110 - val_loss: 4.8004\n",
            "Epoch 1427/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6134 - val_loss: 4.7409\n",
            "Epoch 1428/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6018 - val_loss: 5.3704\n",
            "Epoch 1429/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5927 - val_loss: 6.0826\n",
            "Epoch 1430/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5750 - val_loss: 6.5420\n",
            "Epoch 1431/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5740 - val_loss: 6.8584\n",
            "Epoch 1432/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5770 - val_loss: 6.9457\n",
            "Epoch 1433/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5754 - val_loss: 6.5873\n",
            "Epoch 1434/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5676 - val_loss: 5.7287\n",
            "Epoch 1435/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5774 - val_loss: 5.0980\n",
            "Epoch 1436/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5858 - val_loss: 4.8914\n",
            "Epoch 1437/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5957 - val_loss: 4.8936\n",
            "Epoch 1438/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5911 - val_loss: 5.1433\n",
            "Epoch 1439/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5824 - val_loss: 5.4039\n",
            "Epoch 1440/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5700 - val_loss: 5.8740\n",
            "Epoch 1441/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5643 - val_loss: 6.3088\n",
            "Epoch 1442/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5635 - val_loss: 6.7697\n",
            "Epoch 1443/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5663 - val_loss: 6.8846\n",
            "Epoch 1444/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5709 - val_loss: 7.1583\n",
            "Epoch 1445/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5739 - val_loss: 7.2379\n",
            "Epoch 1446/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5725 - val_loss: 7.0924\n",
            "Epoch 1447/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5694 - val_loss: 6.7810\n",
            "Epoch 1448/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5656 - val_loss: 6.4295\n",
            "Epoch 1449/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5630 - val_loss: 6.0287\n",
            "Epoch 1450/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5611 - val_loss: 6.0213\n",
            "Epoch 1451/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5599 - val_loss: 5.9404\n",
            "Epoch 1452/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5615 - val_loss: 6.0199\n",
            "Epoch 1453/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5588 - val_loss: 5.3505\n",
            "Epoch 1454/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5662 - val_loss: 5.2632\n",
            "Epoch 1455/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5604 - val_loss: 5.8777\n",
            "Epoch 1456/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5554 - val_loss: 6.6920\n",
            "Epoch 1457/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5645 - val_loss: 7.3163\n",
            "Epoch 1458/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5764 - val_loss: 7.6530\n",
            "Epoch 1459/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5952 - val_loss: 7.7376\n",
            "Epoch 1460/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5846 - val_loss: 7.1148\n",
            "Epoch 1461/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5712 - val_loss: 6.3833\n",
            "Epoch 1462/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5523 - val_loss: 6.0601\n",
            "Epoch 1463/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5491 - val_loss: 5.9813\n",
            "Epoch 1464/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5488 - val_loss: 6.0419\n",
            "Epoch 1465/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5499 - val_loss: 5.9682\n",
            "Epoch 1466/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5487 - val_loss: 6.0240\n",
            "Epoch 1467/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5482 - val_loss: 6.0765\n",
            "Epoch 1468/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5482 - val_loss: 5.8471\n",
            "Epoch 1469/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5369 - val_loss: 4.9437\n",
            "Epoch 1470/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5581 - val_loss: 4.4823\n",
            "Epoch 1471/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5617 - val_loss: 4.7970\n",
            "Epoch 1472/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5478 - val_loss: 5.3368\n",
            "Epoch 1473/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5310 - val_loss: 6.1545\n",
            "Epoch 1474/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5642 - val_loss: 7.0276\n",
            "Epoch 1475/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5652 - val_loss: 7.0241\n",
            "Epoch 1476/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5621 - val_loss: 6.7525\n",
            "Epoch 1477/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5534 - val_loss: 6.4112\n",
            "Epoch 1478/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5468 - val_loss: 5.8289\n",
            "Epoch 1479/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5362 - val_loss: 5.5923\n",
            "Epoch 1480/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5375 - val_loss: 5.4231\n",
            "Epoch 1481/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5374 - val_loss: 5.4191\n",
            "Epoch 1482/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5385 - val_loss: 4.9544\n",
            "Epoch 1483/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5375 - val_loss: 4.5844\n",
            "Epoch 1484/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5593 - val_loss: 4.0456\n",
            "Epoch 1485/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5595 - val_loss: 4.4524\n",
            "Epoch 1486/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5369 - val_loss: 5.4221\n",
            "Epoch 1487/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5457 - val_loss: 6.1839\n",
            "Epoch 1488/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5414 - val_loss: 6.2811\n",
            "Epoch 1489/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5394 - val_loss: 6.0578\n",
            "Epoch 1490/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5324 - val_loss: 5.6798\n",
            "Epoch 1491/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5288 - val_loss: 5.5416\n",
            "Epoch 1492/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5259 - val_loss: 5.3748\n",
            "Epoch 1493/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5263 - val_loss: 5.4990\n",
            "Epoch 1494/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5289 - val_loss: 5.8177\n",
            "Epoch 1495/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5270 - val_loss: 5.8199\n",
            "Epoch 1496/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5307 - val_loss: 5.7082\n",
            "Epoch 1497/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5309 - val_loss: 5.8584\n",
            "Epoch 1498/2000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5236 - val_loss: 5.4939\n",
            "Epoch 1499/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5349 - val_loss: 4.6991\n",
            "Epoch 1500/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5271 - val_loss: 4.6532\n",
            "Epoch 1501/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5339 - val_loss: 4.8628\n",
            "Epoch 1502/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5231 - val_loss: 4.7691\n",
            "Epoch 1503/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5225 - val_loss: 5.1554\n",
            "Epoch 1504/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5186 - val_loss: 5.2464\n",
            "Epoch 1505/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5184 - val_loss: 5.0538\n",
            "Epoch 1506/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5161 - val_loss: 4.8378\n",
            "Epoch 1507/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5243 - val_loss: 4.3601\n",
            "Epoch 1508/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5291 - val_loss: 4.2059\n",
            "Epoch 1509/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5343 - val_loss: 4.4288\n",
            "Epoch 1510/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5236 - val_loss: 4.4873\n",
            "Epoch 1511/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5196 - val_loss: 4.7778\n",
            "Epoch 1512/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5112 - val_loss: 5.1117\n",
            "Epoch 1513/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5118 - val_loss: 5.2237\n",
            "Epoch 1514/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5125 - val_loss: 5.1755\n",
            "Epoch 1515/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5082 - val_loss: 4.9679\n",
            "Epoch 1516/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5100 - val_loss: 4.7897\n",
            "Epoch 1517/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5127 - val_loss: 4.5543\n",
            "Epoch 1518/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5253 - val_loss: 4.0391\n",
            "Epoch 1519/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5280 - val_loss: 4.3312\n",
            "Epoch 1520/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5149 - val_loss: 4.5725\n",
            "Epoch 1521/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5088 - val_loss: 4.8048\n",
            "Epoch 1522/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5083 - val_loss: 4.8745\n",
            "Epoch 1523/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5061 - val_loss: 5.1585\n",
            "Epoch 1524/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5030 - val_loss: 5.3735\n",
            "Epoch 1525/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5042 - val_loss: 5.2241\n",
            "Epoch 1526/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5039 - val_loss: 5.3289\n",
            "Epoch 1527/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5038 - val_loss: 5.0101\n",
            "Epoch 1528/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5130 - val_loss: 3.9864\n",
            "Epoch 1529/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5132 - val_loss: 3.5903\n",
            "Epoch 1530/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5328 - val_loss: 3.6582\n",
            "Epoch 1531/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5150 - val_loss: 4.3793\n",
            "Epoch 1532/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5228 - val_loss: 5.5273\n",
            "Epoch 1533/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5045 - val_loss: 5.8970\n",
            "Epoch 1534/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5124 - val_loss: 6.0649\n",
            "Epoch 1535/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5154 - val_loss: 5.7805\n",
            "Epoch 1536/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4920 - val_loss: 4.8343\n",
            "Epoch 1537/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5086 - val_loss: 4.0875\n",
            "Epoch 1538/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5043 - val_loss: 4.2073\n",
            "Epoch 1539/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4984 - val_loss: 4.5338\n",
            "Epoch 1540/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4915 - val_loss: 4.7495\n",
            "Epoch 1541/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4918 - val_loss: 4.8965\n",
            "Epoch 1542/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4908 - val_loss: 4.9017\n",
            "Epoch 1543/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4902 - val_loss: 4.8220\n",
            "Epoch 1544/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4879 - val_loss: 5.0774\n",
            "Epoch 1545/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4853 - val_loss: 5.5168\n",
            "Epoch 1546/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5031 - val_loss: 5.9274\n",
            "Epoch 1547/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5067 - val_loss: 5.7039\n",
            "Epoch 1548/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4954 - val_loss: 4.9029\n",
            "Epoch 1549/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4780 - val_loss: 3.8618\n",
            "Epoch 1550/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5455 - val_loss: 2.9291\n",
            "Epoch 1551/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5512 - val_loss: 3.1249\n",
            "Epoch 1552/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5212 - val_loss: 3.8370\n",
            "Epoch 1553/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4892 - val_loss: 4.6981\n",
            "Epoch 1554/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5008 - val_loss: 5.2328\n",
            "Epoch 1555/2000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4870 - val_loss: 4.9617\n",
            "Epoch 1556/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4901 - val_loss: 4.7046\n",
            "Epoch 1557/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4851 - val_loss: 4.6387\n",
            "Epoch 1558/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4879 - val_loss: 4.7432\n",
            "Epoch 1559/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4812 - val_loss: 3.9900\n",
            "Epoch 1560/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4811 - val_loss: 3.7863\n",
            "Epoch 1561/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4876 - val_loss: 3.5175\n",
            "Epoch 1562/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4915 - val_loss: 3.4801\n",
            "Epoch 1563/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4947 - val_loss: 3.4409\n",
            "Epoch 1564/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4923 - val_loss: 3.6174\n",
            "Epoch 1565/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4850 - val_loss: 3.8935\n",
            "Epoch 1566/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4825 - val_loss: 4.4125\n",
            "Epoch 1567/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4732 - val_loss: 4.5506\n",
            "Epoch 1568/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4748 - val_loss: 4.7692\n",
            "Epoch 1569/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4809 - val_loss: 4.8607\n",
            "Epoch 1570/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4749 - val_loss: 4.5571\n",
            "Epoch 1571/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4722 - val_loss: 4.4192\n",
            "Epoch 1572/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4743 - val_loss: 4.6408\n",
            "Epoch 1573/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4809 - val_loss: 4.7354\n",
            "Epoch 1574/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4728 - val_loss: 4.2777\n",
            "Epoch 1575/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4693 - val_loss: 3.8584\n",
            "Epoch 1576/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4715 - val_loss: 3.6746\n",
            "Epoch 1577/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4754 - val_loss: 3.4850\n",
            "Epoch 1578/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4833 - val_loss: 3.0761\n",
            "Epoch 1579/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5007 - val_loss: 3.1222\n",
            "Epoch 1580/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4833 - val_loss: 3.9750\n",
            "Epoch 1581/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4950 - val_loss: 5.1089\n",
            "Epoch 1582/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4809 - val_loss: 5.2550\n",
            "Epoch 1583/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4772 - val_loss: 4.9560\n",
            "Epoch 1584/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4685 - val_loss: 4.7842\n",
            "Epoch 1585/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4660 - val_loss: 4.6769\n",
            "Epoch 1586/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4637 - val_loss: 4.5353\n",
            "Epoch 1587/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4628 - val_loss: 4.2785\n",
            "Epoch 1588/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4608 - val_loss: 4.4645\n",
            "Epoch 1589/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4610 - val_loss: 4.8047\n",
            "Epoch 1590/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4648 - val_loss: 4.9331\n",
            "Epoch 1591/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4727 - val_loss: 4.8052\n",
            "Epoch 1592/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4630 - val_loss: 3.6541\n",
            "Epoch 1593/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4761 - val_loss: 3.0295\n",
            "Epoch 1594/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4822 - val_loss: 2.9389\n",
            "Epoch 1595/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4941 - val_loss: 2.7787\n",
            "Epoch 1596/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4849 - val_loss: 3.2997\n",
            "Epoch 1597/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4567 - val_loss: 4.2783\n",
            "Epoch 1598/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4580 - val_loss: 4.9639\n",
            "Epoch 1599/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4725 - val_loss: 5.0270\n",
            "Epoch 1600/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4678 - val_loss: 4.3691\n",
            "Epoch 1601/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4567 - val_loss: 3.4792\n",
            "Epoch 1602/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4609 - val_loss: 3.2555\n",
            "Epoch 1603/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4572 - val_loss: 3.6818\n",
            "Epoch 1604/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4559 - val_loss: 4.3962\n",
            "Epoch 1605/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4623 - val_loss: 4.7366\n",
            "Epoch 1606/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4620 - val_loss: 4.6707\n",
            "Epoch 1607/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4626 - val_loss: 4.3350\n",
            "Epoch 1608/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4561 - val_loss: 4.1204\n",
            "Epoch 1609/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4490 - val_loss: 3.8201\n",
            "Epoch 1610/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4538 - val_loss: 3.4375\n",
            "Epoch 1611/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4598 - val_loss: 3.3557\n",
            "Epoch 1612/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4509 - val_loss: 3.7520\n",
            "Epoch 1613/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4479 - val_loss: 3.6671\n",
            "Epoch 1614/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4457 - val_loss: 3.5887\n",
            "Epoch 1615/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4471 - val_loss: 3.4475\n",
            "Epoch 1616/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4489 - val_loss: 3.5590\n",
            "Epoch 1617/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4428 - val_loss: 3.9916\n",
            "Epoch 1618/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4451 - val_loss: 4.1758\n",
            "Epoch 1619/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4447 - val_loss: 4.2936\n",
            "Epoch 1620/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4452 - val_loss: 4.3142\n",
            "Epoch 1621/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4443 - val_loss: 3.8797\n",
            "Epoch 1622/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4583 - val_loss: 2.8224\n",
            "Epoch 1623/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4714 - val_loss: 2.6269\n",
            "Epoch 1624/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4660 - val_loss: 3.1000\n",
            "Epoch 1625/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4588 - val_loss: 4.1424\n",
            "Epoch 1626/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4419 - val_loss: 4.2675\n",
            "Epoch 1627/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4458 - val_loss: 4.1521\n",
            "Epoch 1628/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4457 - val_loss: 4.0197\n",
            "Epoch 1629/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4486 - val_loss: 3.0069\n",
            "Epoch 1630/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4467 - val_loss: 2.8860\n",
            "Epoch 1631/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4421 - val_loss: 3.3580\n",
            "Epoch 1632/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4342 - val_loss: 4.0602\n",
            "Epoch 1633/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4431 - val_loss: 4.1873\n",
            "Epoch 1634/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4387 - val_loss: 3.8466\n",
            "Epoch 1635/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4349 - val_loss: 3.3407\n",
            "Epoch 1636/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4345 - val_loss: 3.0464\n",
            "Epoch 1637/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4403 - val_loss: 3.0773\n",
            "Epoch 1638/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4454 - val_loss: 3.4532\n",
            "Epoch 1639/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4323 - val_loss: 3.3843\n",
            "Epoch 1640/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4319 - val_loss: 3.5440\n",
            "Epoch 1641/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4271 - val_loss: 4.0119\n",
            "Epoch 1642/2000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4410 - val_loss: 4.5845\n",
            "Epoch 1643/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4499 - val_loss: 4.4891\n",
            "Epoch 1644/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4465 - val_loss: 3.9906\n",
            "Epoch 1645/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4297 - val_loss: 3.6517\n",
            "Epoch 1646/2000\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.4302 - val_loss: 3.1175\n",
            "Epoch 1647/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4319 - val_loss: 3.0534\n",
            "Epoch 1648/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4346 - val_loss: 3.3609\n",
            "Epoch 1649/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4274 - val_loss: 3.1227\n",
            "Epoch 1650/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4379 - val_loss: 2.5759\n",
            "Epoch 1651/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4473 - val_loss: 2.7234\n",
            "Epoch 1652/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4452 - val_loss: 3.5261\n",
            "Epoch 1653/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4225 - val_loss: 3.8878\n",
            "Epoch 1654/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4344 - val_loss: 4.0237\n",
            "Epoch 1655/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4153 - val_loss: 3.0042\n",
            "Epoch 1656/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4316 - val_loss: 2.0387\n",
            "Epoch 1657/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4917 - val_loss: 1.8720\n",
            "Epoch 1658/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4789 - val_loss: 2.6091\n",
            "Epoch 1659/2000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4387 - val_loss: 3.9019\n",
            "Epoch 1660/2000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4389 - val_loss: 4.9582\n",
            "Epoch 1661/2000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4674 - val_loss: 5.0247\n",
            "Epoch 1662/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4644 - val_loss: 4.3341\n",
            "Epoch 1663/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4233 - val_loss: 3.4234\n",
            "Epoch 1664/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4109 - val_loss: 2.5514\n",
            "Epoch 1665/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4435 - val_loss: 1.9777\n",
            "Epoch 1666/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4752 - val_loss: 2.1633\n",
            "Epoch 1667/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4468 - val_loss: 2.7705\n",
            "Epoch 1668/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4282 - val_loss: 3.6073\n",
            "Epoch 1669/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4143 - val_loss: 4.1462\n",
            "Epoch 1670/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4274 - val_loss: 4.4631\n",
            "Epoch 1671/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4436 - val_loss: 4.4801\n",
            "Epoch 1672/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4346 - val_loss: 3.7709\n",
            "Epoch 1673/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4241 - val_loss: 3.0799\n",
            "Epoch 1674/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4180 - val_loss: 3.0641\n",
            "Epoch 1675/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4131 - val_loss: 3.5606\n",
            "Epoch 1676/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4175 - val_loss: 4.1287\n",
            "Epoch 1677/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4231 - val_loss: 4.3461\n",
            "Epoch 1678/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4309 - val_loss: 4.3418\n",
            "Epoch 1679/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4247 - val_loss: 3.8642\n",
            "Epoch 1680/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4199 - val_loss: 3.2326\n",
            "Epoch 1681/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4100 - val_loss: 3.1223\n",
            "Epoch 1682/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4130 - val_loss: 2.9357\n",
            "Epoch 1683/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4133 - val_loss: 2.9360\n",
            "Epoch 1684/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4181 - val_loss: 3.1352\n",
            "Epoch 1685/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4119 - val_loss: 3.1627\n",
            "Epoch 1686/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4107 - val_loss: 3.4746\n",
            "Epoch 1687/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4078 - val_loss: 3.5134\n",
            "Epoch 1688/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4079 - val_loss: 3.4358\n",
            "Epoch 1689/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4081 - val_loss: 3.2628\n",
            "Epoch 1690/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4154 - val_loss: 3.1609\n",
            "Epoch 1691/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4105 - val_loss: 3.5202\n",
            "Epoch 1692/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4126 - val_loss: 3.2910\n",
            "Epoch 1693/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4060 - val_loss: 3.4490\n",
            "Epoch 1694/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4116 - val_loss: 3.7172\n",
            "Epoch 1695/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4089 - val_loss: 3.6016\n",
            "Epoch 1696/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4016 - val_loss: 3.0283\n",
            "Epoch 1697/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4183 - val_loss: 2.3051\n",
            "Epoch 1698/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4294 - val_loss: 2.5830\n",
            "Epoch 1699/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4085 - val_loss: 3.0630\n",
            "Epoch 1700/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3978 - val_loss: 3.8879\n",
            "Epoch 1701/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4154 - val_loss: 4.3047\n",
            "Epoch 1702/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4236 - val_loss: 4.2508\n",
            "Epoch 1703/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4186 - val_loss: 3.8756\n",
            "Epoch 1704/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4047 - val_loss: 3.3985\n",
            "Epoch 1705/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4010 - val_loss: 3.0837\n",
            "Epoch 1706/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3986 - val_loss: 3.1565\n",
            "Epoch 1707/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3989 - val_loss: 3.1241\n",
            "Epoch 1708/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3990 - val_loss: 3.0276\n",
            "Epoch 1709/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4004 - val_loss: 3.3495\n",
            "Epoch 1710/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3985 - val_loss: 3.4594\n",
            "Epoch 1711/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3973 - val_loss: 3.1869\n",
            "Epoch 1712/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3960 - val_loss: 2.7852\n",
            "Epoch 1713/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3961 - val_loss: 2.6311\n",
            "Epoch 1714/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4034 - val_loss: 2.5780\n",
            "Epoch 1715/2000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3973 - val_loss: 3.0691\n",
            "Epoch 1716/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4097 - val_loss: 3.7757\n",
            "Epoch 1717/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3998 - val_loss: 3.3413\n",
            "Epoch 1718/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3952 - val_loss: 2.9543\n",
            "Epoch 1719/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3954 - val_loss: 3.2041\n",
            "Epoch 1720/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3949 - val_loss: 3.4561\n",
            "Epoch 1721/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3948 - val_loss: 3.4209\n",
            "Epoch 1722/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3937 - val_loss: 3.3850\n",
            "Epoch 1723/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3919 - val_loss: 3.5301\n",
            "Epoch 1724/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3947 - val_loss: 3.4383\n",
            "Epoch 1725/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3901 - val_loss: 2.9333\n",
            "Epoch 1726/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3886 - val_loss: 2.0217\n",
            "Epoch 1727/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4225 - val_loss: 1.8446\n",
            "Epoch 1728/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4186 - val_loss: 2.3999\n",
            "Epoch 1729/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3887 - val_loss: 3.2703\n",
            "Epoch 1730/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4082 - val_loss: 3.5619\n",
            "Epoch 1731/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3863 - val_loss: 2.6310\n",
            "Epoch 1732/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3886 - val_loss: 2.3656\n",
            "Epoch 1733/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3919 - val_loss: 2.5570\n",
            "Epoch 1734/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3924 - val_loss: 2.6196\n",
            "Epoch 1735/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3971 - val_loss: 2.0733\n",
            "Epoch 1736/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4009 - val_loss: 2.1105\n",
            "Epoch 1737/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3956 - val_loss: 2.4143\n",
            "Epoch 1738/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3848 - val_loss: 3.2543\n",
            "Epoch 1739/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3907 - val_loss: 3.8300\n",
            "Epoch 1740/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4149 - val_loss: 3.8512\n",
            "Epoch 1741/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3949 - val_loss: 3.0849\n",
            "Epoch 1742/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3978 - val_loss: 2.0439\n",
            "Epoch 1743/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3990 - val_loss: 1.9167\n",
            "Epoch 1744/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4008 - val_loss: 2.0594\n",
            "Epoch 1745/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3893 - val_loss: 2.3921\n",
            "Epoch 1746/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3818 - val_loss: 2.6238\n",
            "Epoch 1747/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3798 - val_loss: 2.6068\n",
            "Epoch 1748/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3784 - val_loss: 2.9987\n",
            "Epoch 1749/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3774 - val_loss: 3.1366\n",
            "Epoch 1750/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3791 - val_loss: 2.9565\n",
            "Epoch 1751/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3802 - val_loss: 2.4841\n",
            "Epoch 1752/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3834 - val_loss: 1.9773\n",
            "Epoch 1753/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3896 - val_loss: 2.3476\n",
            "Epoch 1754/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3777 - val_loss: 3.1539\n",
            "Epoch 1755/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3806 - val_loss: 3.5907\n",
            "Epoch 1756/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4020 - val_loss: 3.6609\n",
            "Epoch 1757/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3946 - val_loss: 3.2663\n",
            "Epoch 1758/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3815 - val_loss: 2.9510\n",
            "Epoch 1759/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3746 - val_loss: 2.9085\n",
            "Epoch 1760/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3737 - val_loss: 2.9130\n",
            "Epoch 1761/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3769 - val_loss: 2.8174\n",
            "Epoch 1762/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3696 - val_loss: 2.4794\n",
            "Epoch 1763/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3702 - val_loss: 2.1580\n",
            "Epoch 1764/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3760 - val_loss: 2.2731\n",
            "Epoch 1765/2000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3730 - val_loss: 2.4834\n",
            "Epoch 1766/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3685 - val_loss: 2.6541\n",
            "Epoch 1767/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3678 - val_loss: 2.9489\n",
            "Epoch 1768/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3782 - val_loss: 3.0395\n",
            "Epoch 1769/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3743 - val_loss: 2.7065\n",
            "Epoch 1770/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3703 - val_loss: 2.4861\n",
            "Epoch 1771/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3696 - val_loss: 2.3020\n",
            "Epoch 1772/2000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3721 - val_loss: 2.2630\n",
            "Epoch 1773/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3659 - val_loss: 2.7723\n",
            "Epoch 1774/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3665 - val_loss: 3.1569\n",
            "Epoch 1775/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3776 - val_loss: 3.0927\n",
            "Epoch 1776/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3721 - val_loss: 2.3295\n",
            "Epoch 1777/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3677 - val_loss: 1.9971\n",
            "Epoch 1778/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3716 - val_loss: 2.0013\n",
            "Epoch 1779/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3663 - val_loss: 2.5624\n",
            "Epoch 1780/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3754 - val_loss: 2.8688\n",
            "Epoch 1781/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3599 - val_loss: 2.1064\n",
            "Epoch 1782/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3701 - val_loss: 1.6296\n",
            "Epoch 1783/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3934 - val_loss: 1.5332\n",
            "Epoch 1784/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3905 - val_loss: 1.8004\n",
            "Epoch 1785/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3748 - val_loss: 2.1930\n",
            "Epoch 1786/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3584 - val_loss: 2.5243\n",
            "Epoch 1787/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3626 - val_loss: 2.7596\n",
            "Epoch 1788/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3592 - val_loss: 2.6654\n",
            "Epoch 1789/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3589 - val_loss: 2.6723\n",
            "Epoch 1790/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3573 - val_loss: 2.6859\n",
            "Epoch 1791/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3600 - val_loss: 2.8922\n",
            "Epoch 1792/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3598 - val_loss: 2.9243\n",
            "Epoch 1793/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3654 - val_loss: 3.0444\n",
            "Epoch 1794/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3595 - val_loss: 2.4409\n",
            "Epoch 1795/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3748 - val_loss: 1.6022\n",
            "Epoch 1796/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3835 - val_loss: 1.7647\n",
            "Epoch 1797/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3637 - val_loss: 2.3256\n",
            "Epoch 1798/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3542 - val_loss: 2.8452\n",
            "Epoch 1799/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3638 - val_loss: 3.1699\n",
            "Epoch 1800/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3684 - val_loss: 3.1747\n",
            "Epoch 1801/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3700 - val_loss: 2.9842\n",
            "Epoch 1802/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3562 - val_loss: 2.3499\n",
            "Epoch 1803/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3572 - val_loss: 1.8819\n",
            "Epoch 1804/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3663 - val_loss: 1.8873\n",
            "Epoch 1805/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3683 - val_loss: 2.5562\n",
            "Epoch 1806/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3555 - val_loss: 2.8208\n",
            "Epoch 1807/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3508 - val_loss: 2.4518\n",
            "Epoch 1808/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3489 - val_loss: 2.4914\n",
            "Epoch 1809/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3548 - val_loss: 2.4997\n",
            "Epoch 1810/2000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3608 - val_loss: 1.7776\n",
            "Epoch 1811/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3570 - val_loss: 1.9171\n",
            "Epoch 1812/2000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3475 - val_loss: 2.4630\n",
            "Epoch 1813/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3589 - val_loss: 2.8190\n",
            "Epoch 1814/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3456 - val_loss: 1.9918\n",
            "Epoch 1815/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3505 - val_loss: 1.5504\n",
            "Epoch 1816/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3616 - val_loss: 1.7453\n",
            "Epoch 1817/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3510 - val_loss: 2.3286\n",
            "Epoch 1818/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3464 - val_loss: 2.6393\n",
            "Epoch 1819/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3528 - val_loss: 2.6871\n",
            "Epoch 1820/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3465 - val_loss: 2.4089\n",
            "Epoch 1821/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3431 - val_loss: 2.1267\n",
            "Epoch 1822/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3482 - val_loss: 1.5215\n",
            "Epoch 1823/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3601 - val_loss: 1.6858\n",
            "Epoch 1824/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3538 - val_loss: 1.8260\n",
            "Epoch 1825/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3437 - val_loss: 2.3120\n",
            "Epoch 1826/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3510 - val_loss: 2.7596\n",
            "Epoch 1827/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3487 - val_loss: 2.4121\n",
            "Epoch 1828/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3479 - val_loss: 1.5107\n",
            "Epoch 1829/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3610 - val_loss: 1.6006\n",
            "Epoch 1830/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3620 - val_loss: 2.1949\n",
            "Epoch 1831/2000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3377 - val_loss: 1.9454\n",
            "Epoch 1832/2000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3377 - val_loss: 1.7986\n",
            "Epoch 1833/2000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3411 - val_loss: 1.7164\n",
            "Epoch 1834/2000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3446 - val_loss: 1.6411\n",
            "Epoch 1835/2000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3504 - val_loss: 1.4632\n",
            "Epoch 1836/2000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3561 - val_loss: 1.6390\n",
            "Epoch 1837/2000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3476 - val_loss: 1.9220\n",
            "Epoch 1838/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3360 - val_loss: 2.1025\n",
            "Epoch 1839/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3336 - val_loss: 2.1974\n",
            "Epoch 1840/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3318 - val_loss: 2.4565\n",
            "Epoch 1841/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3358 - val_loss: 2.6055\n",
            "Epoch 1842/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3405 - val_loss: 2.5683\n",
            "Epoch 1843/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3359 - val_loss: 2.0785\n",
            "Epoch 1844/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3356 - val_loss: 1.6856\n",
            "Epoch 1845/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3596 - val_loss: 1.5474\n",
            "Epoch 1846/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3405 - val_loss: 2.2542\n",
            "Epoch 1847/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3323 - val_loss: 2.8116\n",
            "Epoch 1848/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3516 - val_loss: 2.9804\n",
            "Epoch 1849/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3484 - val_loss: 2.3713\n",
            "Epoch 1850/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3311 - val_loss: 2.0673\n",
            "Epoch 1851/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3270 - val_loss: 2.1082\n",
            "Epoch 1852/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3277 - val_loss: 2.1873\n",
            "Epoch 1853/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3266 - val_loss: 2.1272\n",
            "Epoch 1854/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3288 - val_loss: 2.0024\n",
            "Epoch 1855/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3256 - val_loss: 2.0444\n",
            "Epoch 1856/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3237 - val_loss: 2.2554\n",
            "Epoch 1857/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3317 - val_loss: 2.4910\n",
            "Epoch 1858/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3335 - val_loss: 2.2257\n",
            "Epoch 1859/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3243 - val_loss: 1.9654\n",
            "Epoch 1860/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3246 - val_loss: 1.9490\n",
            "Epoch 1861/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3248 - val_loss: 2.3330\n",
            "Epoch 1862/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3336 - val_loss: 2.3613\n",
            "Epoch 1863/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3165 - val_loss: 1.5112\n",
            "Epoch 1864/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3339 - val_loss: 1.2332\n",
            "Epoch 1865/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3472 - val_loss: 1.5393\n",
            "Epoch 1866/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3268 - val_loss: 1.8009\n",
            "Epoch 1867/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3200 - val_loss: 2.3390\n",
            "Epoch 1868/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3239 - val_loss: 2.4282\n",
            "Epoch 1869/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3252 - val_loss: 2.2589\n",
            "Epoch 1870/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3181 - val_loss: 1.9545\n",
            "Epoch 1871/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3186 - val_loss: 1.9421\n",
            "Epoch 1872/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3164 - val_loss: 2.2334\n",
            "Epoch 1873/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3220 - val_loss: 2.6130\n",
            "Epoch 1874/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3378 - val_loss: 2.4757\n",
            "Epoch 1875/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3293 - val_loss: 1.4288\n",
            "Epoch 1876/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3308 - val_loss: 1.4289\n",
            "Epoch 1877/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3299 - val_loss: 1.8739\n",
            "Epoch 1878/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3145 - val_loss: 1.9808\n",
            "Epoch 1879/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3146 - val_loss: 2.0712\n",
            "Epoch 1880/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3138 - val_loss: 2.2946\n",
            "Epoch 1881/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3261 - val_loss: 2.5153\n",
            "Epoch 1882/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3273 - val_loss: 2.2046\n",
            "Epoch 1883/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3151 - val_loss: 1.4526\n",
            "Epoch 1884/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3230 - val_loss: 1.3971\n",
            "Epoch 1885/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3284 - val_loss: 1.4803\n",
            "Epoch 1886/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3081 - val_loss: 2.1731\n",
            "Epoch 1887/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3220 - val_loss: 2.5619\n",
            "Epoch 1888/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3313 - val_loss: 1.9436\n",
            "Epoch 1889/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3108 - val_loss: 1.7705\n",
            "Epoch 1890/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3109 - val_loss: 1.7468\n",
            "Epoch 1891/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3101 - val_loss: 1.8155\n",
            "Epoch 1892/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3136 - val_loss: 2.0026\n",
            "Epoch 1893/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3119 - val_loss: 1.6320\n",
            "Epoch 1894/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3120 - val_loss: 1.5408\n",
            "Epoch 1895/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3078 - val_loss: 1.7925\n",
            "Epoch 1896/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3079 - val_loss: 2.0233\n",
            "Epoch 1897/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3118 - val_loss: 2.0078\n",
            "Epoch 1898/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3089 - val_loss: 1.8119\n",
            "Epoch 1899/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3064 - val_loss: 1.5960\n",
            "Epoch 1900/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3079 - val_loss: 1.4633\n",
            "Epoch 1901/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3140 - val_loss: 1.1470\n",
            "Epoch 1902/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3240 - val_loss: 1.3224\n",
            "Epoch 1903/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3151 - val_loss: 1.6763\n",
            "Epoch 1904/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3084 - val_loss: 1.8120\n",
            "Epoch 1905/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3038 - val_loss: 1.5568\n",
            "Epoch 1906/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3054 - val_loss: 1.5925\n",
            "Epoch 1907/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3030 - val_loss: 1.8404\n",
            "Epoch 1908/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3046 - val_loss: 2.0684\n",
            "Epoch 1909/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3084 - val_loss: 2.1110\n",
            "Epoch 1910/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3088 - val_loss: 1.9391\n",
            "Epoch 1911/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3045 - val_loss: 1.5028\n",
            "Epoch 1912/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3070 - val_loss: 1.3989\n",
            "Epoch 1913/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3043 - val_loss: 1.5086\n",
            "Epoch 1914/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3026 - val_loss: 1.6426\n",
            "Epoch 1915/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3040 - val_loss: 2.1537\n",
            "Epoch 1916/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3076 - val_loss: 2.2290\n",
            "Epoch 1917/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3090 - val_loss: 2.0593\n",
            "Epoch 1918/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3035 - val_loss: 1.9128\n",
            "Epoch 1919/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3008 - val_loss: 1.7954\n",
            "Epoch 1920/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3029 - val_loss: 1.4029\n",
            "Epoch 1921/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3061 - val_loss: 1.3310\n",
            "Epoch 1922/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2987 - val_loss: 1.8169\n",
            "Epoch 1923/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3143 - val_loss: 2.2351\n",
            "Epoch 1924/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2969 - val_loss: 1.5302\n",
            "Epoch 1925/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3258 - val_loss: 0.7665\n",
            "Epoch 1926/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3517 - val_loss: 0.8543\n",
            "Epoch 1927/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3308 - val_loss: 1.3186\n",
            "Epoch 1928/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2972 - val_loss: 1.7874\n",
            "Epoch 1929/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2978 - val_loss: 2.0586\n",
            "Epoch 1930/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3029 - val_loss: 1.7935\n",
            "Epoch 1931/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2911 - val_loss: 1.0525\n",
            "Epoch 1932/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3109 - val_loss: 1.0012\n",
            "Epoch 1933/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3112 - val_loss: 1.1939\n",
            "Epoch 1934/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2970 - val_loss: 1.5316\n",
            "Epoch 1935/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2907 - val_loss: 1.6925\n",
            "Epoch 1936/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2938 - val_loss: 2.0958\n",
            "Epoch 1937/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3014 - val_loss: 2.1512\n",
            "Epoch 1938/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3037 - val_loss: 1.8384\n",
            "Epoch 1939/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2921 - val_loss: 1.3124\n",
            "Epoch 1940/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2979 - val_loss: 1.0209\n",
            "Epoch 1941/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3108 - val_loss: 1.1415\n",
            "Epoch 1942/2000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.2925 - val_loss: 1.9013\n",
            "Epoch 1943/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2934 - val_loss: 2.3850\n",
            "Epoch 1944/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3189 - val_loss: 2.2752\n",
            "Epoch 1945/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2986 - val_loss: 1.5052\n",
            "Epoch 1946/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2860 - val_loss: 0.7778\n",
            "Epoch 1947/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3558 - val_loss: 0.6869\n",
            "Epoch 1948/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3360 - val_loss: 1.3343\n",
            "Epoch 1949/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2963 - val_loss: 1.9555\n",
            "Epoch 1950/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2970 - val_loss: 2.0681\n",
            "Epoch 1951/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2892 - val_loss: 1.5905\n",
            "Epoch 1952/2000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2820 - val_loss: 1.0806\n",
            "Epoch 1953/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3038 - val_loss: 0.8784\n",
            "Epoch 1954/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3005 - val_loss: 1.4214\n",
            "Epoch 1955/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2970 - val_loss: 1.9200\n",
            "Epoch 1956/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2908 - val_loss: 1.3081\n",
            "Epoch 1957/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2846 - val_loss: 1.2615\n",
            "Epoch 1958/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2799 - val_loss: 1.5358\n",
            "Epoch 1959/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2823 - val_loss: 1.8280\n",
            "Epoch 1960/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2898 - val_loss: 1.7441\n",
            "Epoch 1961/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2892 - val_loss: 1.3590\n",
            "Epoch 1962/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2798 - val_loss: 1.3799\n",
            "Epoch 1963/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2796 - val_loss: 1.3929\n",
            "Epoch 1964/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2785 - val_loss: 1.3308\n",
            "Epoch 1965/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2780 - val_loss: 1.3394\n",
            "Epoch 1966/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2783 - val_loss: 1.3860\n",
            "Epoch 1967/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2784 - val_loss: 1.4415\n",
            "Epoch 1968/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2794 - val_loss: 1.6856\n",
            "Epoch 1969/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2802 - val_loss: 1.5578\n",
            "Epoch 1970/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2800 - val_loss: 1.1705\n",
            "Epoch 1971/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2818 - val_loss: 1.1483\n",
            "Epoch 1972/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2777 - val_loss: 1.5367\n",
            "Epoch 1973/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2742 - val_loss: 1.6872\n",
            "Epoch 1974/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2793 - val_loss: 1.8861\n",
            "Epoch 1975/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2810 - val_loss: 1.7645\n",
            "Epoch 1976/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2780 - val_loss: 1.5967\n",
            "Epoch 1977/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2761 - val_loss: 1.3204\n",
            "Epoch 1978/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2727 - val_loss: 1.4070\n",
            "Epoch 1979/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2731 - val_loss: 1.4593\n",
            "Epoch 1980/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2725 - val_loss: 1.6354\n",
            "Epoch 1981/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2726 - val_loss: 1.3538\n",
            "Epoch 1982/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2695 - val_loss: 1.2804\n",
            "Epoch 1983/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2709 - val_loss: 1.2339\n",
            "Epoch 1984/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2709 - val_loss: 1.2845\n",
            "Epoch 1985/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2701 - val_loss: 1.2202\n",
            "Epoch 1986/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2688 - val_loss: 1.3566\n",
            "Epoch 1987/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2773 - val_loss: 1.5092\n",
            "Epoch 1988/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2660 - val_loss: 1.2556\n",
            "Epoch 1989/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2667 - val_loss: 1.2391\n",
            "Epoch 1990/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2669 - val_loss: 1.1817\n",
            "Epoch 1991/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2730 - val_loss: 1.2786\n",
            "Epoch 1992/2000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2674 - val_loss: 0.8500\n",
            "Epoch 1993/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2865 - val_loss: 0.8248\n",
            "Epoch 1994/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2790 - val_loss: 1.4777\n",
            "Epoch 1995/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2666 - val_loss: 1.8072\n",
            "Epoch 1996/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2803 - val_loss: 1.8551\n",
            "Epoch 1997/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2771 - val_loss: 1.5819\n",
            "Epoch 1998/2000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2657 - val_loss: 1.3027\n",
            "Epoch 1999/2000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2638 - val_loss: 0.9079\n",
            "Epoch 2000/2000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2721 - val_loss: 0.9316\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6ff535e9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We train our model for 2000 epochs with a batch size of 5. You can choose any number. Once the model is trained, we can make predictions on a new instance.\n",
        "\n",
        "Let's say we want to predict the output for an input of 30. The actual output should be 30 x 15 = 450. Let's see what value do we get. First, we need to convert our test data to the right shape i.e. 3D shape, as expected by LSTM. The following script predicts the output for the number 30:"
      ],
      "metadata": {
        "id": "i5nnsdLLyBWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = array([30])\n",
        "test_input = test_input.reshape((1, 1, 1))\n",
        "test_output = model.predict(test_input, verbose=0)\n",
        "print(test_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3BDDx3wyHcz",
        "outputId": "f561115f-d28b-4f03-cb82-5c1ca4db46fe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[445.11365]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk--MHSqaDFY"
      },
      "source": [
        "# **3. RNN - Many-to-one**\n",
        "> In this post, We will briefly cover the many-to-one type, which is one the common types of Recurrent Neural Network and its implementation in tensorflow. \n",
        "\n",
        "\n",
        "https://colab.research.google.com/github/goodboychan/goodboychan.github.io/blob/main/_notebooks/2020-12-06-01-RNN-Many-to-one.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1uMP0zxaDFc",
        "outputId": "fe0dcb0b-ef1f-4231-93b5-f1b5ff529e2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow: 2.8.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "print('Tensorflow: {}'.format(tf.__version__))\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (16, 10)\n",
        "plt.rc('font', size=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_6zPMYDaDFe"
      },
      "source": [
        "## Various usage of RNN\n",
        "As we already discussed, RNN is used for sequence data handling. And there are several types of RNN architecture.\n",
        "\n",
        "![various_rnn](image/various_rnn.png) {% fn 1 %}\n",
        "\n",
        "In previous [post](https://goodboychan.github.io/chans_jupyter/python/deep_learning/tensorflow-keras/2020/10/26/02-RNN-Basic.html), we take a look **one-to-one** type, which is the basic RNN structure. And next one is **one-to-many** type. For example, if the model gets the fixed format like image as an input, it generates the sequence data. You can see the implementation on image caption application. Another type is **many-to-many** type. It gets sequence data as an inputs, and also generates the sequence data as an output. Common application of many-to-many type is machine translation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s48ruQipaDFe"
      },
      "source": [
        "## Many-to-one\n",
        "\n",
        "**Many-to-one** type, which is our topic in this post, gets an sequence data as an input and generates some informatic data like labels. So we can use it for classification. Suppose that someone defines the sentiment of each sentence, and train the model with many-to-one type. And when the model gets the unseen sentence, then it will predict the intention of sentence, good or bad.\n",
        "\n",
        "![many-to-one example](image/many-to-one.png)\n",
        "\n",
        "The detailed explanation is like this.\n",
        "\n",
        "Suppose we have a sentence, \"This movis is good\". And we want to classify the sentiment of this sentence. In order to do this, we need to apply tokenization in word level. If this sentensce intends the good sentiment, then word token may contains good words, like \"good\". So we can classify this sentense to good sentiment.\n",
        "\n",
        "So if we want to apply it in RNN model, we need to consider the sentence as a word sequence(many), then clssify its label(one). That is process of many-to-one type model.\n",
        "\n",
        "![many-to-one detail](image/many-to-one_detail.png)\n",
        "\n",
        "But as you notice, computational model cannot accept the word itself as an input. Instead, it needs to convert with numerical vector. **Embedding** Layer can do this.\n",
        "\n",
        "So how can we implement this with tensorflow?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg72Qzc5aDFf"
      },
      "source": [
        "## Example - Word sentiment classification\n",
        "\n",
        "At first, we prepare the dummy data for simple classification. For the simplicity, we defined 1 as a good token, and 0 otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTQuAC9jaDFg"
      },
      "outputs": [],
      "source": [
        "words = ['good', 'bad', 'worse', 'so good']\n",
        "y = [1, 0, 0, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noj5bn_YaDFg"
      },
      "source": [
        "Based on this, we can generate the token dictionary, which is the mapping table for each characters. But before we prepare this, we need to consider one exceptional case, the variation of each sentence length. To train the network, the format (or shape) of input data must be fixed. So we need to add the concept of **padding**. Tensorflow has useful API for padding, `pad_sequences`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XftZdN9kaDFh"
      },
      "outputs": [],
      "source": [
        "char_set = ['<pad>'] + sorted(list(set(''.join(words))))\n",
        "idx2char = {idx:char for idx, char in enumerate(char_set)}\n",
        "char2idx = {char:idx for idx, char in enumerate(char_set)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeVzKvMyaDFh",
        "outputId": "f252fa3b-3127-4992-82a7-61f9b29320c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<pad>', ' ', 'a', 'b', 'd', 'e', 'g', 'o', 'r', 's', 'w']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "char_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJd0YAXMaDFi",
        "outputId": "26b03bd7-bb9d-4a79-bd3a-1e9727844d20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '<pad>',\n",
              " 1: ' ',\n",
              " 2: 'a',\n",
              " 3: 'b',\n",
              " 4: 'd',\n",
              " 5: 'e',\n",
              " 6: 'g',\n",
              " 7: 'o',\n",
              " 8: 'r',\n",
              " 9: 's',\n",
              " 10: 'w'}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "idx2char"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGZenhaLaDFj",
        "outputId": "93de91e1-29b2-4d65-ef96-300d13e1b52f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 1,\n",
              " '<pad>': 0,\n",
              " 'a': 2,\n",
              " 'b': 3,\n",
              " 'd': 4,\n",
              " 'e': 5,\n",
              " 'g': 6,\n",
              " 'o': 7,\n",
              " 'r': 8,\n",
              " 's': 9,\n",
              " 'w': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "char2idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TAefJ0GaDFj"
      },
      "source": [
        "So as we mentioned before, we need to vectorize each tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbdAcKEDaDFj"
      },
      "outputs": [],
      "source": [
        "X = list(map(lambda word: [char2idx.get(char) for char in word], words))\n",
        "X_len = list(map(lambda word: len(word), X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-6CFxcEaDFk",
        "outputId": "617a0f53-219d-4d1a-e489-eb5fa0fdebb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[6, 7, 7, 4], [3, 2, 4], [10, 7, 8, 9, 5], [9, 7, 1, 6, 7, 7, 4]]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JB7JBhuaDFk",
        "outputId": "d9e8ae5f-7718-4a06-fb51-122537b33461",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 3, 5, 7]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "X_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAkwYhaSaDFk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Padding the sequence of indices\n",
        "max_sequence=10\n",
        "\n",
        "X = pad_sequences(X, maxlen=max_sequence, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCjNKhAfaDFl",
        "outputId": "ad02f699-9f37-452b-b438-419b97f70db2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6,  7,  7,  4,  0,  0,  0,  0,  0,  0],\n",
              "       [ 3,  2,  4,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [10,  7,  8,  9,  5,  0,  0,  0,  0,  0],\n",
              "       [ 9,  7,  1,  6,  7,  7,  4,  0,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuAAb_XOaDFl",
        "outputId": "60e3e79d-d6cd-475b-ac62-4bd40a35a87c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omKggSSiaDFm"
      },
      "source": [
        "Here, we used `pad_sequences` API with several arguments. First, we defined maximum sequence length to 10. So numerical vector has an maximum length of 10. That is, we just consider 10 characters for sequence. And there are some words that has less than 10 characters. In that case, we filled some 0s for padding. Through argument, we can define the direction of padding, `pre` or `post`.\n",
        "\n",
        "And of course, it is efficient to use the dataset with generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRX3zdscaDFm",
        "outputId": "d2a70703-a8c5-4197-de8b-3b807451b488",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BatchDataset element_spec=(TensorSpec(shape=(None, 10), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
          ]
        }
      ],
      "source": [
        "# Generate data pipeline\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X, y)).shuffle(buffer_size=4).batch(batch_size=2)\n",
        "print(train_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqOKoeCBaDFm"
      },
      "source": [
        "After that, we can build many-to-one model with simpleRNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0k9OT3XoaDFn"
      },
      "outputs": [],
      "source": [
        "input_dim = len(char2idx)\n",
        "output_dim = len(char2idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbUu9cx8aDFn",
        "outputId": "088e3131-edfe-47df-8653-662df171daef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 10, 11)            121       \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 10)                220       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 22        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 363\n",
            "Trainable params: 242\n",
            "Non-trainable params: 121\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=input_dim, output_dim=output_dim,\n",
        "              mask_zero=True, input_length=max_sequence,\n",
        "              trainable=False, embeddings_initializer=tf.keras.initializers.random_normal()),\n",
        "    SimpleRNN(units=10),\n",
        "    Dense(2)\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dv2lcuq9aDFn"
      },
      "outputs": [],
      "source": [
        "def loss_fn(model, X, y):\n",
        "    return tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(y_true=y, \n",
        "                                                                          y_pred=model(X), \n",
        "                                                                          from_logits=True))\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fNx_hinaDFo",
        "outputId": "17f2d18c-4009-45d1-bab0-c641aef6d546",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:   5, tr_loss: 0.071402\n",
            "epoch:  10, tr_loss: 0.004197\n",
            "epoch:  15, tr_loss: 0.001211\n",
            "epoch:  20, tr_loss: 0.000727\n",
            "epoch:  25, tr_loss: 0.000566\n",
            "epoch:  30, tr_loss: 0.000487\n"
          ]
        }
      ],
      "source": [
        "tr_loss_hist = []\n",
        "\n",
        "for e in range(30):\n",
        "    avg_tr_loss = 0\n",
        "    tr_step = 0\n",
        "    \n",
        "    for x_mb, y_mb in train_ds:\n",
        "        with tf.GradientTape() as tape:\n",
        "            tr_loss = loss_fn(model, x_mb, y_mb)\n",
        "            \n",
        "        grads = tape.gradient(tr_loss, sources=model.variables)\n",
        "        optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
        "        avg_tr_loss += tr_loss\n",
        "        tr_step += 1\n",
        "    \n",
        "    avg_tr_loss /= tr_step\n",
        "    tr_loss_hist.append(avg_tr_loss)\n",
        "    \n",
        "    if (e + 1) % 5 == 0:\n",
        "        print('epoch: {:3}, tr_loss: {:3f}'.format(e + 1, avg_tr_loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e4LN1VSaDFo"
      },
      "source": [
        "After that, we can check the performance of this simple rnn network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLX6yOrvaDFo"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5NzMs64aDFo",
        "outputId": "15aa2363-6466-4f2d-bb87-b207a6ea043c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc: 100.00%\n"
          ]
        }
      ],
      "source": [
        "print('acc: {:.2%}'.format(np.mean(y_pred == y)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnA6mei_aDFp",
        "outputId": "35eb960e-a7b3-474f-a9af-3813bdfe4325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure()\n",
        "plt.plot(tr_loss_hist)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT77e7-oaDFp"
      },
      "source": [
        "As you can see, the performance of this simple network shows almost 100% accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTyA9FOtaDFp"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this post, we just cover the basic concept of **many-to-one** type RNN model for sentiment classification, and implement it with Tensorflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6ChDAxkaDFp"
      },
      "source": [
        "{{ 'Reference from stanford CS231n lecture note' | fndetail: 1 }}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fMAOBMNaMO8"
      },
      "source": [
        "# **4. RNN - Many-to-many**\n",
        "> In this coalb, We will cover the many-to-many RNN model, which can be used for Part of Speech (POS) tagging and Named Entity Recognition (NER).\n",
        "    Ref: https://goodboychan.github.io/python/deep_learning/tensorflow-keras/2020/12/09/01-RNN-Many-to-many.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpnt95xuaMO_",
        "outputId": "134b4600-4d76-45d7-ea37-bd84fd26df69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow: 2.8.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "print('Tensorflow: {}'.format(tf.__version__))\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (16, 10)\n",
        "plt.rc('font', size=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVc0gjgpaMPA"
      },
      "source": [
        "## What is \"Many-to-many\"?\n",
        "\n",
        "Previously, we covered 3 kinds of RNN model, one-to-one, many-to-one, and many-to-one with stacked model. Especially on many-to-one model, it gets an sequence data as an input, and generates the single output. So it can be used for classification, and previous example shows simple implementation of many-to-one model for word/sequence classification.\n",
        "\n",
        "Then, what is **many-to-many** model?\n",
        "\n",
        "The concept is same as before. In many-to-one model, to generate the output, the final input must be entered into model. Unlike this, many-to-many model generates the output whenever each input is read. That is, many-to-many model can understand the feature of each token in input sequence.\n",
        "\n",
        "One possible example is [**Part-of-Speech**](https://en.wikipedia.org/wiki/Part_of_speech) tagging, POS for short. POS is a category of words (or lexical items) that have similar grammatical properties. Common POS type are noun, verb, adjective, adverb, pronoun, etc. {% fn 2 %}. So POS tagging is automatically tagged POS of each token. Of course, it can manually handle with rule-based model, but many-to-many model is appropriate for doing this.\n",
        "\n",
        "For example, we have a sentence.\n",
        "$$ \\text{tensorflow is very easy} $$\n",
        "\n",
        "In order to do POS tagging, word tokenization is processed on that sentence. After that, we can get\n",
        "\n",
        "$$ [\\text{'tensorflow', 'is', 'very', 'easy'}] $$\n",
        "\n",
        "Then POS will be tagged on each token like this,\n",
        "\n",
        "$$[\\text{'noun', 'verb', 'adverb', 'adjective'}]$$\n",
        "\n",
        "If the many-to-many model is well-trained, whole process will be happened well.\n",
        "\n",
        "Unlike many-to-one model, loss measure is also different in many-to-many model. In many-to-one model, it can measure the loss by comparing the prediction value($\\hat{y}$) and actual value($y$). But in many-to-many model, each output node can measure the loss. There are many losses, so common ways to use it for training is by averaging whole losses. This kind of loss is called **sequence loss**. After that, specific optimizer (SGD or Adam) tries to minimize the loss with backpropagation.\n",
        "\n",
        "One thing we need to consider is handling padding tokens('<pad>'). As you saw from previous post, padding tokens are for formalize the various length of each sentence, it has no meaning. So it is required to remove (or \"masking\") padding tokens before training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9y9tYV_aMPB"
      },
      "source": [
        "## Example - Part of Speech Tagging\n",
        "\n",
        "### Prepraring Dataset\n",
        "\n",
        "In this section, we will implement the simple many-to-many model for POS tagging. Of course, there are two types of training data, sentence, and POS of that sentence. (Assume that we already tokenize each sentence.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--IocrJCaMPC"
      },
      "outputs": [],
      "source": [
        "sentences = [['I', 'feel', 'hungry'],\n",
        "             ['tensorflow', 'is', 'very', 'difficult'],\n",
        "             ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
        "             ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
        "\n",
        "pos = [['pronoun', 'verb', 'adjective'], \n",
        "       ['noun', 'verb', 'adverb', 'adjective'],\n",
        "       ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
        "       ['noun', 'verb', 'adverb', 'adjective', 'verb']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTymquu_aMPC"
      },
      "source": [
        "Same as previous example, we can build token dictionary. And additionally, we need to build POS dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTagCLqTaMPD",
        "outputId": "38610abf-496d-4aab-f6fc-aa3f5d3bdb81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<pad>', 'I', 'a', 'changing', 'deep', 'difficult', 'fast', 'feel', 'for', 'framework', 'hungry', 'is', 'learning', 'tensorflow', 'very']\n",
            "{'<pad>': 0, 'I': 1, 'a': 2, 'changing': 3, 'deep': 4, 'difficult': 5, 'fast': 6, 'feel': 7, 'for': 8, 'framework': 9, 'hungry': 10, 'is': 11, 'learning': 12, 'tensorflow': 13, 'very': 14}\n",
            "{0: '<pad>', 1: 'I', 2: 'a', 3: 'changing', 4: 'deep', 5: 'difficult', 6: 'fast', 7: 'feel', 8: 'for', 9: 'framework', 10: 'hungry', 11: 'is', 12: 'learning', 13: 'tensorflow', 14: 'very'}\n"
          ]
        }
      ],
      "source": [
        "word_list =['<pad>'] + sorted(set(sum(sentences, []))) \n",
        "word2idx = {word:idx for idx, word in enumerate(word_list)}\n",
        "idx2word = {idx:word for idx, word in enumerate(word_list)}\n",
        "\n",
        "print(word_list)\n",
        "print(word2idx)\n",
        "print(idx2word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bq4SgCMkaMPD",
        "outputId": "0ecbe7b9-af5c-448f-f218-b3ebeea179c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<pad>', 'adjective', 'adverb', 'determiner', 'noun', 'preposition', 'pronoun', 'verb']\n",
            "{'<pad>': 0, 'adjective': 1, 'adverb': 2, 'determiner': 3, 'noun': 4, 'preposition': 5, 'pronoun': 6, 'verb': 7}\n",
            "{0: '<pad>', 1: 'adjective', 2: 'adverb', 3: 'determiner', 4: 'noun', 5: 'preposition', 6: 'pronoun', 7: 'verb'}\n"
          ]
        }
      ],
      "source": [
        "pos_list = ['<pad>'] + sorted(set(sum(pos, [])))\n",
        "pos2idx = {pos:idx for idx, pos in enumerate(pos_list)}\n",
        "idx2pos = {idx:pos for idx, pos in enumerate(pos_list)}\n",
        "\n",
        "print(pos_list)\n",
        "print(pos2idx)\n",
        "print(idx2pos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKZtvl43aMPE"
      },
      "source": [
        "We build the dictionary for dataset. Based on this, we can convert from sentence to numerical vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjLcJorkaMPE",
        "outputId": "a1562b0b-db40-4b9a-d19e-fed4649423d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 7, 10], [13, 11, 14, 5], [13, 11, 2, 9, 8, 4, 12], [13, 11, 14, 6, 3]]\n",
            "[[6, 7, 1], [4, 7, 2, 1], [4, 7, 3, 4, 5, 1, 4], [4, 7, 2, 1, 7]]\n"
          ]
        }
      ],
      "source": [
        "X = list(map(lambda sentence: [word2idx.get(token) for token in sentence], sentences))\n",
        "y = list(map(lambda sentence: [pos2idx.get(token) for token in sentence], pos))\n",
        "\n",
        "print(X)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcwGRzXlaMPF"
      },
      "source": [
        "As you can see, the length of each sentence is various. We can fix the the length with `pad_sequences`. Also, we need masking vector for filtering pad tokens. In order to this, we feed the length of each sentence without padding as an input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLM5Y2eIaMPF",
        "outputId": "4137827d-5c5f-402f-cc39-337a2beb616d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  7 10  0  0  0  0  0  0  0]\n",
            " [13 11 14  5  0  0  0  0  0  0]\n",
            " [13 11  2  9  8  4 12  0  0  0]\n",
            " [13 11 14  6  3  0  0  0  0  0]]\n",
            "[[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]]\n",
            "[3. 4. 7. 5.]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X = pad_sequences(X, maxlen=10, padding='post')\n",
        "X_mask = (X != 0).astype(np.float32)\n",
        "X_len = np.array(list((map(lambda sentence: len(sentence), sentences))), dtype=np.float32)\n",
        "\n",
        "print(X)\n",
        "print(X_mask)\n",
        "print(X_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZCNoOdPaMPG",
        "outputId": "62d18647-3c38-4e01-b728-85658c93b2f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6 7 1 0 0 0 0 0 0 0]\n",
            " [4 7 2 1 0 0 0 0 0 0]\n",
            " [4 7 3 4 5 1 4 0 0 0]\n",
            " [4 7 2 1 7 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "y = pad_sequences(y, maxlen=10, padding='post')\n",
        "\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2qWyVcraMPG",
        "outputId": "e434dd66-e4e6-4d73-8262-2e50a7bbdb06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BatchDataset element_spec=(TensorSpec(shape=(None, 10), dtype=tf.int32, name=None), TensorSpec(shape=(None, 10), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.float32, name=None))>\n"
          ]
        }
      ],
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((X, y, X_len)).shuffle(buffer_size=4).batch(batch_size=2)\n",
        "\n",
        "print(train_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsE1vj-5aMPG"
      },
      "source": [
        "### Model implementation\n",
        "\n",
        "For many-to-many model, the output node must be number of classes. In our example, we need to predict the type of POS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzwsQPDzaMPH"
      },
      "outputs": [],
      "source": [
        "num_classes = len(pos2idx)\n",
        "input_dim = len(word2idx)\n",
        "output_dim = len(word2idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_7NvI9AaMPH",
        "outputId": "588f40e1-9f5e-449b-9ebb-e947a04e2071",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 10, 15)            225       \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 10, 10)            260       \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 10, 8)            88        \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 573\n",
            "Trainable params: 348\n",
            "Non-trainable params: 225\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, TimeDistributed, Dense, SimpleRNN\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=input_dim, output_dim=output_dim,\n",
        "              mask_zero=True, trainable=False, input_length=10,\n",
        "              embeddings_initializer=tf.keras.initializers.random_normal()),\n",
        "    SimpleRNN(units=10, return_sequences=True),\n",
        "    TimeDistributed(Dense(units=num_classes))\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPR3nIBXaMPH"
      },
      "source": [
        "So, here is important section, the loss definition. As we saw before, we need to filter the pad tokens, and calculate the sequence loss with each POS losses. Actually, tensorflow has API for masking. (`sequence_mask`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChWw18m-aMPH"
      },
      "outputs": [],
      "source": [
        "def loss_fn(model, x, y, x_len, max_sequence):\n",
        "    masking = tf.sequence_mask(x_len, maxlen=max_sequence, dtype=tf.float32)\n",
        "    sequence_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "        y_true=y, y_pred=model(x), from_logits=True\n",
        "    ) * masking\n",
        "    sequence_loss = tf.reduce_mean(tf.reduce_sum(sequence_loss, axis=1) / x_len)\n",
        "    return sequence_loss\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzHcsZ4xaMPI",
        "outputId": "e2b69e65-cbbb-44b7-f714-95dff3956143",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:   5, tr_loss: 0.655\n",
            "Epoch:  10, tr_loss: 0.341\n",
            "Epoch:  15, tr_loss: 0.183\n",
            "Epoch:  20, tr_loss: 0.067\n",
            "Epoch:  25, tr_loss: 0.025\n",
            "Epoch:  30, tr_loss: 0.009\n"
          ]
        }
      ],
      "source": [
        "tr_loss_hist = []\n",
        "\n",
        "for e in range(30):\n",
        "    avg_tr_loss = 0\n",
        "    tr_step = 0\n",
        "    \n",
        "    for x_mb, y_mb, x_mb_len in train_ds:\n",
        "        with tf.GradientTape() as tape:\n",
        "            tr_loss = loss_fn(model, x_mb, y_mb, x_mb_len, max_sequence=10)\n",
        "        grads = tape.gradient(tr_loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(grads_and_vars=zip(grads, model.trainable_variables))\n",
        "        avg_tr_loss += tr_loss\n",
        "        tr_step += 1\n",
        "    avg_tr_loss /= tr_step\n",
        "    tr_loss_hist.append(avg_tr_loss)\n",
        "    \n",
        "    if (e + 1) % 5 == 0:\n",
        "        print('Epoch: {:3}, tr_loss: {:.3f}'.format(e+1, avg_tr_loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwIj5EbBaMPI"
      },
      "source": [
        "We trained the model with 0.003 loss. Then we can enter the X data into the model as an input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxGKrgWtaMPI",
        "outputId": "c2a37f37-4bf0-41a4-ad97-3570a52bc8f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6., 7., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [4., 7., 2., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [4., 7., 3., 4., 5., 1., 4., 0., 0., 0.],\n",
              "       [4., 7., 2., 1., 7., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "y_pred = model.predict(X)\n",
        "y_pred = np.argmax(y_pred, axis=-1) * X_mask\n",
        "\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg6YsvDyaMPJ"
      },
      "source": [
        "To understand the model more visually, we can convert from numerical vector to POS with `idx2pos` dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PL-7aqfaaMPJ",
        "outputId": "494a3f0f-2558-46bd-c6cc-f615770894b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['pronoun',\n",
            "  'verb',\n",
            "  'adjective',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>'],\n",
            " ['noun',\n",
            "  'verb',\n",
            "  'adverb',\n",
            "  'adjective',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>'],\n",
            " ['noun',\n",
            "  'verb',\n",
            "  'determiner',\n",
            "  'noun',\n",
            "  'preposition',\n",
            "  'adjective',\n",
            "  'noun',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>'],\n",
            " ['noun',\n",
            "  'verb',\n",
            "  'adverb',\n",
            "  'adjective',\n",
            "  'verb',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>',\n",
            "  '<pad>']]\n",
            "[['pronoun', 'verb', 'adjective'],\n",
            " ['noun', 'verb', 'adverb', 'adjective'],\n",
            " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
            " ['noun', 'verb', 'adverb', 'adjective', 'verb']]\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "y_pred_pos = list(map(lambda row: [idx2pos.get(elm) for elm in row], y_pred.astype(np.int32).tolist()))\n",
        "\n",
        "pprint(y_pred_pos)\n",
        "\n",
        "pprint(pos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AF1DvesoaMPJ",
        "outputId": "427ae37c-e0f3-4340-9573-55bbfdcd874f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure()\n",
        "plt.plot(tr_loss_hist)\n",
        "plt.title('Training loss for many-to-many model')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy3ZgmLhaMPJ"
      },
      "source": [
        "## Summary\n",
        " we tried to understand the basic concept of many-to-many RNN model, and how it can used for POS tagging. the output node is more than 2, not one, and measuring the sequence loss. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_f1SDa6aMPJ"
      },
      "source": [
        "{{ 'Reference from stanford CS231n lecture note' | fndetail: 1}}\n",
        "{{ 'Bring the definition from [wikipedia](https://en.wikipedia.org/wiki/Part_of_speech)' | fndetail: 2}}"
      ]
    }
  ]
}